{"docstore/metadata": {"c20b184d-c51b-45a8-b944-6f76ec4da2c4": {"doc_hash": "5d5332664c145c52710f8478299f613a59681edbbf7f0842bfcdd7474b32cace"}, "5929e1d3-b915-43c9-a58e-b66c7ea53bac": {"doc_hash": "3b7fac1a3585058301c497485d5c31cde17acfbd757ec6cb1856e8b18c300b8e"}, "c10a68e2-bc15-4867-b386-97876057fb71": {"doc_hash": "1f0500c52c56f1b425ed4c8dbbd63a6fde917c22f508483c576fb589d891136e"}, "4fc80f34-49c4-44e2-a5fd-727769911b22": {"doc_hash": "2cf4790ae7014f320cc320e6f15df22b3ab5b59f4d10023b9f9daf0d661ff3f7"}, "fe64afdc-7e3d-43d8-a28a-81b97b1a7e86": {"doc_hash": "31f5ead890433aa2d14aaa83d7c4edb36a623a9063214c4f5ef72737564d7d55"}, "e95e46ac-8b4e-4142-960f-071b417c25a6": {"doc_hash": "2dbdb26372bd5db753311d8aa3df39f9e828e7837520354775ab8d5977605585"}, "07ac71b4-c757-4ee8-8124-a1b240204ab3": {"doc_hash": "eb41f3082a2f2679b97973801d6fd8b11aa627f14a60ad17fef00e1e5bb38692"}, "f65f9461-731e-4942-9cec-9171159ebc40": {"doc_hash": "d6d24e7412cf7a625a7c860b280c1b561e399c8f511a0c0ce13f3eef85f82611"}, "ccfbbb65-8c20-45bc-9a2c-bb8f38abcff0": {"doc_hash": "24661e511b180eca837ac8c3607c6a679f64d45d4abf9ae11631f18be12e0936"}, "9ace5584-5ddc-4b8b-816b-3894866bea0a": {"doc_hash": "3cb55643585e7cec75f7bf95039fc775c7c7085ac71b3e63f3eb1b95bb9fd61a"}, "f02d1f0a-580c-41db-860e-c054105d3f75": {"doc_hash": "ed8d7157382f79332721a3ada5fca8bc7564cd497bf8250198e3242c87104506"}, "ac38aec3-0a63-4149-9cd9-65ea511cddd9": {"doc_hash": "d1704237621f4642272818e81f5fb5f9d7d0d3132e3f483dd5fbb0dd9d9294a4"}, "6bb2dc81-714d-49af-942e-afe3611e8e91": {"doc_hash": "4ab583dc6354cf0d310299a247cb212b1fe5ad6bb8771ca2414060c794bc0819"}, "54332bd4-83e3-434b-9b1b-fa1cacc15342": {"doc_hash": "cb7b839accc3c7ea36aaad3edbb7d081b61fff7534137f4500f7ab36a8bbc665"}, "5a51ab6b-9793-46b3-a18f-c0b471eee741": {"doc_hash": "927763bdc5de4e7b06e38c63cc058dd38ecc2218ac4e0cdb676675213608439b"}, "4c6bccd2-4e2d-40a1-ad0a-0527c721d7cf": {"doc_hash": "242b6320d7ee0ab579cddccbad888263eb42df8fc3d4ee3699d88b4c28342b2b"}, "2ebcfe31-8007-414d-b2c2-d46f1534c625": {"doc_hash": "6b2a671f7c17846ad89bdebbc7c7ef627669ac26d9505355457810391b29afa2"}, "fb85337e-8c32-42bd-93e9-101ce548c238": {"doc_hash": "398c9aeb25a7848f4cfc18da7468fe3b3b255d62121742318b2476da2c6d1d89"}, "558c49cd-b1b2-49d3-aa0e-82328822695e": {"doc_hash": "beace009f4bed7baee2aa25c1c7451845db9aa4d28d29e237a5598feb78d3699"}, "8f978440-ce79-4065-8cbc-754adab97c80": {"doc_hash": "c52df6ca5e7c1feb28a206169e51460f8f4c5da0b68b27e990262281fbe19a44"}, "4d47f922-9432-41e0-879b-8a5198abebf4": {"doc_hash": "f507869cf17ccf9556e1c9035d3ee0e256c0e33083ede2c55483a90515bd44b4"}, "cb471448-20a9-4f2b-8a36-667ddeb76802": {"doc_hash": "18b4e09bf759d03c2bfe7b045baeba30ea49164390e116c515618e5f630b5b1b"}, "9244cbb3-441d-4c60-8238-e675e6b93caf": {"doc_hash": "cf8f86c0a79524a1531a2af5aa80133799f4e2b45ce4aac51e9e34ad6d4709ee"}, "3fbdc7e5-f123-4784-ab82-ae59036d8c90": {"doc_hash": "cb7e219de3feadd722c587525207fcedc5d0675be7a8c7892256d09aa496dd78"}, "ff7fad39-f51a-42e5-8dd1-9d33dd480f7c": {"doc_hash": "4b34e9e585f89e26ad252edf2529eba138c42159ca0f376f35680a9a33c34639"}, "41ea2a3a-10f7-4149-8948-f7581630abca": {"doc_hash": "9497018af64ef6fd2eaf57fbdd4307389fa960106e0261efa5a840fc9bd80c2d"}, "bb11665f-d289-4b56-92f4-77200f9f89ae": {"doc_hash": "07201db92191773bb00fff0feea4d6a3e022eada60a43f06238225c3c35d979e"}, "66a78f15-0021-4881-ab03-8e4c9d70d200": {"doc_hash": "a52b3fc4f1709a0401209770f5676a82e219fff92d842140da5da6844c1a7c7c"}, "28f3e5fb-c32d-413e-9322-adfda3096bb3": {"doc_hash": "9b6a6a6dec38c26e79b4bc874bdd1384f72d56b836bb3c4f8545c1e3224a6b11"}, "8e4ca1a7-db75-4585-89f7-0295395c8e7f": {"doc_hash": "06735b7c02e2ad7d971812cbde1e324342f4e3acde2dfa1d9ab0b96bc33b1b4c"}, "dcebafd3-a3fb-47c5-9c9b-67bba01fedc6": {"doc_hash": "19ace06464932326fb04f8d5f517edae5b824d26ee4251d8f3c58f5423d69437"}, "b088c9a1-a53b-4a7c-927a-46cbc370b601": {"doc_hash": "f7f9f671ef2028025912611ac1556270f408295ecd80b73464b3dba075635948"}, "4fe11246-aab3-4198-8a83-1a3b0e0777b1": {"doc_hash": "21449d2694e9e3e35ebec05f782c7b4f52833eb48b781689d3249e4f0dbab726"}, "9e24914d-12d0-4943-a47a-c97e676704b3": {"doc_hash": "4615d8d77523d2500bbc3e4c7f6efbd03e80e1a26010ceb7e800b5206182946c"}, "9ed06512-9e4a-425f-bdc8-5bafe6461249": {"doc_hash": "6e1994f08db04e00b91deaca2169aec2c73c01eaf7539d4beba329fc1c3abaa2"}, "b73d52db-4305-4802-aa2e-bf1f584e2f9b": {"doc_hash": "6f1c9d80779c916ee5662807b96c3a463101624e6dc2fcdd6c16d77e0d251e9d"}, "d46a39e9-2645-4958-9f89-40a9e13426b6": {"doc_hash": "37a89bb976bf641251045fa34e708df555b6ea0be180ba665a801bf9cf389363"}, "b803ec6c-2f3a-4872-b187-598e950ef79e": {"doc_hash": "f4d4e57f7ae9eaa3babdfbb42d4f1146dd4dea7c9401314bfb00d5f44a903ff5"}, "9b2ed34c-c574-4e52-b340-35075978d238": {"doc_hash": "d1f96bda86e399156678171dd4866c2964b8d49dd06356ef0907d15c2d96948b"}, "6ae76f48-416b-4355-b014-9da1999e6092": {"doc_hash": "86054b54bebdcc529a6b080c68fa1939081750707843928bf22b3f422a11e08b"}, "45a274e6-b714-499c-a9af-30f043edaa0c": {"doc_hash": "3e649154cdf67ac16221eae6b8f13a49dc892c113883188d670553555d0fd726", "ref_doc_id": "c20b184d-c51b-45a8-b944-6f76ec4da2c4"}, "58517bf7-738a-46d9-a7cc-00465ade224a": {"doc_hash": "999913c0efb2e04c5718ebe00b31afb75108dc3e9bbdc58a4adda575d2d905b8", "ref_doc_id": "c20b184d-c51b-45a8-b944-6f76ec4da2c4"}, "d46101c2-147d-438d-b516-5ea1af1ccb4c": {"doc_hash": "e90b05df19178a970d90204c889a6607499eaed3b1cb6a2be41fe75d2c5611c0", "ref_doc_id": "5929e1d3-b915-43c9-a58e-b66c7ea53bac"}, "b415a11b-46ec-48f2-ad7f-50fdd92194e3": {"doc_hash": "cd83a191dad6a5c8d7bd2a5e9c6243032fabe8fe19c41888ab46ffb6484c7f6f", "ref_doc_id": "5929e1d3-b915-43c9-a58e-b66c7ea53bac"}, "bf9727bd-6606-4172-b370-de2a92f3900e": {"doc_hash": "0de8d3d7522c5d676310bd8d6f976b3ad45cec2de298172d481e86de2d88491d", "ref_doc_id": "c10a68e2-bc15-4867-b386-97876057fb71"}, "e6a59dff-414a-430b-8037-eb9fd2219dd7": {"doc_hash": "75aff068958530fc0e54f50ca52438720bd5ec21daa78e79c18848e53920119b", "ref_doc_id": "c10a68e2-bc15-4867-b386-97876057fb71"}, "3b72150e-4e50-4ff4-b40d-e9e9cb78202e": {"doc_hash": "888e462c4540a49451f46fcc50a66209ad6f902721915615c4845250e3429e55", "ref_doc_id": "4fc80f34-49c4-44e2-a5fd-727769911b22"}, "020129aa-5932-4877-950b-4bb9cda6d1e7": {"doc_hash": "b351474e078a8800833702b10684654b495453f1c424c71dd69b63729036adb4", "ref_doc_id": "fe64afdc-7e3d-43d8-a28a-81b97b1a7e86"}, "7464d452-7b13-4f4c-8aad-3b2b50d013fd": {"doc_hash": "cdac4b1517c03d95d47b9b7ef767eab4289ac32811e63948a1929cdad758f93c", "ref_doc_id": "fe64afdc-7e3d-43d8-a28a-81b97b1a7e86"}, "58cf4218-a39d-41f2-b9f1-871cb5aaf0b3": {"doc_hash": "a83cdf40e2c1629fff65383e83354d0f7269de9a1a303dfb0c96f92fdb3bd55d", "ref_doc_id": "e95e46ac-8b4e-4142-960f-071b417c25a6"}, "d1e24863-0ebc-4e86-b9bb-b1685dc1ef96": {"doc_hash": "9b77a145083df68ded3e224583f3998ceedd9a4811a39d26a3493f35666d3b28", "ref_doc_id": "07ac71b4-c757-4ee8-8124-a1b240204ab3"}, "5422f5e2-c0e8-42ea-a1ba-6b0d12d47895": {"doc_hash": "116dbfaeaee2ba84f71430bb5460511f935e9e601d5c61a49bbd8e40d42a6aa1", "ref_doc_id": "07ac71b4-c757-4ee8-8124-a1b240204ab3"}, "c7837b45-8ace-437a-bdfc-def98f479236": {"doc_hash": "bf3762252cb93cb3f933a12cd8a32d9e0dd8a57e5c890c13523d92873510ca91", "ref_doc_id": "f65f9461-731e-4942-9cec-9171159ebc40"}, "252343ae-4dfc-461f-8a84-aed39aa67153": {"doc_hash": "167b09b30189a62837a362f91a57fbb0acf21aa5fd39db744bc93cee85048670", "ref_doc_id": "f65f9461-731e-4942-9cec-9171159ebc40"}, "2f08b76d-df37-4d22-8715-d6e27ecd2390": {"doc_hash": "71a5438314587be0425e34f4f23c8cf68430fceb62950c9ee143a62d7f1545c8", "ref_doc_id": "ccfbbb65-8c20-45bc-9a2c-bb8f38abcff0"}, "ab3e382c-ffd7-43fe-acf3-18e801ec4b74": {"doc_hash": "16d47c493328dd7f1cbf59901b5d7758bcd40a15583aea04d7a0a2720cf8819d", "ref_doc_id": "9ace5584-5ddc-4b8b-816b-3894866bea0a"}, "397b1bc5-ce1c-4267-ab80-2da2a7e5e8fb": {"doc_hash": "cc4e9391fdbad7da6dd214428cddd34ef5260defd9794e94777725f085e583f8", "ref_doc_id": "f02d1f0a-580c-41db-860e-c054105d3f75"}, "f2d9276d-c9b9-4337-a30a-309320501f8f": {"doc_hash": "d737211f47d6111b0c9e461b773400fc76d2229b9bde4516b7243e17f2f9e69a", "ref_doc_id": "ac38aec3-0a63-4149-9cd9-65ea511cddd9"}, "874d0fb0-3e00-4bdb-a433-fa73656c6b55": {"doc_hash": "25ba9e254f9bfda8edd89fcb5db1a53c2f9571979d3243acbe11f95acca8f1bf", "ref_doc_id": "ac38aec3-0a63-4149-9cd9-65ea511cddd9"}, "74072635-7a7b-4b0b-b46d-49dd2bedca98": {"doc_hash": "87389ed3d5a88f32bf58440d2257e84060ea0c13ed0909617490d095f6c73091", "ref_doc_id": "6bb2dc81-714d-49af-942e-afe3611e8e91"}, "d636174b-d028-4789-a77f-5fb695a0a775": {"doc_hash": "0ba87fb2d9a684afff45d38f6cd35625a6eb9210529164a3f8ab98fcd93a62e6", "ref_doc_id": "6bb2dc81-714d-49af-942e-afe3611e8e91"}, "95763818-3c38-45cc-b334-b32db4dabd66": {"doc_hash": "4ec728ae34b2173a8fd0b19528a14e54bc93033172a37c8bc654ace18ab8b544", "ref_doc_id": "54332bd4-83e3-434b-9b1b-fa1cacc15342"}, "111a9ca7-6a44-4f9b-b8fa-2f4d3b4fae1a": {"doc_hash": "e11766a9638fcd3c22f3205a412ab821adcded7c86e86ec02917b5d3a367ed95", "ref_doc_id": "5a51ab6b-9793-46b3-a18f-c0b471eee741"}, "9f47f532-5a97-4881-bb7e-f9d99fa93652": {"doc_hash": "0e4e55c58b11af4cb21bd82b33cb0abb258f4d4cb57a1c9c51b7dcc0d65ec21a", "ref_doc_id": "5a51ab6b-9793-46b3-a18f-c0b471eee741"}, "d324e843-8b82-4c70-acf0-a949b51bf423": {"doc_hash": "c068b1897cdc477a568f7d8640f076e59ed7f65418d2f71b0cdcc109b4ea26b4", "ref_doc_id": "4c6bccd2-4e2d-40a1-ad0a-0527c721d7cf"}, "810801b7-fbee-4cd6-943e-ee6036264a25": {"doc_hash": "13504256c57f9c5a109a9982f6122205e3048852350807227721af03ca05b708", "ref_doc_id": "4c6bccd2-4e2d-40a1-ad0a-0527c721d7cf"}, "c89036c3-e386-45df-a657-c7b4bb8c5e49": {"doc_hash": "319332931b5a6207d3e7078825914542929c3d68cf1c071d410afec429c04570", "ref_doc_id": "2ebcfe31-8007-414d-b2c2-d46f1534c625"}, "df849252-73c8-4ce6-9233-c8333629921a": {"doc_hash": "2eb383166b6f5af6f53a0378e363b741ebb63aaba870521415be9e8341a3d002", "ref_doc_id": "2ebcfe31-8007-414d-b2c2-d46f1534c625"}, "8f892045-1b9b-4bee-8248-3f5d85b5e2fd": {"doc_hash": "4aa2c6d8b4acaa70b052a1350d2b2fe4bc3e41d6285a73d8781a637080f11a27", "ref_doc_id": "fb85337e-8c32-42bd-93e9-101ce548c238"}, "f7fbcbed-6040-44b3-8580-853f9770e635": {"doc_hash": "84b97b10f58d36f9a13924073cc46d3bd2efb4132bfd3d6de43c82941c594eec", "ref_doc_id": "fb85337e-8c32-42bd-93e9-101ce548c238"}, "89df1068-6713-4e14-ac11-1595fb9747c4": {"doc_hash": "3ca92f6ef4571701598ae12302daaa681a817e17e1c5db4b93ed8d9f47a9df72", "ref_doc_id": "558c49cd-b1b2-49d3-aa0e-82328822695e"}, "6805d554-1155-4b86-9c58-80aad740ed16": {"doc_hash": "50b448f9deb6a115fb05427e70d402a70590c6112ddb3ac830a6eb66980b9feb", "ref_doc_id": "558c49cd-b1b2-49d3-aa0e-82328822695e"}, "8218b2f8-fba7-4866-9d2b-6789bee1e280": {"doc_hash": "ddda9d0b650b646bedc7f8e868fbecf8f33b97f2cc1cf3d8bcabafde9fa789f4", "ref_doc_id": "8f978440-ce79-4065-8cbc-754adab97c80"}, "b80fb0e0-baf4-4998-9ca9-2f96b389e04b": {"doc_hash": "182c7328c7de579d56889cee645e7cdde59544de7e2f93fe8adf6e1f64b5b4f8", "ref_doc_id": "8f978440-ce79-4065-8cbc-754adab97c80"}, "3407d69d-6868-4d61-8bb5-673e0ba63574": {"doc_hash": "e42f7fb443a07ec2edf6916f8cb3bb6a2fa859fce2106fc1739e1f9c66a2269d", "ref_doc_id": "4d47f922-9432-41e0-879b-8a5198abebf4"}, "0b8beeea-f3a0-4132-ba18-a280cfb754b5": {"doc_hash": "d730400f39998d606286084a84cb777a63dd1440c0aa3d36d0962bc52971b7ca", "ref_doc_id": "4d47f922-9432-41e0-879b-8a5198abebf4"}, "994fe664-6027-4bb5-81cf-127e336961c3": {"doc_hash": "99173b1cdfc30d0796a8c25f9fdf14ff0e7390dfd3bcb34348ab4df08a242609", "ref_doc_id": "cb471448-20a9-4f2b-8a36-667ddeb76802"}, "318c557d-9675-42c7-af4a-1798c83ff92e": {"doc_hash": "a2317a5beedc7923f7fc92220f3d431f249cd6cb3b4b2aad64f1496877aba4c5", "ref_doc_id": "cb471448-20a9-4f2b-8a36-667ddeb76802"}, "bf4b4467-d8a2-4d21-ab41-a3453ef26365": {"doc_hash": "f7df08dfa8f2d68e7fd75df4504c29805cb622bf7de7dc0f6e6a26c5adb7b501", "ref_doc_id": "9244cbb3-441d-4c60-8238-e675e6b93caf"}, "e1b7cb24-1324-4f64-b9a5-4b0ca5d21de8": {"doc_hash": "69d5b1f869d40a90f432422e9db6bde6a2dd3fd1bfdd4e808f4a8c7ea5639f73", "ref_doc_id": "9244cbb3-441d-4c60-8238-e675e6b93caf"}, "54640df1-57bf-4260-8e0b-12ff6ec0d004": {"doc_hash": "92478b36fe26e21e0e5a1c0c346ef2bb3ae6686cb513b402f2cf251f1217a536", "ref_doc_id": "3fbdc7e5-f123-4784-ab82-ae59036d8c90"}, "7dd1b51a-f789-4ba6-b1e3-38ec61440340": {"doc_hash": "50ee4fd8baf84fa84c45805e8f27d8fad7e6481c31ae5c6a8c25f567f1ac08dd", "ref_doc_id": "3fbdc7e5-f123-4784-ab82-ae59036d8c90"}, "dc33c5a8-604b-4c82-aa1e-501133d8f731": {"doc_hash": "ac059f39cd52b13f3f72e8c164504e618b9996ddcf3c3e920bd33bca2958c7fb", "ref_doc_id": "ff7fad39-f51a-42e5-8dd1-9d33dd480f7c"}, "cb5beda1-04c6-4cce-9f62-f982392484d2": {"doc_hash": "68ef0388faf14713d9a07cadd72562b8e7e0e17557dad06ccb462cdf93f18bde", "ref_doc_id": "ff7fad39-f51a-42e5-8dd1-9d33dd480f7c"}, "7c85281f-d99f-46be-a194-fb58f0c2aff4": {"doc_hash": "06e3189737b227e3a67aca4a056c8c7f1c69b7b0c4b5dd2019976215f9f41a02", "ref_doc_id": "41ea2a3a-10f7-4149-8948-f7581630abca"}, "c6c982d6-81c0-4653-a08e-e8e1228304e9": {"doc_hash": "543814813cc5ff72015cd00e67044faedc36cf207b9e190905c9184ea029ac4c", "ref_doc_id": "41ea2a3a-10f7-4149-8948-f7581630abca"}, "f39b1126-2e93-4907-9942-6402d0a4d732": {"doc_hash": "694a86c47d75f92d0e0c003e39885498046d18d36e2e86ea644a6ca80ddf1b77", "ref_doc_id": "bb11665f-d289-4b56-92f4-77200f9f89ae"}, "c123dbfb-5155-4f58-896e-8e5721200106": {"doc_hash": "ab56f96edb41e2e601e17d827b5f4ffd087354e3edd86eae4d6880134a67a823", "ref_doc_id": "bb11665f-d289-4b56-92f4-77200f9f89ae"}, "c28529fe-bbb5-4a01-8b2a-c11421a06f61": {"doc_hash": "6c0922e8df38055fede73a3c3062047ba8c2f7be8953ed4c8e09e3a060c3b169", "ref_doc_id": "66a78f15-0021-4881-ab03-8e4c9d70d200"}, "80102867-5bec-4979-ae0d-55a907b37678": {"doc_hash": "3a2898aa930677abeb0531d43a84d96d6c541f99d80d725ee143cffb4adf9c7e", "ref_doc_id": "66a78f15-0021-4881-ab03-8e4c9d70d200"}, "03921183-e74d-4d0a-b1d4-d388002f2aae": {"doc_hash": "3b9edba493a355cf738e4bbf7ffbfd414d22a80f40cee0d0ece0f9ac4ed7050d", "ref_doc_id": "28f3e5fb-c32d-413e-9322-adfda3096bb3"}, "5955a91e-6770-4978-ae18-a028819e10da": {"doc_hash": "7f99fa7e44b39521752dd729081e9745bed117949cdd567f5bd73d3782240c6e", "ref_doc_id": "28f3e5fb-c32d-413e-9322-adfda3096bb3"}, "286c4e19-b865-4046-980e-a13f80f01ec2": {"doc_hash": "bfa5da7fa6d6bef3bd0d6176f4abdd93066432e40fcc63b1a80b47aa7b2d3032", "ref_doc_id": "28f3e5fb-c32d-413e-9322-adfda3096bb3"}, "d9ebe5f7-662b-47ad-87c4-6ea760a61589": {"doc_hash": "2e40c7ec290c76931b0bdd067e53ed7312d896a3613ca7247a173d13728d8153", "ref_doc_id": "8e4ca1a7-db75-4585-89f7-0295395c8e7f"}, "27335c1e-b2a3-4d70-9ba5-b1dd2cb21587": {"doc_hash": "3fe5990ceeee1cc14bf04c466e7a881d804ffe916d2ab777870c316bdc4073aa", "ref_doc_id": "8e4ca1a7-db75-4585-89f7-0295395c8e7f"}, "16b69865-7146-4a44-925c-6e91e2989467": {"doc_hash": "2851306e43448af1fc94b15d5f140b62b5d33f0c90d8a68275e2a330a50ae133", "ref_doc_id": "dcebafd3-a3fb-47c5-9c9b-67bba01fedc6"}, "85217703-6e9b-4ced-9736-6eace695355e": {"doc_hash": "2964f17626b04d7c8cdffb6b7f93cade2d3144a2220112ca9a72c3fc6134f27c", "ref_doc_id": "dcebafd3-a3fb-47c5-9c9b-67bba01fedc6"}, "f4f0daa8-e0a9-44d5-9a98-685b37000aa0": {"doc_hash": "237a2a5550002f77508d1449cea7d78f1e4cddbf189e32693abfccd0fdea6718", "ref_doc_id": "b088c9a1-a53b-4a7c-927a-46cbc370b601"}, "05cbc9bb-6c11-4516-87b5-a47b6c8937bc": {"doc_hash": "518ff637823d80929acd1a3dfe60135217b1b6c8e19f96060c39ce3adcf26be1", "ref_doc_id": "4fe11246-aab3-4198-8a83-1a3b0e0777b1"}, "71aeb199-b664-4109-93a8-6e59f1df0335": {"doc_hash": "2785503f8bd690e6819fec2533264820fd6295ea16397703587e7b67e6fbfe5b", "ref_doc_id": "4fe11246-aab3-4198-8a83-1a3b0e0777b1"}, "10bbf59e-a196-4c26-9287-5f12dcad117a": {"doc_hash": "0242e9cfd4dc8d8e3248e38de8250a4e8ada0805d4674fb081a5d92914ee385a", "ref_doc_id": "9e24914d-12d0-4943-a47a-c97e676704b3"}, "3d61b5b3-6f11-4d07-95ae-7b16e4f5e368": {"doc_hash": "9996a3e02f4d19131c959b9c61718e57601fbcd16369437effe4cf9bb5fdad62", "ref_doc_id": "9e24914d-12d0-4943-a47a-c97e676704b3"}, "25789815-c800-4732-8d44-651c163df013": {"doc_hash": "a476bc969fe2ebf5d84e5bc43ba71363dcd4af1d1fc2484fdd541d5aafcfecf0", "ref_doc_id": "9ed06512-9e4a-425f-bdc8-5bafe6461249"}, "9e40395b-071c-406a-a28f-873e96ff308b": {"doc_hash": "fb83a2296b2671c4ce0c7fecab6b3242ec3498f690937aacbfe369d4499add83", "ref_doc_id": "9ed06512-9e4a-425f-bdc8-5bafe6461249"}, "87af16b4-c6a5-4a01-bb93-8586338f8e44": {"doc_hash": "baabef8824c2dba228bbf901a005e18c92b2e436a4cfc4706532bcb63137491c", "ref_doc_id": "9ed06512-9e4a-425f-bdc8-5bafe6461249"}, "1baa69df-a064-4a2d-bf65-d8775c5cdeb0": {"doc_hash": "86ffa0019c06bd017f2861c7b8d77ce2df313d2b31b9a60d33c810780c564c1f", "ref_doc_id": "b73d52db-4305-4802-aa2e-bf1f584e2f9b"}, "65b6cc08-ca0b-435c-937c-a9fbea629c2f": {"doc_hash": "703a70a48ca8337221726edbedc899d5d406bb723d324eb0513b0b319794c300", "ref_doc_id": "b73d52db-4305-4802-aa2e-bf1f584e2f9b"}, "858c80ad-7893-479d-b229-d1c20ddf2657": {"doc_hash": "5b7f8d73c45f492b9dea068522a9b324fe3bec80d99d954befa232cf1b025e05", "ref_doc_id": "b73d52db-4305-4802-aa2e-bf1f584e2f9b"}, "e751d589-4b59-4388-8e3f-fc142876d3f5": {"doc_hash": "36cf8d369a6bd01de80bc2fb8f252dbdfa5ba2011a34dcde97cc7c594a6ab1b8", "ref_doc_id": "d46a39e9-2645-4958-9f89-40a9e13426b6"}, "13be8a57-dcee-46c2-91d0-596e0dca8a2c": {"doc_hash": "2c67c886a1b6f3b7954b4ca2ecbc0c045aa3651c74dbe6d872f7af951cfc2f9b", "ref_doc_id": "d46a39e9-2645-4958-9f89-40a9e13426b6"}, "de400218-79f5-465d-93a1-f5e7aed0f955": {"doc_hash": "156f65ff8e8a86ede0fe4228396c6c1436636290387c3195e56a7bc72a8a6a5d", "ref_doc_id": "d46a39e9-2645-4958-9f89-40a9e13426b6"}, "97936bd6-9f93-4873-9b00-e2ee608dd859": {"doc_hash": "915f2b247994fe76dd0899c2ac597a8ad46cbf567d051abf01650f517c606a4d", "ref_doc_id": "d46a39e9-2645-4958-9f89-40a9e13426b6"}, "5f8f0398-320d-4921-8ce5-285ec3c472ce": {"doc_hash": "a1ca7a1bcee0f7aca9317e67212d435fb341350af93d095d849a7dc9a4f7f7b1", "ref_doc_id": "b803ec6c-2f3a-4872-b187-598e950ef79e"}, "c1ad9021-2965-46a2-be50-ac38b16ab146": {"doc_hash": "006e52a73e01b193653f629b499222b6b98ba1735bc70956fdfa8240fe077704", "ref_doc_id": "b803ec6c-2f3a-4872-b187-598e950ef79e"}, "b1ab3b83-5095-4ac5-b092-ce2aba1a8b54": {"doc_hash": "48c04daa032657396e558b73aebbcac41daaf7943ba7bccbbf4b5105268ebde0", "ref_doc_id": "b803ec6c-2f3a-4872-b187-598e950ef79e"}, "a09830d7-eef3-4ba8-b66d-228765342ed0": {"doc_hash": "345e5a1cdeca9905390fc984927a188591ceb55798a9b14a514c4dc7ec223068", "ref_doc_id": "b803ec6c-2f3a-4872-b187-598e950ef79e"}, "c9269c6e-122f-4e12-9068-81c32dc57e1f": {"doc_hash": "8f680c4a343a2b08bb87758c96d73dfdedb9d1ba0c125110ddd2eaf4cba91b1b", "ref_doc_id": "9b2ed34c-c574-4e52-b340-35075978d238"}, "06055c5d-a657-4a6c-b66a-7a8e433a6728": {"doc_hash": "505cd3070008d64b13d31c8e84bd6b4960d9a0eaaeec777f6499fb96c069e696", "ref_doc_id": "9b2ed34c-c574-4e52-b340-35075978d238"}, "599d5077-4e0e-4564-af46-71831e865bfb": {"doc_hash": "4f955b634e8520b8bf2d315e852a204e8471f7659967264290852ec9c37b7cbd", "ref_doc_id": "9b2ed34c-c574-4e52-b340-35075978d238"}, "013efaeb-0953-47f4-b292-e4ab0ab9ec86": {"doc_hash": "e8dddc2ed852ea6d5073af014e1f8d8f1cd2f866b67cff32c8cc028d0a5b1d1b", "ref_doc_id": "9b2ed34c-c574-4e52-b340-35075978d238"}, "c89a50d6-2ce7-4171-a280-a52601857a1b": {"doc_hash": "10bd4245c432dfd44b9a7b4b1179edea288830d8b409ed7a11fc99cb61b9614e", "ref_doc_id": "6ae76f48-416b-4355-b014-9da1999e6092"}, "c55c0697-5756-459f-99da-83f17cf672a4": {"doc_hash": "82d40982c5cb65eb082fa0abb5cebd0dcd758dcdf6788e4953bba1eaa5733a5f", "ref_doc_id": "6ae76f48-416b-4355-b014-9da1999e6092"}, "6d7ec912-b086-4d2b-afd6-2943346e20f6": {"doc_hash": "ce9aa04d9c8dea1473e9f4df59758f9544ce4f99a0959ebfc3e5632313c0c84f", "ref_doc_id": "6ae76f48-416b-4355-b014-9da1999e6092"}}, "docstore/data": {"45a274e6-b714-499c-a9af-30f043edaa0c": {"__data__": {"id_": "45a274e6-b714-499c-a9af-30f043edaa0c", "embedding": null, "metadata": {"page_label": "1", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "c20b184d-c51b-45a8-b944-6f76ec4da2c4", "node_type": "4", "metadata": {"page_label": "1", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "hash": "5d5332664c145c52710f8478299f613a59681edbbf7f0842bfcdd7474b32cace", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "58517bf7-738a-46d9-a7cc-00465ade224a", "node_type": "1", "metadata": {}, "hash": "d8967b2c1a713d5e19eb1f0564ac3c793065038334228b5b71bb534489cd202e", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "1\nGPT (Generative Pre-trained Transformer) \u2013 A\nComprehensive Review on Enabling Technologies,\nPotential Applications, Emerging Challenges, and\nFuture Directions\nGokul Yenduri, Ramalingam M, Chemmalar Selvi G, Supriya Y , Gautam Srivastava,\nPraveen Kumar Reddy Maddikunta, Deepti Raj G, Rutvij H Jhaveri, Prabadevi B, Weizheng Wang, Athanasios V .\nVasilakos, and Thippa Reddy Gadekallu\nAbstract\u2014The Generative Pre-trained Transformer (GPT) rep-\nresent a notable breakthrough in the domain of natural language\nprocessing, which is propelling us toward the development of\nmachines that can understand and communicate using language\nin a manner that closely resembles that of humans. GPT is based\non the transformer architecture, a deep neural network designed\nfor natural language processing tasks. Due to their impressive\nperformance on natural language processing tasks and ability\nto effectively converse, GPT have gained signi\ufb01cant popularity\namong researchers and industrial communities, making them one\nof the most widely used and effective models in natural language\nprocessing and related \ufb01elds, which motivated to conduct this\nreview. This review provides a detailed overview of the GPT,\nincluding its architecture, working process, training procedures,\nenabling technologies, and its impact on various applications.\nIn this review, we also explored the potential challenges and\nlimitations of a GPT. Furthermore, we discuss potential solutions\nand future directions. Overall, this paper aims to provide a\ncomprehensive understanding of GPT, enabling technologies,\ntheir impact on various applications, emerging challenges, and\npotential solutions.\nIndex Terms\u2014Generative Pre-trained Transformer, Natural\nlanguage processing, Arti\ufb01cial Intelligence\nGokul Yenduri, Ramalingam M, Chemmalar Selvi G, Supriya Y , Praveen\nKumar Reddy Maddikunta, Deepti Raj G, Prabadevi B are with the School\nof Information Technology and Engineering, Vellore Institute of Technol-\nogy, Vellore, Tamil Nadu- 632014, India (Emails: {gokul.yenduri, rama-\nlingam.m, chemmalarselvi.g, supriya.d, praveenkumarreddy, deeptiraj.g2020,\nprabadevi.b }@vit.ac.in)\nGautam Srivastava is with the Dept. of Math and Computer Science, Bran-\ndon University, Canada, and the Research Centre for Interneural Computing,\nChina Medical University, Taichung, Taiwan as well as Dept. of Computer\nScience and Math, Lebanese American University, Beirut, Lebanon (email:\nsrivastavag@brandonu.ca)\nRutvij H Jhaveri is with the Department of Computer Science and Engi-\nneering, School of Technology, Pandit Deendayal Energy University, India,\n(Email: rutvij.jhaveri@sot.pdpu.ac.in).\nWeizheng Wang is with the Department of Computer Science,\nCity University of Hong Kong, Hong Kong SAR, China, (E-mail:\nweizheng.wang@ieee.org).\nAthanasios V . Vasilakos is with the Center for AI Research\n(CAIR),University of Agder(UiA), Grimstad, Norway, (Email:\nthanos.vasilakos@uia.no).\nThippa Reddy Gadekallu is with the School of Information Technology\nand Engineering, Vellore Institute of Technology, Vellore 632014, India,\nLovely Professional University, Phagwara, India, Department of Electrical\nand Computer Engineering, Lebanese American University, Byblos, Lebanon,\nJiaxing University , Jiaxing 314001, China, Zhongda Group, China, 314312\n(E-mail: thippareddy@ieee.org).", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3318, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "58517bf7-738a-46d9-a7cc-00465ade224a": {"__data__": {"id_": "58517bf7-738a-46d9-a7cc-00465ade224a", "embedding": null, "metadata": {"page_label": "1", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "c20b184d-c51b-45a8-b944-6f76ec4da2c4", "node_type": "4", "metadata": {"page_label": "1", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "hash": "5d5332664c145c52710f8478299f613a59681edbbf7f0842bfcdd7474b32cace", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "45a274e6-b714-499c-a9af-30f043edaa0c", "node_type": "1", "metadata": {"page_label": "1", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "hash": "3e649154cdf67ac16221eae6b8f13a49dc892c113883188d670553555d0fd726", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Weizheng Wang is with the Department of Computer Science,\nCity University of Hong Kong, Hong Kong SAR, China, (E-mail:\nweizheng.wang@ieee.org).\nAthanasios V . Vasilakos is with the Center for AI Research\n(CAIR),University of Agder(UiA), Grimstad, Norway, (Email:\nthanos.vasilakos@uia.no).\nThippa Reddy Gadekallu is with the School of Information Technology\nand Engineering, Vellore Institute of Technology, Vellore 632014, India,\nLovely Professional University, Phagwara, India, Department of Electrical\nand Computer Engineering, Lebanese American University, Byblos, Lebanon,\nJiaxing University , Jiaxing 314001, China, Zhongda Group, China, 314312\n(E-mail: thippareddy@ieee.org).\nTABLE I\nLIST OF KEY ACRONYMS ONLY IF IT IS REPEATED\nAcronyms Description\nAI Arti\ufb01cial Intelligence\nAR Augmented Reality\nBERT Bidirectional Encoder Representations from\nTransformers\nBGN Boneh\u2013Goh\u2013Nissim\nCNN ConvolutionalNeural Network\nDAP Data Access Point\nDLT Decentralized Ledger Technology\nDL Deep Learning\nDRL Deep Reinforcement Learning\nDR Demand response\nEC Edge Computing\nEU End User\nEAPs Energy Access Points\n5G Fifth-Generation\n4G Fourth-Generation\nGPT Generative Pre-trained Transformer\nGPU Graphics Processing Unit\nHPC High Performance Computing\nHCI Human Computer Interaction\nIoT Internet of Things\nML Machine Learning\nNLP Natural Language Processing\nNPC Non Playable Character\nPLM Pre-trained Language Models\nPTM Pre-Trained Models\nRNN Recurrent Neural Network\n6G Sixth-Generation\nTL Transfer Learning\nVU Virtual Reality\nI. I NTRODUCTION\nLanguage is the cornerstone of human communication and\nplays a vital role in shaping our interactions with the world.\nWith the advent of NLP, it has revolutionized the way we\ninteract with machines. NLP has become a game-changer in\nthe world of communication, enabling humans to interact with\narXiv:2305.10435v2  [cs.CL]  21 May 2023", "mimetype": "text/plain", "start_char_idx": 2637, "end_char_idx": 4502, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "d46101c2-147d-438d-b516-5ea1af1ccb4c": {"__data__": {"id_": "d46101c2-147d-438d-b516-5ea1af1ccb4c", "embedding": null, "metadata": {"page_label": "2", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "5929e1d3-b915-43c9-a58e-b66c7ea53bac", "node_type": "4", "metadata": {"page_label": "2", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "hash": "3b7fac1a3585058301c497485d5c31cde17acfbd757ec6cb1856e8b18c300b8e", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "b415a11b-46ec-48f2-ad7f-50fdd92194e3", "node_type": "1", "metadata": {}, "hash": "f266fea0deeb20c145b60d66ebd9225e790228f5a4a6d76504c8584101f52d9c", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "2\nmachines in a more natural way. The evolution of NLP has\nbeen fueled by the exponential growth of textual data in the\ninternet. Over the years, NLP has witnessed a signi\ufb01cant trans-\nformation from simple rule-based systems to complex deep\nlearning-based models. Despite the advances, natural language\nunderstanding and generation have long been a challenging\nproblem in the \ufb01eld of NLP, largely due to the complex\nnature of human language. However, recent advancements\nhave paved the way for the new approaches to tackle these\nchallenges. One such breakthrough in NLP, is the development\nof the GPT [1]. GPT became famous after the launch of\nChatGPT by OpenAI, a research company [2] that focuses on\ndeveloping AI technologies. GPT is a deep learning model that\nis pre-trained on large corpora of text data and can be \ufb01ne-\ntuned for speci\ufb01c tasks like language generation, sentiment\nanalysis, language modelling, machine translation, and text\nclassi\ufb01cation. The transformer architecture used in GPT is\na signi\ufb01cant advancement over previous approaches to NLP,\nsuch as RNN and CNN. It uses a self-attention mechanism to\nallow the model to consider the context of the entire sentence\nwhen generating the next word, which improved the model\u2019s\nability to understand and generate language. The decoder is\nresponsible for generating the output text based on the input\nrepresentation [3].\nGPT can perform a wide range of tasks in NLP. One of\nits key strengths is in natural language understanding (NLU),\nwhere it can analyze and comprehend the meaning of text, in-\ncluding identifying entities and relationships in sentences. It\u2019s\nalso pro\ufb01cient in natural language generation (NLG), which\nmeans it can create text output, such as writing creative content\nor answering questions in a comprehensive and informative\nway. Alternatively, GPT is also code generator, where it can\nwrite programming code in various languages, such as Python\nor JavaScript. GPT can also be utilized for question answering,\nwhich means it can provide summaries of factual topics or\ncreate stories based on the input text. Additionally, GPT can\nsummarize a piece of text, such as providing a brief overview\nof a news article or research paper, and it can be used for\ntranslation, which makes it possible to translate text from\none language to another. Overall, GPT\u2019s ability to perform\na wide range of NLP tasks with high accuracy and precision,\nmakes it an invaluable tool for various industries, including\n\ufb01nance, healthcare, marketing, and more. As NLP technology\ncontinues to advance, we can expect GPT and other language\nmodels to become even more sophisticated and powerful,\nenabling us to communicate with machines more naturally and\neffectively.\nA. Motivation\nGPT has become a transformative technology in the \ufb01eld\nof NLP, enabling the rapid development and growth of a wide\nrange of industries and applications. Despite its wide adoption\nand numerous potential applications, there is still much to be\nexplored and understood about GPT\u2019s capabilities. Although\nthere are studies on GPT in the literature related to academia\nand libraries [4], education [5], GPT models [6], banking and\ncorporate communication [7], advancements in chatGPT and\nits version [8], and on generative AI\u2019s [9], no existing reviews\nare dedicated to providing a comprehensive survey on GPT.\nTherefore, there is a need for a comprehensive review that\nfocuses on GPT\u2019s architecture, enabling technologies, potential\napplications, emerging challenges, interesting projects and fu-\nture directions. These limitations motivated us to conduct this\nreview. Hence, this review will not only help researchers and\npractitioners in this \ufb01eld to gain a better understanding of GPT\nbut also provide valuable insights into its potential applications\nand major limitations when conducting the research.\nB. Related Surveys and Contributions\nThe GPT model is a type of DL model that uses self-\nsupervised learning to pre-train massive amounts of text data,\nenabling it to generate high-quality language output. The\nrecent advancements in GPT model research can be attributed\nto the continual improvement of its architecture, increased\navailability of computing power, and the development of novel\ntechniques to \ufb01ne-tune the model for speci\ufb01c tasks.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 4283, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "b415a11b-46ec-48f2-ad7f-50fdd92194e3": {"__data__": {"id_": "b415a11b-46ec-48f2-ad7f-50fdd92194e3", "embedding": null, "metadata": {"page_label": "2", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "5929e1d3-b915-43c9-a58e-b66c7ea53bac", "node_type": "4", "metadata": {"page_label": "2", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "hash": "3b7fac1a3585058301c497485d5c31cde17acfbd757ec6cb1856e8b18c300b8e", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "d46101c2-147d-438d-b516-5ea1af1ccb4c", "node_type": "1", "metadata": {"page_label": "2", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "hash": "e90b05df19178a970d90204c889a6607499eaed3b1cb6a2be41fe75d2c5611c0", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Therefore, there is a need for a comprehensive review that\nfocuses on GPT\u2019s architecture, enabling technologies, potential\napplications, emerging challenges, interesting projects and fu-\nture directions. These limitations motivated us to conduct this\nreview. Hence, this review will not only help researchers and\npractitioners in this \ufb01eld to gain a better understanding of GPT\nbut also provide valuable insights into its potential applications\nand major limitations when conducting the research.\nB. Related Surveys and Contributions\nThe GPT model is a type of DL model that uses self-\nsupervised learning to pre-train massive amounts of text data,\nenabling it to generate high-quality language output. The\nrecent advancements in GPT model research can be attributed\nto the continual improvement of its architecture, increased\navailability of computing power, and the development of novel\ntechniques to \ufb01ne-tune the model for speci\ufb01c tasks. These\nadvancements have led to the creation of larger and more\npowerful GPT models, enabling them to perform a wider range\nof NLP tasks with unprecedented accuracy and \ufb02uency. These\nGPT models have demonstrated great potential in transforming\nvarious industries like healthcare [10], customer service [11],\n\ufb01nancial industry [12] and so on. These applications are\nenabled by the generation of high-quality and diverse data\nlike large-scale corpora of text data with different fast-growing\nenabling technologies [13], [14]. There are numerous survey\npapers published to provide a comprehensive overview of\nthe latest developments in GPT models, insights into the\ndifferent architectures, training methods, evaluation metrics,\nand highlight the challenges and future directions of this \ufb01eld.\nThis literature survey aims to review and analyze the key\n\ufb01ndings and contributions of the most recent survey papers\npublished on GPT models, to provide a comprehensive and\nup-to-date understanding of the state-of-the-art in this exciting\nand rapidly evolving \ufb01eld.\nLund et al. [4] presents the potential effects of AI and GPT\nmodels, speci\ufb01cally ChatGPT, on academia and libraries. They\ndiscussed the capabilities of ChatGPT in generating human-\nlike responses and its potential applications. They examine\nhow AI-powered chatbots and virtual assistants based on\nGPT models can enhance student learning experiences, assist\nwith research tasks, and improve library services. They also\naddress concerns regarding data privacy, biases, and the need\nfor ethical guidelines. Overall, this survey paper highlighted\nthe transformative potential of AI and GPT models while\nemphasizing the importance of responsible deployment and\nhuman oversight.\nKasneci et al. [5] have reviewed the potential opportunities\nand challenges of using large language models, speci\ufb01cally\nChatGPT, for educational purposes. They highlighted the\nbene\ufb01ts and limitations of using such models by discussing\ntheir implications for teaching and learning. In addition, a\nde\ufb01ned strategy and pedagogical approach with a heavy focus\non critical thinking and fact-checking are required while using\nsuch large language models in educational institution. Thus,", "mimetype": "text/plain", "start_char_idx": 3343, "end_char_idx": 6493, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "bf9727bd-6606-4172-b370-de2a92f3900e": {"__data__": {"id_": "bf9727bd-6606-4172-b370-de2a92f3900e", "embedding": null, "metadata": {"page_label": "3", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "c10a68e2-bc15-4867-b386-97876057fb71", "node_type": "4", "metadata": {"page_label": "3", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "hash": "1f0500c52c56f1b425ed4c8dbbd63a6fde917c22f508483c576fb589d891136e", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "e6a59dff-414a-430b-8037-eb9fd2219dd7", "node_type": "1", "metadata": {}, "hash": "cd4a80a39d899f4e64902403da85539417616415827fd987e22505ec5eb1baa8", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "3\nthey concluded the paper by highlighting the key technical\nchallenges like copyright issues, biased content creation, user\ndependency, privacy and security, and high-cost language\nmodels when such language models are used in the educational\nsector.\nQiu et al. [6] presented an exhaustive survey of various\ntypes of GPT models by detailing their working architecture.\nThey discussed the evolution of pre-training methods for NLP,\nfrom language modelling to TL and pre-training on large-\nscale corpora. It also reviews the different types of GPT\nmodels, including word embeddings, contextual embeddings,\nand transformer-based models, and discusses their applications\nin various NLP tasks such as text classi\ufb01cation, Named Entity\nRecognition, and machine translation. They highlighted the\nbene\ufb01ts of GPT\u2019s models for the NLP domain, such as its\nability to improve model performance with limited annotated\ndata, reduce the need for task-speci\ufb01c feature engineering, and\nenable TL across multiple tasks. They discussed the major\nchallenges and limitations of PTMs, such as the risk of bias\nand the lack of interpretability.\nGeorge et al. [7] studied the potential impact of GPT-4,\nthe next iteration of GPT models, on communication within\ncorporate environments. They discussed how GPT-4 can rev-\nolutionize business communication by enabling more ef\ufb01cient\nand effective interactions. They explore various applications\nof GPT-4 in corporate settings, such as automating customer\nsupport through AI chatbots that can provide personalized\nresponses and resolve queries in real-time. They also ad-\ndressed potential challenges and considerations associated\nwith implementing GPT-4 in corporate settings. These include\nconcerns about data security, privacy, and the need for human\noversight to ensure accurate and ethical communication. Thus,\nthey concluded by emphasizing the transformative potential\nof GPT-4 in revolutionizing business communication to fully\nharness the bene\ufb01ts of GPT-4 while addressing any potential\nrisks or limitations.\nZhang et al. [8] presents an extensive survey of generative\nAI and evaluates the capabilities of the ChatGPT models,\nparticularly from GPT-4 to GPT-5. They provided an overview\nof generative AI, highlighting its signi\ufb01cance in generating\nrealistic and creative outputs across various domains and\nevaluate their advancements over previous iterations. They\nanalyze the architectural improvements, model size, training\ntechniques, and dataset considerations employed in GPT-4\nand GPT-5. In addition to it, they presented a comprehensive\ncomparison of ChatGPT with other state-of-the-art generative\nAI models, such as OpenAI\u2019s DALL-E and CLIP. Finally,\nthey concluded with valuable insights into the capabilities\nand limitations of these models and highlights the broader\nlandscape of generative AI.\nZaib et al. [9] provides a survey on the latest advance-\nments in GPTS and PTMs for conversational AI applications.\nThey focused on PLMs and their approaches while building\ndialogue-based systems. They also highlighted the potential\nuse of transformer-based models such as BERT and GPT,\nwhich have demonstrated good performance in understanding\nNLP generation, and dialogue management. Thus, they con-\ncluded with the signi\ufb01cant challenges in the \ufb01eld of developing\nconversational AI systems using PLMs and GPTs.\nThus, the comparison of existing surveys on GPT models\nhighlighting the growing importance of these models in key\nareas of NLP and other related \ufb01elds are discussed here.\nHence, this is the \ufb01rst-of-its-kind survey that presents the\nextensive information, by comparing existing surveys with our\nsurvey and summarized in Table II.\nC. Systematic Literature Survey\nIn this review of GPT, we conducted a thorough literature\nreview using various reputable sources. Our search was pri-\nmarily focused on peer-reviewed journals, and high-quality\narticles from reputed national and international conferences,\nseminars, books, symposiums, and journals. To ensure the\ncredibility of our sources, we referred to well-known archives\nsuch as Google Scholar and arXiv, and publications from top\ndatabases like IEEE, Springer, Elsevier, Taylor & Francis, and\nWiley. To identify relevant GPT references and publications,\nwe used keywords such as NLPGPT, GPT architecture, DL for\nGPT, Pretraining GPT, Fine-tuning AI GPT and GPT vertical\napplications.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 4379, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "e6a59dff-414a-430b-8037-eb9fd2219dd7": {"__data__": {"id_": "e6a59dff-414a-430b-8037-eb9fd2219dd7", "embedding": null, "metadata": {"page_label": "3", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "c10a68e2-bc15-4867-b386-97876057fb71", "node_type": "4", "metadata": {"page_label": "3", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "hash": "1f0500c52c56f1b425ed4c8dbbd63a6fde917c22f508483c576fb589d891136e", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "bf9727bd-6606-4172-b370-de2a92f3900e", "node_type": "1", "metadata": {"page_label": "3", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "hash": "0de8d3d7522c5d676310bd8d6f976b3ad45cec2de298172d481e86de2d88491d", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Hence, this is the \ufb01rst-of-its-kind survey that presents the\nextensive information, by comparing existing surveys with our\nsurvey and summarized in Table II.\nC. Systematic Literature Survey\nIn this review of GPT, we conducted a thorough literature\nreview using various reputable sources. Our search was pri-\nmarily focused on peer-reviewed journals, and high-quality\narticles from reputed national and international conferences,\nseminars, books, symposiums, and journals. To ensure the\ncredibility of our sources, we referred to well-known archives\nsuch as Google Scholar and arXiv, and publications from top\ndatabases like IEEE, Springer, Elsevier, Taylor & Francis, and\nWiley. To identify relevant GPT references and publications,\nwe used keywords such as NLPGPT, GPT architecture, DL for\nGPT, Pretraining GPT, Fine-tuning AI GPT and GPT vertical\napplications. We then screened all the retrieved articles based\non their titles, excluding any papers with poor-quality material.\nNext, we reviewed the abstracts of the remaining articles to\ndetermine their contributions. In the \ufb01nal step of our literature\nreview, we extracted the necessary data for our analysis. By\nfollowing these phases, we ensured that our study was based\non high-quality and credible sources.\nD. Paper Organization\nThe structure of this paper\u2019s organization is illustrated in\nFig. 1. Section 2 presents the preliminaries of GPT models\nsuch as the de\ufb01nition of GPT, its evolution and architecture,\nhow it works and presents the comparison of various GPT\nmodels. Section 3 discusses the key enabling technologies for\nGPT models. The impact of GPT models in various applica-\ntions are presented in Section 4. In Section 5, we highlighted\nsome of the exciting GPT projects that are currently developed.\nSection 6 includes open issues, other technical challenges\nand future research directions in the \ufb01eld of GPT. Finally,\nwe conclude the paper in Section 7, by summarizing the\nkey \ufb01ndings and contributions of this study. The list of key\nacronyms are listed in Table I.\nII. P RELIMINARIES\nIn this section, the evolution of GPT models, the architecture\nof GPT, working process of GPT models are discussed and\n\ufb01nally, different versions of GPT models are compared.\nA. Generative Pre-trained Transformer\nThe GPT model produces enormous quantities of pertinent\nand complicated machine-generated text from a small amount\nof text as input. GPT models can be identi\ufb01ed as a language\nmodel that mimics human text using a DL techniques and it\nacts as an autoregressive model in which the present value is\nbased on the previous value [15].", "mimetype": "text/plain", "start_char_idx": 3517, "end_char_idx": 6114, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "3b72150e-4e50-4ff4-b40d-e9e9cb78202e": {"__data__": {"id_": "3b72150e-4e50-4ff4-b40d-e9e9cb78202e", "embedding": null, "metadata": {"page_label": "4", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "4fc80f34-49c4-44e2-a5fd-727769911b22", "node_type": "4", "metadata": {"page_label": "4", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "hash": "2cf4790ae7014f320cc320e6f15df22b3ab5b59f4d10023b9f9daf0d661ff3f7", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "4\nSECTION-1:INTRODUCTION\nMOTIVATION RELATED SURVEYS AND\nCONTRIBUTIONS\nSYSTEMATIC LITERATURE\nSURVEY\nPAPER\nORGANIZATION\nSECTION-2:PRELIMINARIES\nGPT Definitions\nEvolution of GPT GPT Architecture How does GPT work? Comparisons of GPT versions\nDefinition-1 Definition-2 Definition-3 Definition-4\nSECTION-3:ENABLING TECHNOLOGIES\nARTIFICIAL INTELLIGENCE\nCLOUD COMPUTING\nEDGE COMPUTING\n5G & BEYOND NETWORKS\nHUMAN COMPUTER INTERACTION\nBIG DATA\nSECTION-4:IMPACT OF GPT ON VARIOUS APPLICATIONS\nEducation Healthcare Industry Agriculture\nTravel and Transport\nE-Commerce\nEntertainmentLifestyleGaming\nMarketing Finance\nINTRODUCTIONIMPACT OF GPT ON APPLICATION\nCHALLENGES SUMMARY\nSiriGPT AI Dungeon Copy.ai Bond.AI Viable\nUber's Plato Research Dialogue SystemAI Channels Fireflies.AI DeepScribe\nPolyglot AI Meena\nSECTION-6:OPEN ISSUES AND OTHER TECHNICAL CHALLENGES\nSECTION-5:PROJECTS\nDomain Specific GPTs Computational requirementsExplainability and interpretabilityData Bias\nMultimodal supportRobustness Multilingual supportModel size Limited understanding\nEthical ConcernsSecurity and privacy concerns\nSECTION-7:CONCLUSION\nFig. 1. Organization Chart of the survey.\n1) De\ufb01nition 1: GPTs are language models pre-trained on\nvast quantities of textual data and can perform a wide range\nof language-related tasks [16].\n2) De\ufb01nition 2: A GPT is a language model relying on DL\nthat can generate human-like texts based on a given text-based\ninput. [17].\n3) De\ufb01nition 3: GPT is a language model developed by\nOpenAI to help give systems intelligence and is used in such\nprojects as ChatGPT [17].\nB. Evolution of GPT\nGPT models have evolved through multiple changes and\nbreakthroughs in NLP technology. These are some signi\ufb01cant", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1704, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "020129aa-5932-4877-950b-4bb9cda6d1e7": {"__data__": {"id_": "020129aa-5932-4877-950b-4bb9cda6d1e7", "embedding": null, "metadata": {"page_label": "5", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "fe64afdc-7e3d-43d8-a28a-81b97b1a7e86", "node_type": "4", "metadata": {"page_label": "5", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "hash": "31f5ead890433aa2d14aaa83d7c4edb36a623a9063214c4f5ef72737564d7d55", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "7464d452-7b13-4f4c-8aad-3b2b50d013fd", "node_type": "1", "metadata": {}, "hash": "d5f46840072a6adcbe4460d54993ab005f22dda80fd64274b5c493d725aeb2df", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "5\nTABLE II\nCOMPARISON OF THIS SURVEY WITH THE EXISTING SURVEYS\nRef. Applications Enabling Technologies Remarks\nEducation\nIndustry\nAgriculture\nHealthcare\nTransport\nE-Commerce\nEntertainment\nLifestyle\nGaming\nMarketing\nFinance\nBig Data\nAI\nCloud Computing\nEdge Computing\n5G and Beyond\nHCI\n[4] \u2713 X X X X X X X X X X X \u2713 \u2713 \u2713 X X They conducted a survey discussing capabilities of\nChatGPT on academia and libraries. Although, Key\nchallenges of Chatgpt were highlighted, practical\nimplementation challenges and research directions\nwere missing.\n[5] \u2713 X X X X X X X X X X X \u2713 X X X X Reviewed the potential opportunities and challenges\nof using large language models, speci\ufb01cally Chat-\nGPT, for educational purposes. Thus, evolution of\nGPT and their preliminaries were not discussed in\nthis survey paper.\n[6] X X X X X X X X X X X X \u2713 X X X X They presented an exhaustive survey of various types\nof GPT models by detailing their working architec-\nture with bene\ufb01ts and limitations of GPTs. However,\n[7] X X X \u2713 X X X X X X X X \u2713 X X X X Studied the potential impact of GPT4 in business\ncommunication and explore various applications of\nGPT-4 in corporate settings by highlighting any\npotential risks or limitations. But, how GPT archi-\ntecture can be used in corporate is not found with\nkey enabling technologies.\n[8] X \u2713 X X \u2713 \u2713 \u2713 X X \u2713 \u2713 X \u2713 X X X X Analyzed the architectural improvements, model\nsize, training techniques, and dataset considerations\nemployed in GPT-4 and GPT-5. However, prelimi-\nnary details are unedr explored.\n[9] X X X X X X X X X X X X X X X X X Recent trends in language models, applications of di-\nalogue management, question answering NLP tasks\nwere discussed along with challenges and future\nscope of GPT. Although it covered most of the\ntechnical aspects, the integration challenges to over-\ncomeare not presented.\nOur Survey\nPaper\n\u2713 \u2713 \u2713 \u2713 \u2713 \u2713 \u2713 \u2713 \u2713 \u2713 \u2713 \u2713 \u2713 \u2713 \u2713 \u2713 \u2713 Presents the evolution of GPT models, GPT architec-\nture and its detailed working, key enabling technolo-\ngies, signi\ufb01cant advancements of GPT models and\ntheir potential bene\ufb01ts in real-life applications, GPT\nprojects, lessons learnt, open challenges and future\nresearch directions.\nturning points in the growth of the GPT model: Before GPT,\nNLP models have been trained on large amounts of annotated\ndata that is related to a speci\ufb01c task. This had a signi\ufb01cant\ndrawback because it was dif\ufb01cult to access the quantity of\nlabelled data required to train the model precisely. The NLP\nmodels were unable to complete tasks outside of their training\nset since they were restricted to a particluar set of data. To\nget around these restrictions, OpenAI offered a Generative\nLanguage Model called GPT-1 that was created using un-\nlabeled data and then given to users to \ufb01ne-tune to carry\nout subsequent tasks like sentiment analysis, categorization,\nand question-answering [18]. This indicates that the model\nattempts to produce an appropriate response based on input\nand that the data used to train the model is not labelled [19].\nFig. 2 shows the timeline of the evolution of several pre-trained\nmodels from Eliza, which was created in 1960, to the more\ncurrent 2022-ChatGPT.\nGPT-1 was the \ufb01rst ever model that could read the text and\nrespond to queries [20]. OpenAI released GPT-1 in 2018. GPT-\n1 was a major move forward in AI development because it\nenabled computers to comprehend textual material in a more\nnatural manner than before. This generative language model\nwas able to learn a wide variety of connections and gain\nimmense knowledge on a varied corpus of contiguous text\nand lengthy stretches [21]. This happened after being trained\non a huge BooksCorpus dataset. In terms of design, GPT-1\nemploys a 12-layer decoder architecture transformer with a\nself-attention system for training.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3777, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "7464d452-7b13-4f4c-8aad-3b2b50d013fd": {"__data__": {"id_": "7464d452-7b13-4f4c-8aad-3b2b50d013fd", "embedding": null, "metadata": {"page_label": "5", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "fe64afdc-7e3d-43d8-a28a-81b97b1a7e86", "node_type": "4", "metadata": {"page_label": "5", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "hash": "31f5ead890433aa2d14aaa83d7c4edb36a623a9063214c4f5ef72737564d7d55", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "020129aa-5932-4877-950b-4bb9cda6d1e7", "node_type": "1", "metadata": {"page_label": "5", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "hash": "b351474e078a8800833702b10684654b495453f1c424c71dd69b63729036adb4", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Fig. 2 shows the timeline of the evolution of several pre-trained\nmodels from Eliza, which was created in 1960, to the more\ncurrent 2022-ChatGPT.\nGPT-1 was the \ufb01rst ever model that could read the text and\nrespond to queries [20]. OpenAI released GPT-1 in 2018. GPT-\n1 was a major move forward in AI development because it\nenabled computers to comprehend textual material in a more\nnatural manner than before. This generative language model\nwas able to learn a wide variety of connections and gain\nimmense knowledge on a varied corpus of contiguous text\nand lengthy stretches [21]. This happened after being trained\non a huge BooksCorpus dataset. In terms of design, GPT-1\nemploys a 12-layer decoder architecture transformer with a\nself-attention system for training. GPT-1\u2019s capacity to execute\nzero-shot performance on different tasks was one of its major\nsuccess as a result of its pre-training. This ability demonstrated\nthat generative language modelling can be used to generalize\nthe model when combined with a successful pretraining idea.\nWith TL as its foundation, GPT models evolved into a potent\ntool for performing NLP tasks with minimal \ufb01ne-tuning [22].\nIt paved the way for other models to progress even more in\ngenerative pre-training using larger datasets and parameters.\n[18].\nTo create a better language model later in 2019, OpenAI\ncreated a GPT-2 using a bigger dataset and more parameters.\nThe model design and execution of GPT-2 are some of the\nkey advancements [23]. With 1.5 billion parameters, it has\n10 times the size of GPT-1 (117 million parameters), and it\nhas 10 times as many parameters and data [21]. By using\nonly the raw text as input and utilizing little to no training\nexamples, it is effective in terms of resolving various language\ntasks related to translation, summarization, etc. Evaluation of\nGPT-2 on various downstream task datasets revealed that it\nexcelled by substantially increasing accuracy in recognizing\nlong-distance relationships and predicting sentences [24].\nThe most recent iteration of the GPT model is GPT-3. It is a\nsizable language prediction and production model created by\nOpenAI that can produce lengthy passages of the source text.", "mimetype": "text/plain", "start_char_idx": 3011, "end_char_idx": 5202, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "58cf4218-a39d-41f2-b9f1-871cb5aaf0b3": {"__data__": {"id_": "58cf4218-a39d-41f2-b9f1-871cb5aaf0b3", "embedding": null, "metadata": {"page_label": "6", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "e95e46ac-8b4e-4142-960f-071b417c25a6", "node_type": "4", "metadata": {"page_label": "6", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "hash": "2dbdb26372bd5db753311d8aa3df39f9e828e7837520354775ab8d5977605585", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "6\nELIZA-1960\nPattern matching &\nreplacement\nHelps human chat by\nentertaining\nchatbot to provide original\nreplies on its own\nALICE-1995\nSmarterChild-2001\nSiri -2010\nGoogle Now-2012 Alexa-2014\nAnalyze human language\n& synthesize\nBot provides the\nconversations in a\nfun manner\nintelligent\npersonal assistant\nHelps to answer the questions,\nperforms actions,  makes\nrecommendations\nIntelligent personal\nassistant\nPARRY-1970\nChatbot to provide\npsychological concepts\nRacter-1980 Jabberwacky-1990\nCHatGPT-2022\nAssist users in generating\nhuman-like text based on\ngiven input\nFig. 2. GPT Road Map.\nGPT-3 eventually emerged as OpenAI\u2019s ground-breaking AI\nlanguage software. Simply put, it is a piece of software that can\ncreate lines on its own that are so distinctive they almost sound\nlike they were written by a human [25]. The GPT-3 program\nis presently accessible with limited access via a cloud-based\nAPI, and access is required to investigate the utility. Since its\ndebut, it has produced several interesting apps. Its capacity,\nwhich is about 175 billion parameters big and 100 times larger\nthan GPT-2, is a key advantage. It is taught using a corpus of\n500 billion words called \u201dCommon Crawl\u201d that was gathered\nfrom a sizable content archive and the internet [26]. Its other\nnoteworthy and unexpected capability is its ability to carry out\nbasic mathematical operations, write bits of code, and carry out\nclever tasks. As a result, NLP models can help businesses by\nresponding more quickly to requests and accurately keeping\nbest practices while minimizing human mistakes [27]. Due\nto its intricacy and size, many academics and writers have\nreferred to it as the ultimate black-box AI method. Due to the\nhigh cost and inconvenience of performing inference, as well\nas the billion-parameter size that makes it resource-intensive,\nit is dif\ufb01cult to put into practice in jobs [24].\nGPT-4 was named as the successor of GPT-3. In the meantime,\nseveral AI models built on GPT-3.5, an updated version of\nGPT-3, have been surreptitiously released by OpenAI [28].\nGPT-3.5 was trained on a mixture of text and code. From the\nvast amounts of data collected from the web, which includes\ntens and thousand of Wikipedia entries, social media posts,\nand news items, GPT 3.5 learned the relations between words,\nsentences, and various components. It was utilized by OpenAI\nto develop several systems that have been tailored to complete\nparticular jobs [26]. It collected vast amounts of data from the\nweb, including tens of thousands of Wikipedia entries, posts\non social media, and news items, and used that information\nto learn the relationships between sentences, words, and word\ncomponents [29].\nThe latest version of the GPT model by OpenAI is GPT-4\nwhich is a multimodal big language model. It was launched\non March 14, 2023, and is now accessible to the general\npublic through ChatGPT Plus in a constrained capacity. A\nwaitlist is required to gain access to the business API [10].\nUsing both public data and \u201ddata licensed from third-party\nproviders,\u201d GPT-4 was pre-trained to anticipate the next coin as\na transformer. It was then adjusted with reinforcement learning\nbased on input from humans and AI for human alignment\nand policy conformance. In comparison to GPT-3, which had\ncontext windows of only 4096 and 2049 tokens, respectively,\nthe group created two variants of GPT-4 with context windows\nof 8192 and 32768 tokens.\nC. GPT model\u2019s architecture\nGPT models are based on neural networks that are used for\nNLP tasks, such as language modelling, text classi\ufb01cation,\nand text generation.\nThe GPT model\u2019s architecture is based on the transformer", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3640, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "d1e24863-0ebc-4e86-b9bb-b1685dc1ef96": {"__data__": {"id_": "d1e24863-0ebc-4e86-b9bb-b1685dc1ef96", "embedding": null, "metadata": {"page_label": "7", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "07ac71b4-c757-4ee8-8124-a1b240204ab3", "node_type": "4", "metadata": {"page_label": "7", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "hash": "eb41f3082a2f2679b97973801d6fd8b11aa627f14a60ad17fef00e1e5bb38692", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "5422f5e2-c0e8-42ea-a1ba-6b0d12d47895", "node_type": "1", "metadata": {}, "hash": "faa4261d9cd9e8519074c336325b9564d0eecef5f54f035ba3c61699e59aa53b", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "7\nmodel [30]. The Transformer model uses self-attention\nmechanisms to process input sequences of variable length,\nmaking it well-suited for NLP tasks. GPT simpli\ufb01es the\narchitecture by substituting encoder-decoder blocks with\ndecoder blocks. GPT model takes the transformer model and\npre-trains it on large amounts of text data using unsupervised\nlearning techniques. The pre-training process involves\npredicting the next word in a sequence given the previous\nwords, a task known as language modelling. This pre-training\nprocess enables the model to learn representations of natural\nlanguage that can be \ufb01ne-tuned for speci\ufb01c downstream\ntasks [31]. The following are the components of the GPT\narchitecture.\n\u2022 Input Embedding layer: The embedding layer maps the\ninput tokens (e.g., words or subwords) to continuous\nvector representations, which can be processed by the\ntransformer blocks [32].\n\u2022 Positional encoding: Since the transformer blocks do not\nhave any notion of order or position, positional encoding\nis added to the input embeddings to provide information\nabout the relative position of tokens. Masking: In some\ncases, masking may be necessary to mask certain input\ntokens (e.g., in language modelling tasks, the model\nshould only use tokens that come before the target\ntoken). Transformer blocks: GPT models are based on\nthe transformer architecture. It is designed for NLP tasks\nand has been widely used in applications such as ma-\nchine translation, text classi\ufb01cation, and text generation.\nTransformers allow the model to focus on different areas\nof the input while processing [33].\n\u2022 Linear and Softmax Functions: In the GPT architecture,\nthe softmax function is commonly used for classi\ufb01cation\ntasks. The softmax function is applied to the output of\nthe \ufb01nal layer of the model. It generates a probability\ndistribution over a set of output classes. The output of\nthe \ufb01nal layer is speci\ufb01cally converted into a set of\nlogits before being normalized with the softmax function.\nThe normalized values obtained from the model can\nbe interpreted as the likelihood or probability that a\nparticular input belongs to each of the output classes. The\nquery, key, and value vectors for each token in the input\nsequence are frequently calculated using linear functions\nin the attention mechanism. The output of the multi-\nhead attention layer is transformed using them in the\nfeedforward layers as well. The output layer also employs\nlinear functions to forecast the following token in the\nsequence [34].\n\u2022 Pre-training: Pre-training is a key component of the\nGPT architecture. In pre-training, the model is trained\non a large amount of data in an unsupervised manner\neven before \ufb01ne-tuning the model for speci\ufb01c tasks like\nclassi\ufb01cation and text generation.\n\u2022 Fine-tuning: Fine-tuning is the process of adapting a pre-\ntrained neural network model, such as GPT, to a new\ntask or dataset by further training the model on that\ntask or dataset. Fine-tuning in GPT involves adjusting\nthe parameters of the pre-trained model to optimize\nperformance on a speci\ufb01c downstream task, such as text\nclassi\ufb01cation or text generation [35].\n\u2022 Language modeling: Language modelling is a key task in\nthe GPT architecture. In the case of GPT, the language\nmodelling task is performed during the pre-training phase\nof the model. In pre-training, the model is trained based\non a large amount of data using a language model\nobjective. It is the task of predicting the next word in\nsequence based on the previous words. It allows the\nmodel to learn relationships between the words and their\nmeaning in the training data [36].\n\u2022 Unsupervised learning: Unsupervised learning is an ML\nalgorithm which enables the model to learn form unla-\nbelled data without any human intervention. GPT models\nuse unsupervised learning in the pre-training phase to\nunderstand the relationships between the words and their\ncontext in the training data [37].\nD. How do GPT models work?\nGPT models work by using a transformer which is a neural\nnetwork architecture that processes the input sequences of\nnatural language text [38]. The GPT model uses unsupervised\nlearning techniques to pre-train this transformer architecture\non a signi\ufb01cant amount of text input [39]. The model gains\nthe ability to anticipate the subsequent word in a sequence\nbased on the preceding words during pre-training.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 4354, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "5422f5e2-c0e8-42ea-a1ba-6b0d12d47895": {"__data__": {"id_": "5422f5e2-c0e8-42ea-a1ba-6b0d12d47895", "embedding": null, "metadata": {"page_label": "7", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "07ac71b4-c757-4ee8-8124-a1b240204ab3", "node_type": "4", "metadata": {"page_label": "7", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "hash": "eb41f3082a2f2679b97973801d6fd8b11aa627f14a60ad17fef00e1e5bb38692", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "d1e24863-0ebc-4e86-b9bb-b1685dc1ef96", "node_type": "1", "metadata": {"page_label": "7", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "hash": "9b77a145083df68ded3e224583f3998ceedd9a4811a39d26a3493f35666d3b28", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "It allows the\nmodel to learn relationships between the words and their\nmeaning in the training data [36].\n\u2022 Unsupervised learning: Unsupervised learning is an ML\nalgorithm which enables the model to learn form unla-\nbelled data without any human intervention. GPT models\nuse unsupervised learning in the pre-training phase to\nunderstand the relationships between the words and their\ncontext in the training data [37].\nD. How do GPT models work?\nGPT models work by using a transformer which is a neural\nnetwork architecture that processes the input sequences of\nnatural language text [38]. The GPT model uses unsupervised\nlearning techniques to pre-train this transformer architecture\non a signi\ufb01cant amount of text input [39]. The model gains\nthe ability to anticipate the subsequent word in a sequence\nbased on the preceding words during pre-training. Language\nmodelling is the process that enables a model to discover\nthe statistical connections between words and their context\nin training data. Fig. 5 shows the various stages of GPT\noperation. The \ufb01rst step entails supervised \ufb01ne-tuning, the\nsecond step involves producing optimal responses to input,\nand the third step involves proximal policy optimization and\nreinforcement learning.\nThe model can be \ufb01ne-tuned for particular tasks, like text\nclassi\ufb01cation or text production, after pre-training. The model\nis trained on a smaller dataset that is unique to the work at hand\nduring \ufb01ne-tuning, and the model\u2019s parameters are changed\nto maximize performance on that task [8]. Fig. 3 shows the\ngeneral transformer architecture of GPT.\nWhen used for text creation, GPT models create text by\nanticipating the following word in a series based on the\npreviously created words. Depending on how it has been\nmodi\ufb01ed, the model can produce text that is comparable to\nthe input text or that adheres to a certain theme or style. Fig.\n4 projects the GPT model\u2019s transformer architecture and input\ntransformations for \ufb01ne-tuning different tasks.\nE. Comparisons of GPT Versions\nThere are several versions of GPT models each having their\nown features and capabilities. Table III presents a comparison\nof various versions of the GPT models. The table presents\nthe following details like year of release of the GPT model,\nparameters, tokens generated, input type, features of each\nmodel, drawbacks of each model, and the size of each model.", "mimetype": "text/plain", "start_char_idx": 3502, "end_char_idx": 5881, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "c7837b45-8ace-437a-bdfc-def98f479236": {"__data__": {"id_": "c7837b45-8ace-437a-bdfc-def98f479236", "embedding": null, "metadata": {"page_label": "8", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "f65f9461-731e-4942-9cec-9171159ebc40", "node_type": "4", "metadata": {"page_label": "8", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "hash": "d6d24e7412cf7a625a7c860b280c1b561e399c8f511a0c0ce13f3eef85f82611", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "252343ae-4dfc-461f-8a84-aed39aa67153", "node_type": "1", "metadata": {}, "hash": "e910706387a2f8339b77b089a5412ae16dd64d0f1359c86e099ff1e83a8e6ee0", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "8\nTABLE III\nCOMPARSION OF DIFFERENT VERSIONS OF GPT MODEL\nModel Tokens Size Parameters Dataset Year Features Input Type Drawbacks\nGPT-1 - 12-layer decoder 117M parametersBooks corpus 2018 Used mostly for lan-\nguage modelling tasks\nand it is transformer\nbased\nA sequence of tokens\nand words\nLimited Capacity, Limited\nData, Cannot perform complex\ntasks, Limited applications\nGPT-2 - 10 times the size\nof GPT-1\n1.5B parameters Downstream task\ndatasets\n2019 Text generation capa-\nbilities are improved\nand a chance for misuse\nA sequence of tokens\nand words\nLimited Control, Limited Data\nDiversity, Expensive computa-\ntional requirements, Risk of\nimproper information\nGPT-3 4096 and 2049\ntokens\n100 times larger\nthan GPT-2\n175B parameters Common Crawl 2020 Good NLP capabilities,\nlanguage translation,\nsummarization and\ngeneration of text\nA sequence of tokens\nand words and images\nand tables\nLimited Control, Limited Data\nDiversity, Lack of explanation,\nEthical concerns\nGPT-3.5 maximum token\nlimit of 4096 to-\nkens\n96 layers similar or larger\nnumber of\nparameters like\nGPT-3\n- 2022 Improves user experi-\nence by delivering more\nprecise and contextu-\nally relevant informa-\ntion\nThe input type typi-\ncally consists of text\ndata\nLimited resources to train,Data\nBias,Lack of Explain-\nability,Limited Contextual\nUnderstanding,High Inference\nLatency\nGPT-4 8192 and 32768\ntokens\n- 100T parameters - 2023 Creative and technical\nwriting tasks\nA sequence of tokens\nand words and images\nand tables\n-\nGenerative AI (GAI) models are of different types like uni-\nmodal, cross-modal, and multimodal. The \ufb01rst type is uni-\nmodal which rely on a single type of input, such as text\nor images. The cross-modal, on the other hand, can process\nmultiple types of inputs and relate them to each other. The\nMultimodal is the most complex type of AI as it can process\nand integrate information from multiple modalities, such as\nspeech, text, images, and even physical interactions with the\nenvironment. GPT adopts only unimodal and multimodal types\nwhere ChatGPT is said to be unimodal, while GPT-4 is\nmultimodal. Fig. 6 is an illustration that distinguishes between\nunimodal, cross-modal, and multimodal Generative AI models.\nOverall, GPT models have demonstrated outstanding per-\nformance with NLP, by enhancing each iteration and its pre-\ndecessor\u2019 capabilities. Each model, however, also has its own\nrestrictions and drawbacks, such as restricted output control,\nlack of diverse data, and ethical concerns. While selecting a\nGPT model for a particular task, researchers and developers\nshould carefully take these factors into account [40].\nIn detail, this section describes the evolution, and architecture\nof GPT and compares the different versions and types of GPT.\nIII. E NABLING TECHNOLOGIES\nGPT is a convergence of several technologies. It is enabled\nby the latest technologies like Big data, AI, Cloud Computing,\nEC, 5G and beyond networks, and HCI. In this section, we\nprovide an overview of enabling technologies related to GPT.\nThe major technologies that constitute the GPT models are\ndepicted in Fig. 7.\nA. Big Data\nBig data refers to the vast amounts of structured and\nunstructured data generated by businesses, individuals, and\nmachines. The proliferation of new technologies, such as the\nIoT, has led to an explosion of data production from sources\nlike social media, sensors, and transaction-based systems [41].\nThe emergence of big data has revolutionized the way\norganizations approach data analysis and decision-making.\nThe training provided by this massive amount of data has\nyielded valuable insights for the use of advanced models like\nGPT in the \ufb01eld of NLP [42]. The GPT models utilize DL\nand big data for natural language generation, with GPT-4\nbeing the most advanced model to date [43]. The training\ndata for GPT models typically include millions or even\ntrillions of data from a diverse range of sources, such as\nbooks, articles, websites, and social media platforms.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3969, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "252343ae-4dfc-461f-8a84-aed39aa67153": {"__data__": {"id_": "252343ae-4dfc-461f-8a84-aed39aa67153", "embedding": null, "metadata": {"page_label": "8", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "f65f9461-731e-4942-9cec-9171159ebc40", "node_type": "4", "metadata": {"page_label": "8", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "hash": "d6d24e7412cf7a625a7c860b280c1b561e399c8f511a0c0ce13f3eef85f82611", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "c7837b45-8ace-437a-bdfc-def98f479236", "node_type": "1", "metadata": {"page_label": "8", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "hash": "bf3762252cb93cb3f933a12cd8a32d9e0dd8a57e5c890c13523d92873510ca91", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "7.\nA. Big Data\nBig data refers to the vast amounts of structured and\nunstructured data generated by businesses, individuals, and\nmachines. The proliferation of new technologies, such as the\nIoT, has led to an explosion of data production from sources\nlike social media, sensors, and transaction-based systems [41].\nThe emergence of big data has revolutionized the way\norganizations approach data analysis and decision-making.\nThe training provided by this massive amount of data has\nyielded valuable insights for the use of advanced models like\nGPT in the \ufb01eld of NLP [42]. The GPT models utilize DL\nand big data for natural language generation, with GPT-4\nbeing the most advanced model to date [43]. The training\ndata for GPT models typically include millions or even\ntrillions of data from a diverse range of sources, such as\nbooks, articles, websites, and social media platforms. This\nlarge and diverse training data helps GPT models capture the\nvariations in language usage, making them more accurate\nand effective at NLP tasks. As a result, GPT models may\nbe used for a variety of tasks, including question-answering,\ntext summarization, and language translation [44]. Moreover,\nsince GPT models can learn from a variety of data sources,\nthey can be tuned for certain tasks and domains, making them\nvery adaptive and versatile. GPT model has the potential to\nbe utilized for a variety of activities, including the creation\nof images and videos in addition to its excellent language\nprocessing capabilities [45].\nWhile big data presents numerous bene\ufb01ts to GPT, by\nenabling the models to get trained with large amounts of data,\nit also presents several challenges [46]. GPT is trained on\na variety of data, large amounts of data, and also sensitive\ndata. Thus, ensuring data accuracy, privacy concerns, and\nethical use of data are some of the challenges that must be\nconsidered. However, with the continuous growth of available\ndata, GPT models will become even more advanced and\ncapable of performing increasingly complex tasks [47]. The\nfuture of big data as an enabling technology for GPT models\nis promising, with the potential to revolutionize the \ufb01eld of\nNLP. As technology continues to advance, organizations must\nprioritize ethical considerations and data accuracy to fully\nharness the bene\ufb01ts of big data and GPT models.\nB. Arti\ufb01cial Intelligence\nAI refers to the simulation of intelligent behaviour in\nmachines that are programmed to learn from their experience\nto reason, understand natural language, and perceive their\nenvironment [48]. AI gives machines the ability to sense their\nsurroundings, deal with what they see, handle issues, and", "mimetype": "text/plain", "start_char_idx": 3087, "end_char_idx": 5742, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "2f08b76d-df37-4d22-8715-d6e27ecd2390": {"__data__": {"id_": "2f08b76d-df37-4d22-8715-d6e27ecd2390", "embedding": null, "metadata": {"page_label": "9", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "ccfbbb65-8c20-45bc-9a2c-bb8f38abcff0", "node_type": "4", "metadata": {"page_label": "9", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "hash": "24661e511b180eca837ac8c3607c6a679f64d45d4abf9ae11631f18be12e0936", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "9\nAdd & Norm\nMulti-Head\nAttention \nSoftmax\nLinear \nAdd & Norm\nFeed\nForward \nAdd & Norm\nAdd & Norm\nMulti-Head\nAttention \nMasked Multi-\nHead\nAttention \nInput\nEmbedding \n+\nOutput\nEmbedding \n+\nInputs Outputs\nPositional\nEncoding\nPositional\nEncoding\nOutput\nProbabilities \nAdd & Norm\nFeed\nForward \nFig. 3. Transformer Architecture.\ntake action to reach a particular objective. The importance\nand capability of AI is growing all the time.\nAI enables GPT models to allow machines to comprehend\nand react to human language. There are several ways in which\nAI can continue to help improve GPT and make it more\npowerful and effective in its language generation capabilities\n[49].\nThe following are the several ways through which AI can make\nGPT models more powerful:\n1) Fine tuning\n2) Dialogue generation\n3) Natural language understanding\nGPT\u2019s model performance on particular tasks can be enhanced\nby utilizing AI approaches. For instance, it can be trained on\na large corpus of text from a particular \ufb01eld such as legal\ndocuments or medical literature to better grasp and produce\nlanguage in that \ufb01eld [4]. Considering dialogue generation,\nAI techniques such as reinforcement learning and sequence-\nto-sequence models can be used to enable GPT generate\nmore natural and engaging dialogue in conversational contexts.\nSimilarly, AI techniques such as semantic parsing and named\nentity recognition can be used to help GPT better understand\nthe meaning of language and the relationships between words\nand phrases. This can enable it generate more accurate and\ncoherent language [14].\nThe development and enhancement of GPT model language\nproduction capabilities depend heavily on AI, and GPT\u2019s\ncapabilities will continue to be growing by continuous research\nand development in AI.\nAs GPT models become more advanced, there are growing\nconcerns about the potential for them in reinforcing biases and\npropagate harmful or offensive content [50]. Some of these\nconcerns also include bias which can lead to unintended dis-\ncrimination and unfairness, lack of understanding of the con-\ntext that can lead to misunderstandings or incorrect responses,\npoor data quality can lead to inaccurate or biased models,\nethical concerns like privacy and autonomy [51]. AI models\nlike GPT require signi\ufb01cant amounts of computational power\nto train and run, which can have a signi\ufb01cant environmental\nimpact due to their high energy consumption [52].\nThough AI has a great deal of promise, it\u2019s critical to be aware\nof the underlying issues and make efforts to \ufb01x them to ensure\nthat it is utilized responsibly and morally for GPT.\nC. Cloud Computing\nCloud computing refers to the on-demand availability\nof computer resources, such as storage, processing power,\nand applications, delivered over the internet [53]. The GPT\nmodel\u2019s successes are possible not only because of algorithmic\nevolution but also increased computational capabilities i.e.\nexponential growth in hardware (computational power, storage\ncapacity), cloud computing, and related operational software\n[54]. The applications for cloud and EC working together\nsuch as natural language generation, image completion, or\nvirtual simulations from wearable sensors see that the work\nis made more compute-intensive [55].\nGPT models need a lot of computational power to analyze\na lot of data, and cloud computing offers the scalability\nrequired to cope with demand spikes. Without worrying about\nthe constraints of on-premises hardware, GPT models can\nrapidly and easily scale up or down as needed with cloud\ncomputing [56]. Cloud-based platforms like Amazon Web\nServices (AWS) or Google Cloud Platform (GCP) provide\naccess to distributed computing resources that can be used\nto train GPT. Since cloud computing provides web-based\nsolutions and thereby does not require the purchase and\nmaintenance of costly hardware, it can be a cost-effective\nchoice for a GPT model. By utilizing cloud computing, the\nGPT model can only pay for the computing resources it uses\n[57]. The other added advantage of cloud computing in GPT\nis, it gives GPT models the freedom to access computing\nresources whenever it wants, from any location in the world.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 4162, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "ab3e382c-ffd7-43fe-acf3-18e801ec4b74": {"__data__": {"id_": "ab3e382c-ffd7-43fe-acf3-18e801ec4b74", "embedding": null, "metadata": {"page_label": "10", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "9ace5584-5ddc-4b8b-816b-3894866bea0a", "node_type": "4", "metadata": {"page_label": "10", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "hash": "3cb55643585e7cec75f7bf95039fc775c7c7085ac71b3e63f3eb1b95bb9fd61a", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "10\nLayer Norm\nFeed\nForward \nText & Position\nEmbedded \n+\nLayer Norm\nMasked Multi\nSelf Attention \n+\nText\nPrediction\nTask\nClassifier Start Text Extract Transformer LinearClassification\nStart Premise Delim Transformer LinearEntailment HypothesisExtract\nStart Text 1 Delim Transformer \nLinearSimilarity \nText 2 Extract\nStart Text 2 Delim Transformer Text 1 Extract\nStart Context Delim Answer 1Extract\nStart Context Delim Answer 2Extract\nTransformer Linear\nTransformer LinearMultiple\nChoice\nStart Context Delim Answer NExtract Transformer Linear\nFig. 4. Transformer Architecture and Input Transformations for Fine-Tuning on Different Tasks.\nSupervised fine tuning (Step1) Reward Model (Step 2)\nProximal Policy Optimization (PPO) Reinforcement Learning  (Step 3)\nA pretrained GPT model is used,\nfine-tuned with labelers by creating\na supervised dataset. \n1\n1.1\nThe labelers then wrote an\nappropriate response to the\ninput prompt\u2019s 1.2\nGPT model will be fine-tuned using new supervised dataset1.3\nAfter the model is trained in step 1, In this step it\ngenerates optimal responses to input \nSupervised fine tuning (SFT) model is used, inputs\nare fed to the finetuned model, several responses\nwere generated 2.1\n2\nLabeler provides a reward for each of\nthese outcomes, ranks the outcomes\nfrom best to worst 2.2 2.3\nThis data is used to\ntrain a reward model\nA new prompt is sampled from the\ntrained dataset\n3.1\n3\nThe PPO model is initialized from\nthe supervised policy\n3.2\nThe policy generates the output\n3.3\nThe reward model calculates a\nreward for the output\n3.4\nIn this step unseen input sequences are passed to the clone SFT model, pass the responses\nto the reward model for understanding, how high quality was this response for that input \nThe reward is used to update the\npolicy using PPO\n3.5\nFig. 5. How does GPT Work.\nThis makes GPT models more accessible to users by enabling\nsmooth operation across a variety of gadgets and platforms\n[58]. Cloud computing providers offer high security and\ncompliance standards, which can protect the GPT model and\nits data from online dangers. Cloud service providers also\npossess the knowledge and tools necessary to effectively\naddress security problems and stop data leaks. Cloud-based\nstorage services, such as Amazon S3 or Google Cloud\nStorage, provide scalable and reliable storage for GPT\u2019s data.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2334, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "397b1bc5-ce1c-4267-ab80-2da2a7e5e8fb": {"__data__": {"id_": "397b1bc5-ce1c-4267-ab80-2da2a7e5e8fb", "embedding": null, "metadata": {"page_label": "11", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "f02d1f0a-580c-41db-860e-c054105d3f75", "node_type": "4", "metadata": {"page_label": "11", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "hash": "ed8d7157382f79332721a3ada5fca8bc7564cd497bf8250198e3242c87104506", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "11\nHUMAN\nINSTRUCTION GPT TEXT RESULTS\nData\nInput Output\nUNIMODAL (CHATGPT)\nHUMAN\nINSTRUCTION GPT VISUAL\nRESULTSInput Output\nCROSS MODAL(STABLE DIFFUSION 2.1)\n INSTRUCTION 1\n INSTRUCTION 2\n INSTRUCTION 3\nPre-\ntraining\nPre-\ntraining\nPre-\ntraining\nTEXT RESULTS\nVISUAL\nRESULTS\nAUDIO RESULTS\nHuman\nInstructions\nMULTI-MODAL Results\nData\nData\nGPT\nInput\nOutput\nFig. 6. A comparison between unimodal, cross-modal, and multimodal modal GPTs.\nKey\nenabling\ntechnologies\nBig Data\nArtificial\nIntelligence\nCloudComputing\nEdge\nComputing\n5G &\nBeyond\nHCI\nMassive data for training\nImproves model accuracy\nfor training\nFine tuningFaster data transmission\nImproved connectivity\nLower latency\nImproved input quality\nEnhanced user experience\nEnhances the usability of \nGPT models\nReduced latency\nCost effective\nSecurity and\ncompliance\nLow bandwidth usage\nProvides scalability for GPT\nmodels \nCost effective option\nSecurity and compliance \nFlexibility\nGood computational\npower\nModel Optimization\nHelps in deployment of\nvarious application\nFig. 7. Enabling technologies of GPT models.\nDespite the advantages of cloud computing where it can\nhelp GPT models to operate more ef\ufb01ciently, effectively, and\nsecurely, there are also a few technological aspects where it\ncreates a drawback for GPT [59]. To function properly, the\nGPT model needs a sizable amount of computing power and\ndata storage. These resources can be accessible online with\ncloud computing. As a result, continued operation of the GPT\nmodel requires a robust and dependable internet connection,", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 1534, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "f2d9276d-c9b9-4337-a30a-309320501f8f": {"__data__": {"id_": "f2d9276d-c9b9-4337-a30a-309320501f8f", "embedding": null, "metadata": {"page_label": "12", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "ac38aec3-0a63-4149-9cd9-65ea511cddd9", "node_type": "4", "metadata": {"page_label": "12", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "hash": "d1704237621f4642272818e81f5fb5f9d7d0d3132e3f483dd5fbb0dd9d9294a4", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "874d0fb0-3e00-4bdb-a433-fa73656c6b55", "node_type": "1", "metadata": {}, "hash": "b8073cd2baaec3f96187f2789a5e511463cb65ca7cbb6b05874fca908db6c0bd", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "12\nand any breakdown in connectivity may result in delays or\neven data loss. There are some security concerns when storing\nsensitive data, such as personal information or trade secrets, in\nthe cloud which can be risky if proper security measures are\nnot in place [54]. While cloud computing can be more cost-\neffective than building and maintaining an in-house computing\ninfrastructure, it can still be expensive for long-term use. It also\nsuffers issues like performance variability, limited availability\netc.,\nD. Edge Computing\nThe rapid growth of IoT, a large amount of data from\nseveral IoT devices, and also cloud services have necessitated\nthe emergence of a concept called EC. EC is an open AI\nand distributed design with decentralized computational\npower. In EC, there is a lesser need for clients and servers to\ncommunicate over long distances, which lowers latency and\nbandwidth utilization.\nInstead of depending on centralized data centers, EC entails\nbringing computing capacity and data storage closer to the\nconsumer [60].\nIn GPT, where there is a need for real-time data analysis, EC\nplays a major role in faster processing and better ef\ufb01ciency in\nproducing good results [61]. GPT models are typically large\nand complex, requiring signi\ufb01cant processing power to run.\nBy deploying GPT models on the edge devices, closer to the\nsource of data, latency can be reduced in replying to users\nwho seek information through the GPT models by eliminating\nthe need to move data back and forth from end devices to\nthe cloud. Since EC maintains data near the periphery and\naway from centralized servers, it can offer improved security\nand more privacy protections in the case of the requests\nmade by users through GPT [62]. GPT models utilize a lot\nof data for learning and thereby the cost of data transfer\nalso increases with data volume. EC can aid in controlling\ndata transfer expenses. EC can also help in lowering the\namount of bandwidth by pre-processing the data even before\ntransferring it to the cloud. Particularly when analyzing photos\nor videos, GPT models can produce a lot of data [63]. EC\naccelerators, such as graphics processing units (GPUs) and\n\ufb01eld-programmable gate arrays (FPGAs), can be used to speed\nup GPT model inference and training. These accelerators can\nbe integrated into edge devices or edge servers, providing more\nef\ufb01cient processing of GPT models.\nEC and GPT models make a great combination. Comparative\nto cloud data centres, edge devices may have constrained\ncomputation and storage capabilities [64]. This might limit the\nscope of GPT models that can be installed on edge devices in\nterms of size and complexity. Since GPT models handle large\nand varied data, EC can also increase security risks and data\nprivacy concerns. Implementing EC in existing infrastructure\ncan be dif\ufb01cult and require signi\ufb01cant investment in hardware,\nsoftware, and networking components. This can be a barrier\nfor many organizations which are using the GPT model and\nEC [65].\nE. 5G and beyond networks\n5G networks represent the latest generation of cellular\nnetworks that promise faster data speeds, lower latency, and\nthe ability to connect a vast number of devices simultaneously\n[66]. 5G and beyond networks enable faster data transmission\nspeeds than previous generations of cellular networks,\nwhich can help in training and deploying larger and more\ncomplex language models. This can result in faster training\ntimes and better performance. 5G and beyond networks\ncan provide lower latency than previous generations of\ncellular networks, which can reduce the time required for\ncommunication between GPT and other devices, such as\nservers or other language models [67]. This can improve\nthe real-time response of the GPT model for applications\nthat require quick and accurate language processing. 5G and\nbeyond networks offer improved connectivity options, such\nas increased capacity and more reliable connections, which\ncan help in scaling up the deployment of the GPT model for\nlarge-scale language processing tasks. With the deployment\nof 5G and beyond networks, EC is becoming more prevalent.\nThis means that a GPT model can potentially be deployed\ncloser to the end-user, reducing the latency and improving the\nresponse time for applications that require real-time language\nprocessing [68]. Ultra-Reliable Low-Latency Communication\n(URLLC) is a key feature of 5G networks.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 4398, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "874d0fb0-3e00-4bdb-a433-fa73656c6b55": {"__data__": {"id_": "874d0fb0-3e00-4bdb-a433-fa73656c6b55", "embedding": null, "metadata": {"page_label": "12", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "ac38aec3-0a63-4149-9cd9-65ea511cddd9", "node_type": "4", "metadata": {"page_label": "12", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "hash": "d1704237621f4642272818e81f5fb5f9d7d0d3132e3f483dd5fbb0dd9d9294a4", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "f2d9276d-c9b9-4337-a30a-309320501f8f", "node_type": "1", "metadata": {"page_label": "12", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "hash": "d737211f47d6111b0c9e461b773400fc76d2229b9bde4516b7243e17f2f9e69a", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "5G and beyond networks\ncan provide lower latency than previous generations of\ncellular networks, which can reduce the time required for\ncommunication between GPT and other devices, such as\nservers or other language models [67]. This can improve\nthe real-time response of the GPT model for applications\nthat require quick and accurate language processing. 5G and\nbeyond networks offer improved connectivity options, such\nas increased capacity and more reliable connections, which\ncan help in scaling up the deployment of the GPT model for\nlarge-scale language processing tasks. With the deployment\nof 5G and beyond networks, EC is becoming more prevalent.\nThis means that a GPT model can potentially be deployed\ncloser to the end-user, reducing the latency and improving the\nresponse time for applications that require real-time language\nprocessing [68]. Ultra-Reliable Low-Latency Communication\n(URLLC) is a key feature of 5G networks. In the context\nof GPT language models, URLLC can enable real-time and\nreliable communication between multiple devices, such as\nedge devices, cloud servers, and end-users [69].\nThough 5G and beyond technology offers potential advan-\ntages to GPT models, it is also important to note that the actual\nimpacts of this technology may change depending on how it\u2019s\nimplemented and used. 5G enables the access to uncontrolled\naccess to the Internet,it may attract cybersecurity risks and\nprivacy concerns [70]. Also, as GPT uses a large amount of\ndata for analysis it could also cause privacy concerns. 5G\nand beyond networks in GPT models need high infrastructural\nrequirements which is a costly process.\nF . Human Computer Interaction\nHCI, which is multi-faceted, concentrates on the design of\ncomputer technology and, in particular, on how people and\ncomputers communicate with each other [71].\nHCI has a greater in\ufb02uence over GPT models. As a\nlanguage model, GPT is designed to interact with humans\nby generating natural language responses to input text. HCI\nresearch can help designers create more effective input\nmechanisms for the GPT model, such as natural language\ninterfaces, that allow users to communicate more easily and\naccurately with the model [72]. HCI also helps in enhancing\nthe GPT model\u2019s user experience by creating interfaces that\nare more intuitive and user-friendly. This makes it easy for\nthe users to interact with GPT models and understand their\nresponses [73]. HCI also estimates the performance of GPT\nmodels by evaluating their responses with real-time users\nand identi\ufb01es the areas where the model needs improvement,", "mimetype": "text/plain", "start_char_idx": 3463, "end_char_idx": 6039, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "74072635-7a7b-4b0b-b46d-49dd2bedca98": {"__data__": {"id_": "74072635-7a7b-4b0b-b46d-49dd2bedca98", "embedding": null, "metadata": {"page_label": "13", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "6bb2dc81-714d-49af-942e-afe3611e8e91", "node_type": "4", "metadata": {"page_label": "13", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "hash": "4ab583dc6354cf0d310299a247cb212b1fe5ad6bb8771ca2414060c794bc0819", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "d636174b-d028-4789-a77f-5fb695a0a775", "node_type": "1", "metadata": {}, "hash": "4cf430a662f8dac6d9efcad5c518d8b231425a07857326c6f3884b9ca5e107ae", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "13\nthereby improving its reliability and accuracy. HCI enhances\nthe usability of GPT models by reducing the time and effort\nrequired for the users to interact with [74].\nWhile HCI can be incredibly helpful in improving the de-\nsign and usability of GPT models, there are also some potential\ndrawbacks to consider. If the research is not conducted with\na diverse group of users, HCI can introduce biases into the\ndesign of the GPT model. HCI techniques can be expensive\nand time-consuming. As GPT models become more complex,\nit may become more dif\ufb01cult to design interfaces and input\nmechanisms that are both effective and user-friendly [75]. HCI\nmay not always be able to provide the necessary insights or\nfeedback to drive improvements in GPT models. There are\nalso ethical concerns around the use of GPT models, including\nissues related to privacy, bias, and the potential misuse of\nthe technology [76]. As GPT models become more complex,\nit may become more dif\ufb01cult to design interfaces and input\nmechanisms that are both effective and user-friendly.\nIV. I MPACT OF GPT MODELS ON VARIOUS APPLICATIONS\nGPTs have made signi\ufb01cant progress, and its impact is\nbeing felt across various industries like education, healthcare,\nindustry, agriculture, travel and transport, e-commerce, en-\ntertainment, lifestyle, gaming, marketing, and \ufb01nance. This\nsection provides valuable insights on the impact of the GPT\nmodels in the aforementioned applications as depicted in Fig.\n8.\nA. Education\n1) Introduction: Education has been around for centuries,\nwith traditional education being the most common form.\nTraditional education involves a teacher imparting knowledge\nto a group of students in a physical classroom. While suc-\ncessful, traditional education can be restrictive and in\ufb02exible,\nlimiting students\u2019 ability to learn at their own pace and in\ntheir preferred style. It can also be limited by geography, as\nstudents need to be physically present in a classroom to learn.\nTechnology has emerged as a solution to some of these issues,\nallowing for personalized learning experiences and more en-\ngaging, accessible resources. Online learning platforms, digital\ntextbooks, and multimedia tools offer students access to a vast\narray of resources from anywhere in the world. Technology\ncan also facilitate collaboration and communication among\nstudents and teachers, leading to a more dynamic and inter-\nactive learning experience. Distance learning, hybrid learning\nmodels, and online classes are examples of how technology\ncan help break down the barriers of traditional education,\nmaking learning more \ufb02exible, ef\ufb01cient, and effective. By\nintegrating technology into traditional education, we can create\na more personalized and effective learning experience, bene-\n\ufb01ting students worldwide.\n2) Impact of GPT in Education: The \ufb01eld of education is\nconstantly evolving, with advancements in technology playing\na signi\ufb01cant role in shaping the way we learn and teach.\nOne such technology that has the potential to transform the\neducation industry is GPT. As a large language model trained\non a vast amount of data, GPT can generate human-like text\nthat is coherent and informative, making it a valuable tool\nin developing educational content such as textbooks, study\nguides, and course materials. Furthermore, GPT can be used to\nanalyze and summarize complex text, which can help educa-\ntors and students save time and increase comprehension. With\nits ability to support NLP applications and create intelligent\ntutoring systems, GPT has the potential to revolutionize the\nway we learn and teach. In this context, following section\nwill explore the different ways in which GPT can contribute\nto the education industry and transform the future of learning.\n\u2022 Intelligent Tutoring: Intelligent tutoring is a teaching ap-\nproach that uses AI and ML to provide personalized and\nadaptive instruction. It analyzes student performance data,\nunderstands their strengths and weaknesses, and gener-\nates customized learning paths. It provides immediate\nfeedback, personalized guidance, and remedial support.\nIt is effective in improving learning outcomes, increasing\nstudent engagement, and reducing learning time. With\nadvanced natural language processing capabilities, GPT\ncan enhance the personalized and adaptive instruction\nprovided by intelligent tutoring systems. It can analyze\nnatural language input from students, enabling intelligent\ntutoring systems to better understand and respond to\ntheir queries, needs, and preferences. It can also gen-\nerate personalized feedback and assessment based on\nthe individual learning progress of each student, helping\nthem to identify and address their knowledge gaps and\nimprove their performance.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 4724, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "d636174b-d028-4789-a77f-5fb695a0a775": {"__data__": {"id_": "d636174b-d028-4789-a77f-5fb695a0a775", "embedding": null, "metadata": {"page_label": "13", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "6bb2dc81-714d-49af-942e-afe3611e8e91", "node_type": "4", "metadata": {"page_label": "13", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "hash": "4ab583dc6354cf0d310299a247cb212b1fe5ad6bb8771ca2414060c794bc0819", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "74072635-7a7b-4b0b-b46d-49dd2bedca98", "node_type": "1", "metadata": {"page_label": "13", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "hash": "87389ed3d5a88f32bf58440d2257e84060ea0c13ed0909617490d095f6c73091", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "\u2022 Intelligent Tutoring: Intelligent tutoring is a teaching ap-\nproach that uses AI and ML to provide personalized and\nadaptive instruction. It analyzes student performance data,\nunderstands their strengths and weaknesses, and gener-\nates customized learning paths. It provides immediate\nfeedback, personalized guidance, and remedial support.\nIt is effective in improving learning outcomes, increasing\nstudent engagement, and reducing learning time. With\nadvanced natural language processing capabilities, GPT\ncan enhance the personalized and adaptive instruction\nprovided by intelligent tutoring systems. It can analyze\nnatural language input from students, enabling intelligent\ntutoring systems to better understand and respond to\ntheir queries, needs, and preferences. It can also gen-\nerate personalized feedback and assessment based on\nthe individual learning progress of each student, helping\nthem to identify and address their knowledge gaps and\nimprove their performance. GPT can also analyze student\nperformance data and generate adaptive learning paths\nthat provide customized instruction and remediation, en-\nsuring that each student learns at their own pace and\nachieves their learning objectives. Additionally, it can\ncreate interactive dialogue systems that simulate natural\nconversations between students and virtual tutors, making\nlearning more engaging, interactive, and personalized\n[77]. The authors in [76] have identi\ufb01ed that GPT-4 model\noutperforms general-purpose GPT-3.5 model as well as\nGPTs (Med-PaLM, a prompt-tuned version of Flan-PaLM\n540B) specailly trained on medical data. The authors\nhave tested GPT-4 models\u2019 ability to explain medical\nreasoning, personalize explanations to students, and in-\nteractively craft new counterfactual scenarios around a\nmedical case.\n\u2022 Learning assistance and material development: Learning\nmaterials are critical in education as they provide a\nstructured way for students to acquire knowledge and\nskills. They can be tailored to meet the needs of diverse\nlearners and make learning more engaging and effective,\nsupporting teachers to create a more dynamic and interac-\ntive learning environment. GPT can contribute to creating\nlearning materials by automating content generation, pro-\nviding multilingual content creation, language correction,\npersonalized content creation, conducting topic research,\nand generating assessments. It saves time and effort for\neducators and publishers, improves the accuracy and\nreadability of material, and makes learning more engag-", "mimetype": "text/plain", "start_char_idx": 3746, "end_char_idx": 6275, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "95763818-3c38-45cc-b334-b32db4dabd66": {"__data__": {"id_": "95763818-3c38-45cc-b334-b32db4dabd66", "embedding": null, "metadata": {"page_label": "14", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "54332bd4-83e3-434b-9b1b-fa1cacc15342", "node_type": "4", "metadata": {"page_label": "14", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "hash": "cb7b839accc3c7ea36aaad3edbb7d081b61fff7534137f4500f7ab36a8bbc665", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "14\nEducation\nHealthcare\nAgriculture\nLifestyle\nMarketing\nGaming\nEntertainment\nFinance\nIndustry\n           Travel & Transport\nE-Commerce\nContent Creation\nAutomated Assessment\nWriting Assistance\nIntelligent Tutoring\nDrug Discovery\nPatient Diagnosis\nDiesease Prediction\nPersonalized Medicine\nImproving Crop Yield\nPest Control Assistance\nIdentifying Diseases, Data\nAnalysis and Prediction\nDiet Planner\nTravel Guide and Trip Advisor\nPersonalized Cook Book\nHobby Curator\nContent Creation\nCustomer Service\nPersonalized Advertising\nForecast Analysis\nChatbot Development\nGame Content Creation\nNon Playable Character\nSolitude \nEnhanced Customer Interaction\nPersonalized Content Creation\nSentiment Analysis\nFinancial Forecasting\nTrading Strategies\nRisk prediction and Management\nSustainability\nCustomer Service\nAutomated Assitance\nLogistical Management\nIntelligent Fleet Management and\nTracking\nReal-Time Inventory Trackiing \nProof Reading\nOrder Processing\nData Analysis\nEnabling Technologies\nApplications\nBig Data\nArtificial\nIntelligence\nCloud\nComputing\nEdge Computing\n5G &\nBeyond\nHuman Computer\nInteraction\nBenefits of Integrating GPT\nFig. 8. The impact of GPT models on various applications.\ning and effective. GPT can generate high-quality content\nsuch as summaries, quizzes, and lesson plans based on\nspeci\ufb01c learning objectives, making learning accessible\nto a wider audience. It can analyze written content and\nprovide suggestions to improve grammar, punctuation,\nand readability. GPT can also assist in research writing by\nsuggesting ideas for structure, rephrasing and organizing\ncontent, and identifying gaps in research [78]. Moreover,\nGPT can also provide personalized feedback based on in-\ndividual learning progress, enhancing the development of\nmore comprehensive and informative learning materials.\n\u2022 Automated Assessments: Automated assessment in ed-\nucation uses technology to evaluate students\u2019 learning\noutcomes, providing immediate feedback and reducing\npotential bias in grading. It can also help teachers iden-\ntify areas where students may need additional support,\nenabling them to tailor their teaching methods to better\nmeet individual needs. GPT with its advanced natural\nlanguage processing skills, can help in automated as-\nsessment by analyzing and grading student responses\nto various types of assessment questions, including es-\nsays and short answer questions. It can also provide\nfeedback to students [79], such as highlighting areas\nfor improvement and suggesting further reading or re-\nsources. GPT\u2019s natural language processing capabilities\ncan help to identify the meaning and context of students\u2019\nresponses, making automated assessment more accurate\nand effective. Additionally, GPT can generate personal-", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2732, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "111a9ca7-6a44-4f9b-b8fa-2f4d3b4fae1a": {"__data__": {"id_": "111a9ca7-6a44-4f9b-b8fa-2f4d3b4fae1a", "embedding": null, "metadata": {"page_label": "15", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "5a51ab6b-9793-46b3-a18f-c0b471eee741", "node_type": "4", "metadata": {"page_label": "15", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "hash": "927763bdc5de4e7b06e38c63cc058dd38ecc2218ac4e0cdb676675213608439b", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "9f47f532-5a97-4881-bb7e-f9d99fa93652", "node_type": "1", "metadata": {}, "hash": "cf79702b266863a73adc9a0e2f6c5b8a242794a3686e13c8a0fea9fadd466eb6", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "15\nized learning materials and exercises based on students\u2019\nassessment results, supporting educators to create more\ntailored and effective learning experiences. The authors\nin [80] have used Chat GPT in evaluating the students\u2019\nassignments such as quiz style questions, and also in\ngenerating relevant practice problems to improve content\nretention and understanding. The results were promising\nin the classroom. The authors believe that Chat GPT has\nthe signi\ufb01cant ability in reducing the load of instructor\nwithout compromising students\u2019 learning outcomes.\n\u2022 Fostering Creativity: Creativity thinking plays a vital role\nin education by encouraging students to think beyond\ntraditional boundaries and develop innovative solutions to\ncomplex problems. It helps students to approach learning\nwith an open mind and a willingness to explore new ideas,\nleading to greater engagement and motivation. GPT\u2019s\nability to generate human-like responses and creative\nwriting can aid in improving creativity. It can help\nimprove creativity by generating new and innovative\nideas based on vast amounts of data and information.\nBy analyzing patterns in language and identifying con-\nnections between different concepts, GPT can suggest\nnovel approaches to teaching and learning. Additionally,\nGPT can also generate creative prompts or challenges for\nstudents, encouraging them to think outside the box and\napproach problems in unique ways [81]. GPT can also\nanalyze and evaluate students\u2019 creative work, providing\nfeedback and suggestions for improvement. So, GPT can\nbe a valuable tool for promoting and enhancing creativity\namong students and faculty members.\n3) Challenges: There are several advantages to incorpo-\nrating GPTs in education, but it is essential to acknowledge\nthe potential limitations. While GPTs can quickly generate\ninformation, they may impede students\u2019 critical thinking and\nproblem-solving skills. Furthermore, learners who bene\ufb01t from\npersonal interaction with instructors may \ufb01nd the lack of\nhuman involvement disadvantageous. GPTs rely on statistical\npatterns, so they cannot provide a comprehensive understand-\ning of the material being taught [79]. Privacy concerns arise\nwhen using sensitive student data in GPTs for educational\npurposes. Additionally, since GPTs cannot provide citations, it\nis challenging to identify the source of information generated.\nThe cost of maintaining GPT may be prohibitive for schools\nand educational institutions with limited resources. Finally,\ndistinguishing between reliable and unreliable information\ngenerated by GPTs can be dif\ufb01cult, so it is necessary to have\nhuman oversight to ensure data accuracy and regulate access.\n4) Summary: GPT offers numerous advantages in the edu-\ncation sector, including personalized and adaptive instruction,\nautomated assessment, creative writing support, and research\nwriting assistance. They have the potential to revolutionize\nteaching by creating lesson plans and activities, responding\nto natural language queries, and integrating multiple digital\napplications. However, there are also challenges to consider,\nsuch as the potential negative impact on critical thinking and\nproblem-solving skills, lack of human interaction, data security\nand privacy concerns, inability to provide full comprehension,\nlack of citations or sources, high cost of maintenance, and po-\ntential for producing unreliable information. Further research\nis needed to explore human-computer interaction and user\ninterface design to integrate GPT into educational work\ufb02ows\nwhile ensuring that the information they provide is accurate\nand reliable.\nB. Healthcare\n1) Introduction: Before technology became widespread\nin healthcare, healthcare services were primarily delivered\nthrough face-to-face interactions between healthcare profes-\nsionals and patients. Traditional healthcare faced several chal-\nlenges, including limited medical instruments, paper-based\nhealth records, patients receiving care mostly in hospitals\nor clinics, physical travel requirements to receive medical\nattention, and limited medical research. Despite these chal-\nlenges, traditional healthcare still provided valuable medi-\ncal services to patients. However, with the introduction of\ntechnology, healthcare has become more ef\ufb01cient, accessible,\nand personalized, resulting in improved patient outcomes and\nbetter overall healthcare services. Technology has become\nan essential aspect of society, as re\ufb02ected in the signi\ufb01cant\ninvestments made in this sector. Despite the advancements\nin technology, the healthcare industry still faces various new\nchallenges, including access to healthcare, high costs, per-\nsonalized medicine, data privacy and security concerns, and\nan aging population. However, technology has the potential\nto address these challenges and improve the ef\ufb01ciency of\nhealthcare services.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 4846, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "9f47f532-5a97-4881-bb7e-f9d99fa93652": {"__data__": {"id_": "9f47f532-5a97-4881-bb7e-f9d99fa93652", "embedding": null, "metadata": {"page_label": "15", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "5a51ab6b-9793-46b3-a18f-c0b471eee741", "node_type": "4", "metadata": {"page_label": "15", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "hash": "927763bdc5de4e7b06e38c63cc058dd38ecc2218ac4e0cdb676675213608439b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "111a9ca7-6a44-4f9b-b8fa-2f4d3b4fae1a", "node_type": "1", "metadata": {"page_label": "15", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "hash": "e11766a9638fcd3c22f3205a412ab821adcded7c86e86ec02917b5d3a367ed95", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Despite these chal-\nlenges, traditional healthcare still provided valuable medi-\ncal services to patients. However, with the introduction of\ntechnology, healthcare has become more ef\ufb01cient, accessible,\nand personalized, resulting in improved patient outcomes and\nbetter overall healthcare services. Technology has become\nan essential aspect of society, as re\ufb02ected in the signi\ufb01cant\ninvestments made in this sector. Despite the advancements\nin technology, the healthcare industry still faces various new\nchallenges, including access to healthcare, high costs, per-\nsonalized medicine, data privacy and security concerns, and\nan aging population. However, technology has the potential\nto address these challenges and improve the ef\ufb01ciency of\nhealthcare services.\n2) Impact of GPT in healthcare: Recent years have seen\nsigni\ufb01cant advancements in technology, including in the\nhealthcare industry. Biotechnology, medical devices, and phar-\nmaceuticals have undergone transformations through the use\nof cutting-edge technologies like DL [82] and ML [83].\nCurrently, the healthcare sector is utilizing various forms of\nAI techniques for medical research and providing medical\nservices. One such technique is the GPT features of NLP,\nwhich hold immense potential for the healthcare industry.\nGPT can help to overcome several challenges in healthcare\nin multiple ways. For instance, it can be used to develop\nintelligent systems that assist doctors in making accurate\ndiagnoses and providing clinical assistance [84] [85]. GPT\ncan also analyze large volumes of medical data and generate\nreports. Furthermore, it has potential applications in drug\ndiscovery [86] [87], personalized medicine, patient diagnosis,\nmedical image analysis, analyzing electronic health records,\nclinical decision support systems, and disease prediction.\n\u2022 Drug Discovery: Recent AI and machine learning tech-\nniques [88] [89] are having the potential to contribute\nto the growth and development of drug discovery. GPTs\nare capable of learning new patterns and relationships\n[90] in the dataset they were trained on. This capability\ncan be used in drug discovery to aid in the identi\ufb01cation\nand design of potential new drugs with desired properties\n[91]. One of the key challenges in drug discovery is\n\ufb01nding compounds that can interact with speci\ufb01c parts\nof the body. GPT can help in this process by learning\nthe patterns and relationships from large databases of", "mimetype": "text/plain", "start_char_idx": 4085, "end_char_idx": 6516, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "d324e843-8b82-4c70-acf0-a949b51bf423": {"__data__": {"id_": "d324e843-8b82-4c70-acf0-a949b51bf423", "embedding": null, "metadata": {"page_label": "16", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "4c6bccd2-4e2d-40a1-ad0a-0527c721d7cf", "node_type": "4", "metadata": {"page_label": "16", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "hash": "242b6320d7ee0ab579cddccbad888263eb42df8fc3d4ee3699d88b4c28342b2b", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "810801b7-fbee-4cd6-943e-ee6036264a25", "node_type": "1", "metadata": {}, "hash": "fe0d7ba9da021c867d42e9f0d1ca12537f4c94c085963f68ec4eea529db686a7", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "16\nknown compounds [86]. GPT can be trained on large\nsets of chemical databases to analyze chemical reactions\nand their outcomes. This can help suggest potential\ncombinations of new drugs using the analyzed data. These\nnew drugs can also be analyzed using GPT to test their\nef\ufb01cacy and toxicity.\n\u2022 Diagnosis: GPT can be used in medical diagnosis by ana-\nlyzing patient data. It can help to analyze medical records\nand extract information such as patient demographics,\nsymptoms, and medical history. This can help medical\nprofessionals provide effective patient care and improve\noutcomes. The recent release of GPT-4 has the ability to\nsupport multimodal information, allowing it to analyze\nimages as input and produce text results as output [92].\nIt is recommended to use AI systems such as a GPT,\nas clinical support tools to assist medical professionals\nin diagnosing and treating patients, but they should not\nbe relied upon as the sole source of medical advice or\ndecision-making. GPT can also be used to identify rare\ndiseases by analyzing patient\u2019s complete information. The\nauthors in [93] have used a general-purpose GPT based\non GPT-3 model for patient diagnosis and triage. The\nmodel has given a triage accuracy of 70% which was\nworse than a physician. But, in next subsequent weeks,\nthe accuracy has improved to 92% which is close to the\nperformance of a physician. In diagnosis, GPT-3 model\nhas given 88% accuracy. For emergency cases, GPT-3 has\ngiven 75% accuracy whereas physician has given 94%.\n\u2022 Disease prediction: GPT has great potential in disease\nprediction [94]. By analyzing large amounts of medical\ndata, including patient records, medical images, and clin-\nical trials, these pre-trained language models can learn\npatterns and make predictions about the likelihood of\na patient developing a particular disease. For instance,\ntrained healthcare GPTs can be used to predict the\noccurrence of diseases such as diabetes, heart disease,\nand cancer by analyzing various parameters, including\nthe patient\u2019s medical history, age, family history, and\nlifestyle. It can also be used to predict the likelihood of\na rare disease This helps in the early detection of high-\nrisk patients so that medical personnel can take necessary\nmeasures and suitable medicines to reduce the risk of\ndeveloping the disease. The medical practitioner and\nauthor in [95] have recommended using GPT-4 models\u2019\nability of NLP in bariatric surgery.\n\u2022 Personalized medicine: The COVID-19 pandemic has\nhighlighted that not all body systems are clinically sim-\nilar. For instance, during the pandemic, medicines like\nRemdesivir and Tocilizumab have been effective for one\ncategory of patients but do not affect another category\nof patients with similar clinical metrics, as they progress\nfrom a mild or moderate level of infection to a severe\nstage [96]. This highlights the need for personalized\nmedicine in today\u2019s world. GPT can be used to identify\nvariable patterns of data to predict or classify hidden\nor unseen patterns, which can be used for exploratory\ndata analysis. GPT provide the possibility of identify-\ning personalized medicines [97] based on the clinical,\ngenomic, and nutritional data of patients. The dietician\nand the author in [98] have observed that the utilization\nof Chat GPTs has signi\ufb01cantly decreased obesity rates\namong patients by offering personalized recommenda-\ntions regarding nutrition plans, exercise programs, and\npsychological support. This approach allows for the de-\nvelopment of customized treatment plans that cater to the\nspeci\ufb01c needs of individuals, leading to a more ef\ufb01cient\nmethod of treating obesity with the assistance of Chat\nGPT.\n3) Challenges: While GPT is a powerful language model\nwith numerous applications in healthcare, it is not without\nits challenges. The primary challenge is data bias. As GPT\nmodels are also learning models, the signi\ufb01cant drawback of\nbiasing is also applicable to GPT. GPT can be susceptible\nto bias. If the data used to train the model is biased, the\nmodel will learn from it and replicate the bias. This leads to\nincorrect treatment and predictions. Another challenge is the\ntransparency of the model. GPT is complex to understand and\ninterpret.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 4214, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "810801b7-fbee-4cd6-943e-ee6036264a25": {"__data__": {"id_": "810801b7-fbee-4cd6-943e-ee6036264a25", "embedding": null, "metadata": {"page_label": "16", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "4c6bccd2-4e2d-40a1-ad0a-0527c721d7cf", "node_type": "4", "metadata": {"page_label": "16", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "hash": "242b6320d7ee0ab579cddccbad888263eb42df8fc3d4ee3699d88b4c28342b2b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "d324e843-8b82-4c70-acf0-a949b51bf423", "node_type": "1", "metadata": {"page_label": "16", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "hash": "c068b1897cdc477a568f7d8640f076e59ed7f65418d2f71b0cdcc109b4ea26b4", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "This approach allows for the de-\nvelopment of customized treatment plans that cater to the\nspeci\ufb01c needs of individuals, leading to a more ef\ufb01cient\nmethod of treating obesity with the assistance of Chat\nGPT.\n3) Challenges: While GPT is a powerful language model\nwith numerous applications in healthcare, it is not without\nits challenges. The primary challenge is data bias. As GPT\nmodels are also learning models, the signi\ufb01cant drawback of\nbiasing is also applicable to GPT. GPT can be susceptible\nto bias. If the data used to train the model is biased, the\nmodel will learn from it and replicate the bias. This leads to\nincorrect treatment and predictions. Another challenge is the\ntransparency of the model. GPT is complex to understand and\ninterpret. This lack of transparency in technology can make\ndoctors and medical personnel not believe in the predictions,\nwhich may result in a hesitancy to trust and adopt technology\n[99]. Another important concern is security and privacy issues.\nAs it is a model to be trained on data, there is a huge\namount of sensitive information about the patients to be used\nto improve the algorithm and its performance. This results in\nsigni\ufb01cant security and privacy concerns related to the use of\nGPT in healthcare. The \ufb01nal and important challenge is limited\nclinical validation. GPT are showing promising improvement\nin various \ufb01elds of healthcare, such as drug discovery, and\ndisease prediction. But still, their effectiveness and accuracy in\nmedical research and clinical settings have yet to be validated.\nMore research and clinical trials are required to prove that GPT\ncan transform the medical industry with full trust.\n4) Summary: GPT have the potential to revolutionize the\nhealthcare industry by contributing to drug discovery, per-\nsonalized medicine, clinical support in making decisions,\ndiagnosis support, and disease prediction. This can be helpful\nfor human beings to predict the disease in advance and treat\nit through proper medicine. However, there are signi\ufb01cant\nchallenges that are to be addressed, such as technology adop-\ntion, data bias, regulatory challenges, and security and privacy\nissues. It is so important to analyze and evaluate the bene\ufb01ts\nand risks of using GPT in healthcare and to continue to\nmonitor their development and implementation.\nC. Industry\n1) Introduction: An important economic transition from\nagriculture and handicrafts to large-scale industry and auto-\nmated production was achieved by the industrial revolution.\nEf\ufb01ciency and productivity were raised as a result of modern\nequipment, energy sources, and labour arrangements. New\nopportunities and challenges have been created as a result\nof the quick development of new technologies in both the\nworkplace and other industries [100]. The utilization of big\ndata is a well-known technology-driven trend. Nowadays,\ncompanies have access to enormous volumes of data that", "mimetype": "text/plain", "start_char_idx": 3460, "end_char_idx": 6367, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "c89036c3-e386-45df-a657-c7b4bb8c5e49": {"__data__": {"id_": "c89036c3-e386-45df-a657-c7b4bb8c5e49", "embedding": null, "metadata": {"page_label": "17", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "2ebcfe31-8007-414d-b2c2-d46f1534c625", "node_type": "4", "metadata": {"page_label": "17", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "hash": "6b2a671f7c17846ad89bdebbc7c7ef627669ac26d9505355457810391b29afa2", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "df849252-73c8-4ce6-9233-c8333629921a", "node_type": "1", "metadata": {}, "hash": "83c0d228261b5c6c8524ab4f9b339857bbc23dc5d2ead02906c0977742249214", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "17\nmay be examined to uncover insightful information. Big data\ncan help businesses make wise decisions and discover areas\nfor development. AI is another innovation that is changing\nindustries. AI systems have the ability to analyse complex\ndata, automate procedures, and make wise conclusions [101].\nThis improves production by increasing its dependability,\nadaptability, and ef\ufb01ciency. The process of \u201ddigitalization,\u201d\nwhich includes incorporating digital technologies into every\nelement of business, is creating industries to become more\n\ufb02exible, ef\ufb01cient, and valuable. Businesses may automate\ntedious work, improve client experiences, and streamline oper-\nations by implementing digital solutions. In today\u2019s digitally-\ndriven world, adopting technological advancements is essential\nfor maintaining competitiveness and promoting growth.\n2) Impact of GPT in Industry: In industrial scenarios, GPT\nhas the potential to be applied as a sustainability tool, assisting\nbusinesses in evaluating and enhancing their sustainability\ngoals. Companies can improve supply chain tracking and\nquery response by integrating pre-trained transformer models\nlike ChatGPT with supply chain management platforms [102].\nAdditionally, GPTs can offer modi\ufb01cations to the production\nprocess that might increase ef\ufb01ciency [103]. GPT can also\nhelp users make knowledgeable decisions about how to use\nresources, allowing businesses to remain competitive while\nreducing their environmental effect. For example, the GPT-\n2 model has demonstrated ef\ufb01cacy in sentiment analysis,\nproviding insightful data for numerous applications [104].\n\u2022 Hospitality sector In the hospitality industry, hotels place\na high focus on providing satisfying guest experiences.\nTo ensure that every tourist is satis\ufb01ed during their\nstay, this necessitates adapting to their requirements and\npreferences. Hotels may improve the guest experience\nin a number of ways by integrating GPT into their\nwebsite or mobile application. Hotels may respond to\nconsumer inquiries in a timely and precise manner by\nutilizing GPT [105]. Customers do not have to wait for\nhuman assistance when looking up information about\nfacilities, booking procedures, or room availability. Cus-\ntomers\u2019 overall satisfaction with the hotel\u2019s services is\nincreased as a result of the large reduction in client wait\ntimes. GPTs can also make it easier for visitors who\nspeak multiple languages to communicate [106]. Hotels\ncan offer a more inclusive and welcoming experience\nfor visitors from other countries by removing linguistic\nobstacles. Hotels may provide their visitors with immer-\nsive and engaging experiences by combining GPT with\nAR technologies. For instance, customers can use their\nmobile devices to get AR guided tours of the hotel or\nnearby attractions, offering a distinctive and entertaining\nway to explore the surroundings and learn more about the\nhotel\u2019s amenities.GPTs integration into various aspects of\nthe hospitality industry gives hotels the ability to deliver\nstreamlined, tailored, and effective services, increasing\nclient happiness and loyalty.\n\u2022 Fashion: By providing highly customized user recommen-\ndations based on personal style, brand preferences, and\nparticular clothing or accessory demands, collaborative\n\ufb01ltering and AI algorithms have undoubtedly revolution-\nized the fashion business. The amount of personaliza-\ntion has been further increased in this context by the\nincorporation of GPT, dramatically altering the purchas-\ning experience for customers [107]. Fashion platforms\nmay analyse a signi\ufb01cant quantity of user data, such as\nbrowsing history, purchasing behaviour, and style prefer-\nences, using the advanced capabilities of GPT to produce\ntailored recommendations. Fashion platforms can direct\nconsumers towards clothing options that \ufb01t their desire\nfor sustainable fashion by including eco-friendly fabric\nselections into the system. GPT improve users\u2019 general\nfashion knowledge and con\ufb01dence while enabling users\nto keep up with the most recent trends. The image-text\nretrieval skills of GPT signi\ufb01cantly improve visual search\ncapability in fashion platforms [108]. Users may make\nmore con\ufb01dent shopping decisions and minimize the need\nfor returns by visualizing how various clothing items\nand accessories would appear on them without physically\ntrying them on. The model may recommend the proper\nsize for various brands and apparel products by taking\ninto account a user\u2019s measurements, preferred \ufb01t styles,\nand historical data. The overall purchasing experience is\nenhanced and the frustration of wrong size is decreased.\n\u2022 Sustainability: Sustainable development means address-\ning current demands without sacri\ufb01cing the capacity of\nfuture generations to address their own needs.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 4755, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "df849252-73c8-4ce6-9233-c8333629921a": {"__data__": {"id_": "df849252-73c8-4ce6-9233-c8333629921a", "embedding": null, "metadata": {"page_label": "17", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "2ebcfe31-8007-414d-b2c2-d46f1534c625", "node_type": "4", "metadata": {"page_label": "17", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "hash": "6b2a671f7c17846ad89bdebbc7c7ef627669ac26d9505355457810391b29afa2", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "c89036c3-e386-45df-a657-c7b4bb8c5e49", "node_type": "1", "metadata": {"page_label": "17", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "hash": "319332931b5a6207d3e7078825914542929c3d68cf1c071d410afec429c04570", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "GPT improve users\u2019 general\nfashion knowledge and con\ufb01dence while enabling users\nto keep up with the most recent trends. The image-text\nretrieval skills of GPT signi\ufb01cantly improve visual search\ncapability in fashion platforms [108]. Users may make\nmore con\ufb01dent shopping decisions and minimize the need\nfor returns by visualizing how various clothing items\nand accessories would appear on them without physically\ntrying them on. The model may recommend the proper\nsize for various brands and apparel products by taking\ninto account a user\u2019s measurements, preferred \ufb01t styles,\nand historical data. The overall purchasing experience is\nenhanced and the frustration of wrong size is decreased.\n\u2022 Sustainability: Sustainable development means address-\ning current demands without sacri\ufb01cing the capacity of\nfuture generations to address their own needs. Goals for\nsustainable development can be attained by implementing\nGPTs in a variety of sectors, including manufacturing\nand corporate operations [109]. The models can estimate\nwhere energy saving measures would be most useful\nby analyzing past data and patterns to provide insights\ninto energy usage, pinpoint problem areas, and recom-\nmend opportunities for improvement. GPTs can aid in\nidentifying sustainability-related problems, creating plans\nand strategies to solve them, investigating brand-new\nsustainable activities, keeping track of advancements,\nand conducting routine reviews. Companies can choose\nactivities that will have the biggest positive impact by\ngrading tasks and actions according to their impact on\nsustainability [110]. The models can optimize supply\nchains for decreased carbon emissions, minimized waste,\nand improved resource ef\ufb01ciency by assessing elements\nincluding transportation routes, packaging materials, and\nsupplier practises [111]. This results in more environ-\nmentally friendly production, distribution, and sourcing\nprocedures.\n3) Challenges: There are many different industrial \ufb01elds\nwhere GPT models can be applied; the three areas mentioned\nabove are only a few. However, for optimal use, the industrial\nsector needs to be ready to adapt to a constantly changing\nenvironment. Public and corporate policies must be developed\nover the long term to promote the use of sustainable production\ntechniques. For enterprises, deploying pre-trained GPT models\ncan be a costly task. Continuous development and training are\nalso required to accommodate new and evolving inquiries as\nclient expectations change. Companies have to carefully assess\nthe bene\ufb01ts and costs before implementing the GPT model", "mimetype": "text/plain", "start_char_idx": 3906, "end_char_idx": 6488, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "8f892045-1b9b-4bee-8248-3f5d85b5e2fd": {"__data__": {"id_": "8f892045-1b9b-4bee-8248-3f5d85b5e2fd", "embedding": null, "metadata": {"page_label": "18", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "fb85337e-8c32-42bd-93e9-101ce548c238", "node_type": "4", "metadata": {"page_label": "18", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "hash": "398c9aeb25a7848f4cfc18da7468fe3b3b255d62121742318b2476da2c6d1d89", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "f7fbcbed-6040-44b3-8580-853f9770e635", "node_type": "1", "metadata": {}, "hash": "18bae2249ab37cdac906eace70edede0bc738a4dd59bd38827b7c1648e56bb59", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "18\nbecause these continuing efforts raise the deployment cost\n[112]. For industries to fully bene\ufb01t from GPT models, it is\ncrucial to address issues with interpretability, data reliance, and\nethical considerations. Industry may therefore take advantage\nof these GPT models\u2019 advantages, make wise decisions, and\npromote sustainable development.\n4) Summary: GPTs have the ability to have a positive\nimpact on society and business operations. They can speed\nup operations like accounting, sales, and marketing, increasing\nproductivity. But before they are widely used, ethical problems\nneed to be fully investigated. Technology products will change\nas GPT models develop. To reap the bene\ufb01ts and reduce dan-\ngers, it is essential to solve interpretability and data concerns.\nGPTs can have a tremendous positive impact on businesses,\nsociety, and the economy when they are used responsibly.\nD. Agriculture\n1) Introduction: Traditional agriculture, a time-honored\npractice passed down through generations, sustains civiliza-\ntions with its crop cultivation and livestock rearing methods.\nRooted in a deep connection to nature, it emphasizes sustain-\nability and local ecosystem understanding. Beyond providing\nsustenance and livelihoods, traditional agriculture preserves\ncultural heritage. However, it also faces challenges such as\nlabor-intensive processes and shortages, inef\ufb01cient resource\nutilization, vulnerability to pests and diseases, and limited\naccess to real-time data and environmental impact. Today, by\nmerging tradition with modernity, we have the opportunity to\nleverage technological advancements to enhance productivity,\nsustainability, and resilience while honoring the profound\nlegacy of traditional agriculture for future generations.\n2) Impact of GPT in Agriculture : GPTs have the ability\nto overcome the challenges of agriculture. It offers valuable\nadvantages to the agriculture sector. It acts as a comprehensive\nknowledge source, providing information on crop cultivation,\npest management, and soil health. By analyzing real-time data,\nGPT assists farmers in making informed decisions regarding\noptimal planting times and resource allocation. It plays a\ncrucial role in identifying and addressing crop diseases and\npests accurately. Moreover, GPT enables precision farming\npractices by utilizing sensor data and satellite imagery, en-\nsuring precise irrigation, fertilization, and pest control. Ad-\nditionally, it provides market analysis and price prediction,\nempowering farmers to navigate market conditions and opti-\nmize pricing strategies. GPT also supports farm management\nand planning, optimizing crop rotation and resource usage.\nBy facilitating agricultural research and innovation, GPT con-\ntributes to advancements in crop breeding and sustainable\npractices. Embracing GPT in agriculture enhances decision-\nmaking, ef\ufb01ciency, and sustainability, ultimately promoting\nimproved productivity and food security. For instance, GPT-4\ncan educate farmers about new methods and goods and warn\nthem of potential issues or possibilities by analyzing data from\nmany sources [113].\n\u2022 Improving Crop Yields:\nWith its data analysis capabilities and real-time rec-\nommendations, GPTs plays a crucial role in enhancing\ncrop yields. By examining historical yield data, weather\npatterns, soil conditions, and crop management practices,\nGPT identi\ufb01es valuable patterns and correlations, pro-\nviding insights and suggestions for optimal crop man-\nagement techniques [114]. It enables precision farming\nby integrating data from sensors, satellites, and IoT\ndevices, granting timely guidance on resource allocation\nfor improved ef\ufb01ciency. Additionally, GPT aids in the\nearly identi\ufb01cation and management of crop diseases and\npests, minimizing yield losses through precise and prompt\nrecommendations. Moreover, GPT supports crop breeding\nand genetic optimization by analyzing genetic data and\nplant characteristics, expediting the development of high-\nyielding and resilient crop varieties. Therefore, GPTs data\nanalysis and decision support capabilities signi\ufb01cantly\ncontribute to enhancing crop yields and maximizing agri-\ncultural productivity [115].\n\u2022 Pest Control:\nGPT offers signi\ufb01cant support in the realm of pest control\nin agriculture. By analyzing extensive data on pests,\nincluding their behavior, life cycles, and characteristics,\nGPT can provide valuable insights for effective control\nmeasures. It aids in early pest detection by analyzing\nsensor data and satellite imagery, enabling proactive\ninterventions to prevent pest spread and minimize damage\n[116]. GPT also assists in determining suitable pest\ncontrol methods tailored to speci\ufb01c crops and pests,\nconsidering factors like environmental impact and sus-\ntainability.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 4748, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "f7fbcbed-6040-44b3-8580-853f9770e635": {"__data__": {"id_": "f7fbcbed-6040-44b3-8580-853f9770e635", "embedding": null, "metadata": {"page_label": "18", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "fb85337e-8c32-42bd-93e9-101ce548c238", "node_type": "4", "metadata": {"page_label": "18", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "hash": "398c9aeb25a7848f4cfc18da7468fe3b3b255d62121742318b2476da2c6d1d89", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "8f892045-1b9b-4bee-8248-3f5d85b5e2fd", "node_type": "1", "metadata": {"page_label": "18", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "hash": "4aa2c6d8b4acaa70b052a1350d2b2fe4bc3e41d6285a73d8781a637080f11a27", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Moreover, GPT supports crop breeding\nand genetic optimization by analyzing genetic data and\nplant characteristics, expediting the development of high-\nyielding and resilient crop varieties. Therefore, GPTs data\nanalysis and decision support capabilities signi\ufb01cantly\ncontribute to enhancing crop yields and maximizing agri-\ncultural productivity [115].\n\u2022 Pest Control:\nGPT offers signi\ufb01cant support in the realm of pest control\nin agriculture. By analyzing extensive data on pests,\nincluding their behavior, life cycles, and characteristics,\nGPT can provide valuable insights for effective control\nmeasures. It aids in early pest detection by analyzing\nsensor data and satellite imagery, enabling proactive\ninterventions to prevent pest spread and minimize damage\n[116]. GPT also assists in determining suitable pest\ncontrol methods tailored to speci\ufb01c crops and pests,\nconsidering factors like environmental impact and sus-\ntainability. Additionally, it contributes to precision pest\ncontrol by leveraging real-time data to optimize timing\nand dosage of interventions, reducing chemical usage\nand resistance risks. It also aids in identifying natural\nenemies and bene\ufb01cial organisms, promoting natural pest\ncontrol mechanisms such as habitat diversi\ufb01cation and\ncompanion planting. Through GPT\u2019s data analysis and\nrecommendation capabilities, it empowers farmers with\ninformed decisions, leading to more effective and sus-\ntainable pest management strategies, ultimately reducing\ncrop losses and enhancing agricultural productivity.\n\u2022 Identifying Diseases and Soil analysis:\nGPTs offer valuable assistance in disease identi\ufb01cation\nand soil analysis within the \ufb01eld of agriculture. With\nits ability to analyze extensive data sets, GPT can ac-\ncurately identify crop diseases by processing information\nsuch as symptoms, historical data, and disease patterns.\nThis enables timely and effective disease management\nstrategies [114]. Additionally, It plays a signi\ufb01cant role\nin soil analysis by analyzing diverse soil-related data,\nincluding nutrient levels, pH, organic matter content, and\nsoil composition. By interpreting this data, It provides\ninsights into soil health and fertility, empowering farmers\nto make informed decisions regarding nutrient manage-\nment, soil amendments, and cultivation practices. More-\nover, GPT can identify complex interactions between soil\nconditions and crop diseases, helping farmers understand\nthe relationship and take preventive measures accord-\ningly. It also supports precision agriculture practices by\nintegrating sensor data and satellite imagery to assess", "mimetype": "text/plain", "start_char_idx": 3811, "end_char_idx": 6405, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "89df1068-6713-4e14-ac11-1595fb9747c4": {"__data__": {"id_": "89df1068-6713-4e14-ac11-1595fb9747c4", "embedding": null, "metadata": {"page_label": "19", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "558c49cd-b1b2-49d3-aa0e-82328822695e", "node_type": "4", "metadata": {"page_label": "19", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "hash": "beace009f4bed7baee2aa25c1c7451845db9aa4d28d29e237a5598feb78d3699", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "6805d554-1155-4b86-9c58-80aad740ed16", "node_type": "1", "metadata": {}, "hash": "b181c8ce94ddc183244750feea30a00ed6b3e0ce909f690c06ed9f860fb7de07", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "19\nsoil variations across \ufb01elds, allowing for site-speci\ufb01c\nmanagement strategies and optimized resource allocation.\nFurthermore, it also facilitates knowledge sharing and\ncollaboration by analyzing and disseminating research\n\ufb01ndings, best practices, and disease outbreak information\namong agricultural communities. This collective intelli-\ngence enhances disease monitoring and control efforts on\na broader scale.\n3) Challenges: While GPT, provides signi\ufb01cant bene\ufb01ts\nto agriculture, there are challenges to its implementation.\nGPT\u2019s effectiveness depends on the availability and quality\nof data, making insuf\ufb01cient or biased data a limitation. The\ninterpretability of GPT\u2019s decision-making process is challeng-\ning due to its black-box nature, hindering trust and under-\nstanding. GPT\u2019s computational requirements and infrastructure\ncan be demanding, posing dif\ufb01culties for resource-constrained\nfarmers. Language and domain-speci\ufb01c nuances can affect\nits performance, impacting accuracy and relevance. Ethical\nconsiderations surrounding data privacy and ownership need\ncareful attention to ensure responsible use. By addressing\nthese challenges, researchers and practitioners can unlock\nGPT\u2019s potential while ensuring its practicality and ethical\nimplementation in agriculture.\n4) Summary: GPT holds immense potential in agriculture,\noffering numerous bene\ufb01ts alongside notable challenges. Its\ndata analysis capabilities empower farmers with informed\ndecision-making in disease identi\ufb01cation, soil analysis, and\nprecision farming, leading to improved crop yields and sus-\ntainable practices. However, the effectiveness of GPT relies\non data availability and quality, while its interpretability re-\nmains a challenge due to its black-box nature. Additionally,\ncomputational requirements, language nuances, and ethical\nconsiderations require careful attention. By addressing these\nchallenges, the agricultural sector can harness the full potential\nof GPT, paving the way for more productive, ef\ufb01cient, and\nresponsible farming practices.\nE. Travel and Transport\n1) Introduction: Historically, animals have been used by\npeople as their main source of transportation. But as the\nworld\u2019s population increased, the demand for more effec-\ntive transportation systems increased. Transportation-related\ntechnological advancements have fundamentally changed the\nsector in several ways. Business operations like order tracking,\nfreight management, and customer support can be streamlined\nby automation employing AI-driven technologies. Companies\ncan enable their employees to concentrate on more bene\ufb01-\ncial and pro\ufb01table duties by automating these tasks [117].\nWith better transportation networks and logistics management\nsystems that optimize routes and reduce transit times, tech-\nnological developments also enable speedier delivery times.\nIn terms of product development, technical advancement has\npaved the way for the development of innovative vehicles,\ninfrastructure, and logistics systems, leading to the production\nof more sophisticated and effective transportation choices.\nAnother noteworthy bene\ufb01t of technology advancement in\nlogistics and transportation is increased customer service.\nInquiries and problems can be handled quickly and ef\ufb01ciently\nby chatbots and customer support systems powered by AI,\nimproving the entire customer experience [14].\n2) Impact of GPT in Travel and Transport : Companies\ncan learn about customer preferences in real time by us-\ning GPTs in logistics and transportation, which results in\nbetter personalization and more customer satisfaction. GPTs\nleverage NLP approaches to interpret customer requirements\nand preferences, enabling customized suggestions as well as\nguidance in the logistics and transportation processes. The\nmost effective routes and forms of transportation can be\nrecommended using GPTs, which can analyse a large amount\nof data, including traf\ufb01c patterns, weather conditions, and\ndelivery requirements [118]. In addition, GPTs can be used as\ntravel planners, allowing visitors to enter their travel budget,\nduration, and destination to create customized itineraries. For\ntravel agencies, this personalized approach increases consumer\nsatisfaction and revenue.\n\u2022 Logistical Management: GPTs can be quite important\nin the context of shipping logistics. They can automate\nthe creation of shipping labels, eliminating up manual\nentry and lowering the possibility of mistakes. Addi-\ntionally, GPTs can have access to real-time tracking\ndata and can integrate GPS data and sensors to provide\nbusinesses and customers with precise and up-to-date\nshipment status information. Companies can successfully\nmonitor shipments with the use of GPTs, geographic\ninformation systems (GIS), and routing algorithms [14].\nOrganizations can track shipments in real-time and ensure\nvisibility throughout the supply chain by utilizing GPS\ndata and sensor technology [119].", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 4905, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "6805d554-1155-4b86-9c58-80aad740ed16": {"__data__": {"id_": "6805d554-1155-4b86-9c58-80aad740ed16", "embedding": null, "metadata": {"page_label": "19", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "558c49cd-b1b2-49d3-aa0e-82328822695e", "node_type": "4", "metadata": {"page_label": "19", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "hash": "beace009f4bed7baee2aa25c1c7451845db9aa4d28d29e237a5598feb78d3699", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "89df1068-6713-4e14-ac11-1595fb9747c4", "node_type": "1", "metadata": {"page_label": "19", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "hash": "3ca92f6ef4571701598ae12302daaa681a817e17e1c5db4b93ed8d9f47a9df72", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "In addition, GPTs can be used as\ntravel planners, allowing visitors to enter their travel budget,\nduration, and destination to create customized itineraries. For\ntravel agencies, this personalized approach increases consumer\nsatisfaction and revenue.\n\u2022 Logistical Management: GPTs can be quite important\nin the context of shipping logistics. They can automate\nthe creation of shipping labels, eliminating up manual\nentry and lowering the possibility of mistakes. Addi-\ntionally, GPTs can have access to real-time tracking\ndata and can integrate GPS data and sensors to provide\nbusinesses and customers with precise and up-to-date\nshipment status information. Companies can successfully\nmonitor shipments with the use of GPTs, geographic\ninformation systems (GIS), and routing algorithms [14].\nOrganizations can track shipments in real-time and ensure\nvisibility throughout the supply chain by utilizing GPS\ndata and sensor technology [119]. Customers can receive\nprecise updates on their shipments using this real-time\ninformation, which will improve their experience overall.\nOverall, the use of GPTs into shipping logistics results in\nincreased automation, ef\ufb01ciency, and client satisfaction.\n\u2022 Intelligent Fleet Management and Tracking: Companies\ncan get real-time \ufb02eet updates by utilizing GPT models,\nwhich enables them to track vehicles quickly and pre-\ncisely. GPT models\u2019 underlying technology also supports\nproactive \ufb02eet management. GPTs can identify possible\nproblems or maintenance needs before they develop into\nexpensive breakdowns or accidents by analyzing data\nfrom a variety of sources [120]. With this knowledge,\ncompanies may take preventative measures, such as plan-\nning maintenance or quickly \ufb01xing developing problems,\nultimately saving time and money by preventing unin-\ntended delays. Additionally, GPTs can provide clever\nalerts and noti\ufb01cations. Businesses can receive alerts\nwhen vehicles arrive at speci\ufb01ed areas by setting up\nspeci\ufb01c triggers, which enables better coordination and\ncustomer service [121]. For instance, businesses can alert\nclients or storage facilities in advance of a truck\u2019s arrival,\nallowing for effective unloading and loading procedures.\n\u2022 Real-Time Inventory Tracking: GPTs enable businesses\nto manage their inventory levels while on the road\nwith a cloud-based platform that makes it simple to\naccess inventory data from anywhere in the world. Better\ninventory management and decision-making are made", "mimetype": "text/plain", "start_char_idx": 3965, "end_char_idx": 6420, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "8218b2f8-fba7-4866-9d2b-6789bee1e280": {"__data__": {"id_": "8218b2f8-fba7-4866-9d2b-6789bee1e280", "embedding": null, "metadata": {"page_label": "20", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "8f978440-ce79-4065-8cbc-754adab97c80", "node_type": "4", "metadata": {"page_label": "20", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "hash": "c52df6ca5e7c1feb28a206169e51460f8f4c5da0b68b27e990262281fbe19a44", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "b80fb0e0-baf4-4998-9ca9-2f96b389e04b", "node_type": "1", "metadata": {}, "hash": "0412b6edae500477dad5d19901eabf3164df73591ec8a2b8ed2e8f2a80dcd0a4", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "20\npossible by this real-time accessibility. This ensures that\nthe appropriate quantity of stock is accessible when\nneeded to ful\ufb01l consumer requests, while minimizing\ncarrying costs and preventing lost sales as a result of\nstockouts. GPTs can streamline inventory management\nprocedures by eliminating the need for human data entry\ninto spreadsheets, saving time and cutting overhead costs\n[117]. With the advent of 5G technology, the cost of\nconnected devices has dramatically decreased, making it\nmore practical and affordable for businesses to set up and\noperate connected inventory monitoring systems. This\nmay make real-time inventory tracking solutions more\nwidely adopted, thereby increasing the effectiveness and\nprecision of inventory management [122].\n\u2022 Streamlining Delivery Operations: GPTs are able to es-\ntimate traf\ufb01c trends and improve routes for both drivers\nand passengers using real-time data [14]. These models\ncan produce effective routes that reduce travel times and\nenhance overall delivery performance by taking into ac-\ncount aspects like traf\ufb01c congestion, road conditions, and\ndelivery schedules. Route optimization not only reduces\ntravel time but also bene\ufb01ts the environment. In order to\nimprove air quality and create a more sustainable delivery\nprocess, it is possible to cut down on idle times and trip\ndistances. Businesses may streamline operations, improve\nthe overall customer experience, and contribute to a\nmore sustainable and environmentally friendly approach\nto logistics by automating procedures, optimizing routes,\nand utilizing real-time data [123].\n\u2022 Tourism: GPTs have the potential to signi\ufb01cantly improve\na number of tourism-related aspects. GPTs can offer\ncustomized solutions that suit the individual\u2019s preferences\nby understanding their needs and interests, resulting in a\nmore pleasurable travel experience. GPTs are excellent\nat understanding and creating text that is human-like [4].\nThis functionality can be used in the travel and tourism\nsector to enable chatbots or virtual travel assistants to\ncommunicate with users in natural language [124]. Trip\nplanning and information retrieval are made more sim-\nple and user-friendly by the ability of travelers to ask\nquestions, look for advice, and obtain full details about\ndestinations, modes of transportation, customs, and more.\nGPTs are capable of producing in-depth and interesting\ndescriptions of tourist sites, attractions, lodging, restau-\nrants etc. GPTs can provide time-ef\ufb01cient routes that\nguarantee a complete travel experience [125]. Including\nadvice on local legislation, emergency contacts, medical\nfacilities, and potential risks, GPTs can offer helpful\ninformation and direction regarding travel safety.\n3) Challenges: Privacy issues may occur when using sen-\nsitive data in travel GPTs. It is essential to manage user data\nsensibly and putting up strong security measures to safeguard\nprivate data. The quality of the model\u2019s outputs is directly\nin\ufb02uenced by the correctness and completeness of the data uti-\nlized during the training phase. Ethical considerations should\nbe taken into account when creating AI-powered applications\nemploying GPTs. It\u2019s crucial to check that the models are\ntruthful, unbiased, and free from harmful presumptions or\ndiscriminatory procedures [126]. Although the models contain\nadvanced features, they are dif\ufb01cult to tailor for speci\ufb01c use\ncases, need a lot of data to train, and have built-in limitations.\n4) Summary: Emerging GPTs have the potential to enhance\nproductivity, communication, and the calibre of goods and\nservices, which will bene\ufb01t many aspects of people\u2019s life.\nGPTs can offer real-time updates, effective route optimization,\nand customized recommendations in the travel and transporta-\ntion industries, enhancing the overall travel experience and\nincreasing operational effectiveness. Adopting them, however,\ncomes with some dif\ufb01culties. As speci\ufb01c roles are replaced\nby automation, GPTs may result in job displacement [127].\nAdditionally, the computational and memory requirements\nfor GPTs make their deployment on compact or low-power\ndevices dif\ufb01cult. GPTs may not be accessible to growing\nbusinesses due to the high costs associated with obtaining and\nusing them. Despite these obstacles, attempts are being done to\novercome them and improve the usability and value of GPTs\nfor a larger range of users.\nF .", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 4384, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "b80fb0e0-baf4-4998-9ca9-2f96b389e04b": {"__data__": {"id_": "b80fb0e0-baf4-4998-9ca9-2f96b389e04b", "embedding": null, "metadata": {"page_label": "20", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "8f978440-ce79-4065-8cbc-754adab97c80", "node_type": "4", "metadata": {"page_label": "20", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "hash": "c52df6ca5e7c1feb28a206169e51460f8f4c5da0b68b27e990262281fbe19a44", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "8218b2f8-fba7-4866-9d2b-6789bee1e280", "node_type": "1", "metadata": {"page_label": "20", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "hash": "ddda9d0b650b646bedc7f8e868fbecf8f33b97f2cc1cf3d8bcabafde9fa789f4", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "GPTs can offer real-time updates, effective route optimization,\nand customized recommendations in the travel and transporta-\ntion industries, enhancing the overall travel experience and\nincreasing operational effectiveness. Adopting them, however,\ncomes with some dif\ufb01culties. As speci\ufb01c roles are replaced\nby automation, GPTs may result in job displacement [127].\nAdditionally, the computational and memory requirements\nfor GPTs make their deployment on compact or low-power\ndevices dif\ufb01cult. GPTs may not be accessible to growing\nbusinesses due to the high costs associated with obtaining and\nusing them. Despite these obstacles, attempts are being done to\novercome them and improve the usability and value of GPTs\nfor a larger range of users.\nF . E-Commerce\n1) Introduction: Electronic commerce, commonly referred\nto as e-commerce, is a way for conducting economic trans-\nactions and create relationships between groups of people\nand entities using digital information processes and electronic\ncommunications [128]. Globally, this type of trade has experi-\nenced substantial growth, particularly in the retail sector. The\npreference for internet shopping, especially among younger\nmillennials, is a prominent trend in consumer behaviour.\nMobile devices have consequently taken over as the main\nmethod for carrying out internet transactions [129]. Therefore,\nit is crucial for e-commerce companies to give the customer\nexperience in their mobile applications top priority. The pro-\nvision of brief text summaries for titles and reviews is an\nessential component of this. These summaries are essential\nfor optimizing search results, helping consumers identify ap-\npropriate items, and ultimately raising customer happiness in\nthe online purchasing space [130].\n2) Impact of GPT in E-Commerce Realms: The e-\ncommerce sector could signi\ufb01cantly advance with the intro-\nduction of GPTs. GPTs can be accessed by users or customers\nand are intended to answer commonly asked questions and\ngive in-depth details about many elements of the e-commerce\nprocess, such as products, delivery, refunds, and more [107].\nOne of the main bene\ufb01ts of GPTs is their capacity for quick\nresponses, which decreases the amount of time customers must\nwait to hear back from businesses [131]. By taking care of an\nimportant number of client inquiries, this function not only\nincreases customer happiness but also lessens the workload\non support workers. Customers will ultimately have a better\npurchasing experience as a result of being able to quickly\nacquire the information they require and interact with GPTs\n[106].\n\u2022 Proofreading: To improve the calibre and accuracy of\nwritten content in e-commerce, GPTs can be used for\nproofreading. Written content is essential for product", "mimetype": "text/plain", "start_char_idx": 3635, "end_char_idx": 6390, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "3407d69d-6868-4d61-8bb5-673e0ba63574": {"__data__": {"id_": "3407d69d-6868-4d61-8bb5-673e0ba63574", "embedding": null, "metadata": {"page_label": "21", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "4d47f922-9432-41e0-879b-8a5198abebf4", "node_type": "4", "metadata": {"page_label": "21", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "hash": "f507869cf17ccf9556e1c9035d3ee0e256c0e33083ede2c55483a90515bd44b4", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "0b8beeea-f3a0-4132-ba18-a280cfb754b5", "node_type": "1", "metadata": {}, "hash": "9521a96554547765ba0d41769c283d0203a659f7a383ac607cce5ce699bf2f85", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "21\ndescriptions, marketing materials, customer reviews, and\nother text-based components in the e-commerce sector\n[105]. For the purpose of projecting professionalism,\nfostering trust, and delivering a satisfying user experi-\nence, this text must be devoid of errors, well-written,\nand grammatically correct. E-commerce companies can\nautomate the process of identifying and correcting these\nproblems by using GPTs for proofreading, which saves\ntime and effort as comparison to manual proofreading\n[132]. This can be especially helpful in situations when\nusers are writing product reviews or interacting with\ncustomer service. An improved user experience is facil-\nitated by the early detection and recti\ufb01cation of errors,\nwhich also helps to avoid potential misunderstandings or\nmiscommunications.\n\u2022 Order Processing: GPTs are useful in many areas of\norder management and customer service because they\ncan comprehend and produce text that looks like human\nspeech. GPTs can help with handling consumer questions\nabout orders [133]. GPT is capable of interpreting the\nqueries, providing important details like order status,\ntracking information, and expected delivery time, as well\nas suggesting corrections for frequent problems [134].\nBy delivering real-time information, GPTs can assist cus-\ntomers in tracking their orders. Customers can customize\ntheir purchase with the help of GPTs. GPTs can help in\nthe identi\ufb01cation of possibly fraudulent orders by exam-\nining past transaction data, consumer behaviour patterns\netc [135]. Based on a customer\u2019s past purchases, browsing\nhabits, and preferences, GPTs can offer tailored product\nrecommendations. When a consumer puts a purchase,\nthe model can examine the information and produce\nrecommendations for related or supplementary products\nthat the customer might \ufb01nd interesting.\n\u2022 Generating titles for products: Companies can use GPTs\nto produce interesting and educational material to im-\nprove the appeal of their product listings [117]. Based on\na product\u2019s category, brand, and special characteristics,\nGPTs can come up with attractive titles for it. The model\ncan produce imaginative and memorable names that aid in\nbrand awareness and differentiation by receiving relevant\ninformation such as the characteristics of the product\nand the target market. GPTs are trained to produce in-\ndepth and interesting product descriptions [113]. These\nsummaries can offer a thorough summary that aids clients\nin selecting products wisely. GPTs are capable of coming\nup with clever and appealing captions for product images.\nGPTs can be adjusted to better re\ufb02ect the tone and\naesthetic of a certain brand [136]. As a result, the brand\nidentity is consistent and uni\ufb01ed throughout all product\nlistings.\n\u2022 Strategy Planning: GPTs have the ability to come up\nwith original and distinctive concepts for marketing\ncampaigns [137]. The model can provide recommenda-\ntions for different campaign aspects, such as slogans,\ntaglines, themes, contests, social media strategies, and\nmore by taking into account relevant information about\nthe product, target audience, marketing objectives, and\ndesired outcomes. GPTs can help with email writing\nthat encourages readers to become partners, investors,\nor customers [138]. To increase the likelihood of a\nfavourable response or interaction, these emails can be\ncustomized to address the needs and potential bene\ufb01ts\nfor the receivers. To improve their comprehension and\nproduction of appropriate material, GPTs can be trained\non domain-speci\ufb01c knowledge bases, such as e-commerce\n[107]. The models can offer more precise and situation-\nspeci\ufb01c recommendations for advertising strategies, prod-\nuct positioning, and target audience interaction because\nof this specialized training.\n\u2022 Data analysis: There are numerous ways to use GPTs for\ndata analysis in e-commerce. E-commerce data prepa-\nration can be aided by GPTs [24]. Data normalization,\ncleansing, and formatting are a few of the duties in-\nvolved. GPTs can produce summaries, identify signi\ufb01cant\ntopics, and extract appropriate data by studying textual\ndescriptions, reviews, and consumer feedback. This helps\nyou know the data more thoroughly, identify trends, and\n\ufb01nd insightful information. Customer reviews and social\nmedia comments from e-commerce can be analyzed for\nsentiment using GPTs. The sentiment expressed in text\ncan be evaluated using GPTs and categorized as either\npositive, negative, or neutral [107].", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 4453, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "0b8beeea-f3a0-4132-ba18-a280cfb754b5": {"__data__": {"id_": "0b8beeea-f3a0-4132-ba18-a280cfb754b5", "embedding": null, "metadata": {"page_label": "21", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "4d47f922-9432-41e0-879b-8a5198abebf4", "node_type": "4", "metadata": {"page_label": "21", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "hash": "f507869cf17ccf9556e1c9035d3ee0e256c0e33083ede2c55483a90515bd44b4", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "3407d69d-6868-4d61-8bb5-673e0ba63574", "node_type": "1", "metadata": {"page_label": "21", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "hash": "e42f7fb443a07ec2edf6916f8cb3bb6a2fa859fce2106fc1739e1f9c66a2269d", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "\u2022 Data analysis: There are numerous ways to use GPTs for\ndata analysis in e-commerce. E-commerce data prepa-\nration can be aided by GPTs [24]. Data normalization,\ncleansing, and formatting are a few of the duties in-\nvolved. GPTs can produce summaries, identify signi\ufb01cant\ntopics, and extract appropriate data by studying textual\ndescriptions, reviews, and consumer feedback. This helps\nyou know the data more thoroughly, identify trends, and\n\ufb01nd insightful information. Customer reviews and social\nmedia comments from e-commerce can be analyzed for\nsentiment using GPTs. The sentiment expressed in text\ncan be evaluated using GPTs and categorized as either\npositive, negative, or neutral [107]. Understanding client\nviews, recognizing product strengths and de\ufb01ciencies,\nand making data-driven decisions all bene\ufb01t from this\nanalysis, which also helps to increase customer happiness.\nSegmenting consumers based on preferences, behaviours,\nor past purchases can be aided by GPT models [139].\nFor the purpose of detecting fraud in e-commerce trans-\nactions, GPTs can be used. GPTs can support the identi\ufb01-\ncation of potentially fraudulent actions by examining past\ntransaction data, user behaviour patterns, and recognized\nfraudulent tendencies [140].\n3) Challenges: While GPTs have a lot of potential for\nnumerous e-commerce applications, they also have several\ndrawbacks. In order to produce responses, GPTs mostly rely\non the context given in the input text. They could, however,\n\ufb01nd it dif\ufb01cult to fully understand the broader context or\ndetails that are unique to e-commerce. GPTs provide replies\nusing training data and prior knowledge. They are unable to\naccess real-time data or carry out real-time calculations [141].\nThey might not be appropriate for giving current information,\nsuch as pricing, product availability, or dynamic promotional\noffers. GPTs gain their knowledge from a wealth of training\ndata, which includes text taken from the internet, which\nmay be biased, stereotyped, or otherwise offensive [142].\nThe models may unintentionally provide biased or unsuitable\nreplies if they are not rigorously managed and monitored,\nwhich could be harmful to the customer experience and brand\nreputation. The use of ethical principles and the training data\nmust both be given careful thought.\n4) Summary: The conversational interface offered by GPTs\ncustomizes the purchasing process and makes interactions with\nclients more interesting and appropriate to their individual\nrequirements. GPTs can also be utilized to get insightful\ncustomer feedback. Businesses can learn about customers\u2019", "mimetype": "text/plain", "start_char_idx": 3758, "end_char_idx": 6354, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "994fe664-6027-4bb5-81cf-127e336961c3": {"__data__": {"id_": "994fe664-6027-4bb5-81cf-127e336961c3", "embedding": null, "metadata": {"page_label": "22", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "cb471448-20a9-4f2b-8a36-667ddeb76802", "node_type": "4", "metadata": {"page_label": "22", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "hash": "18b4e09bf759d03c2bfe7b045baeba30ea49164390e116c515618e5f630b5b1b", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "318c557d-9675-42c7-af4a-1798c83ff92e", "node_type": "1", "metadata": {}, "hash": "6c9f8da1f393a7057c721a19fbce5592d684b47526ae511c54bda97d9c34f12d", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "22\npreferences, issues, and opinions regarding their products and\nservices by conversing with them. In order to better serve\ntheir target audience, organizations can use this information to\ndiscover areas for improvement, increase customer happiness,\nand make data-driven decisions. It\u2019s essential to recognize\nthat GPTs might occasionally make mistakes or give poor\nanswers, particularly when dealing with complicated or am-\nbiguous queries. This highlights the necessity of continual\nmodel training, thorough testing, and modi\ufb01cation to guarantee\nthat they consistently meet consumer needs. To con\ufb01rm the\nef\ufb01cacy and dependability of using GPTs speci\ufb01cally in the e-\ncommerce area, more research and testing are required. When\nimplementing GPTs, it\u2019s critical for businesses to take into\naccount the particulars of their own e-commerce businesses,\ntheir target market, and the type of the client enquiries. Regular\nmonitoring and feedback analysis, along with a systematic\nand iterative approach, can help make sure that the outcomes\nof using GPT models are in line with the objectives of e-\ncommerce enterprises.\nG. Entertainment\n1) Introduction: In the ancient days, the Entertainment\nmeant about playing games with neighbors covers all outdoor\ngames, indoor games and chatting with neighbours through\ntelephone. As digitization has bought greater advancements\nin computation and communication, in turn access to internet\nis also much easier. This has changed the way people are\nentertained. as people are connected and fully engaged in\ncompleting the target for the day. And there was a radical shift\nfrom traditional employment to employment in the Industrial\nRevolution age. Stress and pressure are common factors hin-\ndering people of different age groups. The different forms of\nentertainment serve as stress busters. Entertainment and mental\nhealth are interrelated; the former transfers happiness, bringing\nharmony and peace to mental health. Some common forms\nof entertainment include playing games, watching TV series\nor movies, or funny videos, shopping, debugging, coding,\nbrowsing the internet, listening to music, dancing, chatting,\npainting, crafting, reading books, cooking, and many more,\nwhich can lessen the stress carried [143]. Entertaining and\ngetting entertained is the biggest motivation and medicine for\nall mental illnesses. Entertainment helps to improve the motor\nskills of humans, thereby inducing a positive cognitive effect\ntowards the work.\n2) Impact of GPT on the Entertainment Industry: GPT is\na potential game-changer in the entertainment \ufb01eld, delivering\nendless entertainment. Since its evolution, GPT models have\nbeen adopted as an entertainer crosschecking their ability\nto produce content on funny and illogical questions. GPTs\nentertain people in many ways, and of course, using GPT itself\nan entertainment as it reduces the burden of overthinking by\nproviding immediate feedback to queries in seconds [144].\nThe results are amazing and have been utilized for many\npurposes today. When the GPT model was probed to complete\na scene from the movie \u201cFrozen,\u201d it responded with an\nentertaining writeup [145], [146]. Some of the impacts of\nGPTs on Entertainment applications are given below:\n\u2022 Solitude with GPT: As the GPT itself is an entertainer,\none can feel better alone with the GPT, which helps to\ncome out of loneliness by exploring its savors [147].\nGPTs assist in providing soothing poems, mental healing\nquotes, and funny riddles. People with loneliness may feel\nanxiety, especially with older ones at home. In this case,\nGPT-4 helps people with its V oice Technology feature,\nenabling users to input their audio [147]. In turn, the\nGPT model responds to user-speci\ufb01c speech output using\nNLP algorithms embedded with it. The elderly can feel\nsafe and attentive at home. GPT-4 is multilingual and can\nunderstand various dialects and accents for personalized\nuser experience.\n\u2022 Enhanced Customer Interaction: The advent of Chat-\nGPT and Bard has improved customer interactions on\ncontent such as movies, Over-the-Top (OTT) platforms\nlike Net\ufb02ix, Hulu, Disney+ Hotstar, and prime video,\nsound recordings, song lyrics, pictorial works, comics,\njokes, memes, viral videos, and other entertaining factors.\nFurther, GPTs provide human-like recommendations on\nuser-speci\ufb01c fun activities based on user interactions for\nan immersive experience.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 4385, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "318c557d-9675-42c7-af4a-1798c83ff92e": {"__data__": {"id_": "318c557d-9675-42c7-af4a-1798c83ff92e", "embedding": null, "metadata": {"page_label": "22", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "cb471448-20a9-4f2b-8a36-667ddeb76802", "node_type": "4", "metadata": {"page_label": "22", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "hash": "18b4e09bf759d03c2bfe7b045baeba30ea49164390e116c515618e5f630b5b1b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "994fe664-6027-4bb5-81cf-127e336961c3", "node_type": "1", "metadata": {"page_label": "22", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "hash": "99173b1cdfc30d0796a8c25f9fdf14ff0e7390dfd3bcb34348ab4df08a242609", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "In this case,\nGPT-4 helps people with its V oice Technology feature,\nenabling users to input their audio [147]. In turn, the\nGPT model responds to user-speci\ufb01c speech output using\nNLP algorithms embedded with it. The elderly can feel\nsafe and attentive at home. GPT-4 is multilingual and can\nunderstand various dialects and accents for personalized\nuser experience.\n\u2022 Enhanced Customer Interaction: The advent of Chat-\nGPT and Bard has improved customer interactions on\ncontent such as movies, Over-the-Top (OTT) platforms\nlike Net\ufb02ix, Hulu, Disney+ Hotstar, and prime video,\nsound recordings, song lyrics, pictorial works, comics,\njokes, memes, viral videos, and other entertaining factors.\nFurther, GPTs provide human-like recommendations on\nuser-speci\ufb01c fun activities based on user interactions for\nan immersive experience. This has dramatically improved\nthe interactions in the engagement industries. User en-\ngagement can be further improved by providing dynamic\nand more realistic responses to user queries, such as\ncreating virtual actors for interacting with real actors\n[148].\n\u2022 Personalized Content Creation: GPTs can help generate\nuser-speci\ufb01c personalized content by analyzing the user\npreferences and generating content like predicting future\nscenarios tailored to the user\u2019s interest. GPTs can be\nused for creating personalized, engaging, and high-quality\ncontent for online business advertising, ideas for content\ngeneration, marketing messages for attracting customers,\ndescriptions for selling products, and captions for social\nmedia [149]. In addition, it can be used for optimizing\nthe contents for search engines, i.e., GPTs will provide\nrelevant terms for search, thereby avoiding traf\ufb01c to the\nweb sources.\n\u2022 For the Film and TV industry: GPT-powered virtual\nassistants assist users in booking tickets and generat-\ning content and personalized recommendations using AI\nmodels. The evolution of GPT-4 with advanced NLP\nand DL algorithms helps the scriptwriter to generate AI-\ndriven content without the human author named virtual\nstorytelling [150]. GPTs create interactive stories, dia-\nlogues, and characters, recommending suitable characters.\nFurthermore, GPTs can be used to create content for\nvideo games, voice-enabled applications, AR applica-\ntions, and other VR experiences in virtual worlds [151].\n\u2022 For Social media in\ufb02uencers: GPTs can generate person-\nalized marketing ads for each customer based on their\nprevious interactions and provides relevant suggestions\nfor customer viewing experiences. Youtubers and other\nsocial media content creators will potentially bene\ufb01t from\ngenerating channel content based on demand and realistic\nsocietal activities.", "mimetype": "text/plain", "start_char_idx": 3558, "end_char_idx": 6245, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "bf4b4467-d8a2-4d21-ab41-a3453ef26365": {"__data__": {"id_": "bf4b4467-d8a2-4d21-ab41-a3453ef26365", "embedding": null, "metadata": {"page_label": "23", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "9244cbb3-441d-4c60-8238-e675e6b93caf", "node_type": "4", "metadata": {"page_label": "23", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "hash": "cf8f86c0a79524a1531a2af5aa80133799f4e2b45ce4aac51e9e34ad6d4709ee", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "e1b7cb24-1324-4f64-b9a5-4b0ca5d21de8", "node_type": "1", "metadata": {}, "hash": "74163a6d5585af713912661bf8d965489c382b4a19a0a8c6991167f293e98308", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "23\n\u2022 Realistic Gaming Interactions: GPT helps to generate the\nplayers, gaming narratives, dialogues, user interface, and\nuser-speci\ufb01c gaming recommendations and new game\ncreation. Powerful HCIs can render a better user ex-\nperience for game developers and players. Assistance\nto the game developers in debugging and enhancing\nthe code developed. GPT uses various NLP and AI\nalgorithms trained with massive data to predict the next\nphrase/movements and provide human-like experiences in\n3D gaming environments. ChatGPT has been integrated\nwith AR and VR to provide an immersive gaming expe-\nrience.\n3) Challenges: Latency is the major issue connected with\nrendering the voice-based response to the voice input. As\nwell, plausible misinterpretations may mislead the responses,\nand interruptions to the relayed output are dif\ufb01cult. Enabling\ntechnologies like EC and 5G can help overcome this issue.\nAlso, GPTs must be capable of storing the facts with audio\nconversations to relay them while conversing the other day.\nFurthermore, the AI system must be built in such a way\nthat it can continuously learn (lifelong machine learning) and\nenhance over time. The major ethical concern with virtual\nstorytelling is the bias exposed in the training data and the\nobscurity of reproduced content on the generated stories.\nAnother issue with the generated content is plagiarism (i.e.,\nproducing content similar to the content in the published\narticles or books), raising disputes with intellectual property\nrights. In addition to this, the source of the content generated\nremains unexplored. The language barriers in using GPT must\nbe lessened to improve user experience and utilize the features\nof GPT [113]. The implication of the user to provide inputs in\na certain format to GPTs can be further improved by providing\ndifferent options in addition to voice-based inputs GPT4,\nlike braille screen input for visually disabled people. The\nuser authentication can also be further enhanced to safeguard\nuser-speci\ufb01c content generation and avoid repeated content\ngeneration for users with similar requests. One of the primary\nconcerns with the GPTs adoption is job loss. Content creators,\nbloggers, and poets may lose their jobs.\n4) Summary: The entertainment industry is the one which\nwill be in demand always, as it is a lifeline for many indi-\nviduals leading a stressful work environment or personal life.\nDespite the stress, entertainment has become part of routine\nlife due to its immersive nature, creating harmony in the mind\nand the environment. GPTs have made a major contribution to\nenhancing the entertainment industry, but the job security of\nmany professionals in this \ufb01eld remains unanswered. GPTs\nmust be trained on unbiased data and ensure transparency\nin source content generation to provide a secure, robust, and\nef\ufb01cient contribution to the entertainment industry. To attract\nall types of users, the multilingual capability and content\nrendering of GPTs can be further enhanced. The issues con-\nstrained by providing user inputs to GPTs can be alleviated to\nall extent. Furthermore, safer user content generation without\nplagiarism and relating facts with previous conversations can\nbe guaranteed by abiding by the storage requirements to deal\nwith a more personalized user experience.\nH. Lifestyle\n1) Introduction: Lifestyle, the way of our living, is one\nof the prominent areas most people in today\u2019s digital era of\nAI, are bound to and look for constant improvement. The\n\u201cmodus vivendi\u201d is a Latin expression that semantically means\na way of living and should be understood in terms of values\nand attitudes. These two terms manifest self, in\ufb02uenced by\nfamily, society, and global media. Directly or indirectly, these\nin\ufb02uence an individual\u2019s lifestyle. Adopted from a sociological\nperspective, an individual expresses oneself through different\npractices, viz., eating ways, drinking behaviours, mode of\ntravel, travelling places, costume designs, body-shaping cloth\nto wear, media preferences, education choices, job preferences,\nentertainment modes, managing leisure time, means of com-\nmunication and so [152]. In all these practices, individuals\nwould like to explore and learn about what, where, how, and\nwhen factors for reading sustainable development [153].", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 4272, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "e1b7cb24-1324-4f64-b9a5-4b0ca5d21de8": {"__data__": {"id_": "e1b7cb24-1324-4f64-b9a5-4b0ca5d21de8", "embedding": null, "metadata": {"page_label": "23", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "9244cbb3-441d-4c60-8238-e675e6b93caf", "node_type": "4", "metadata": {"page_label": "23", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "hash": "cf8f86c0a79524a1531a2af5aa80133799f4e2b45ce4aac51e9e34ad6d4709ee", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "bf4b4467-d8a2-4d21-ab41-a3453ef26365", "node_type": "1", "metadata": {"page_label": "23", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "hash": "f7df08dfa8f2d68e7fd75df4504c29805cb622bf7de7dc0f6e6a26c5adb7b501", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "The\n\u201cmodus vivendi\u201d is a Latin expression that semantically means\na way of living and should be understood in terms of values\nand attitudes. These two terms manifest self, in\ufb02uenced by\nfamily, society, and global media. Directly or indirectly, these\nin\ufb02uence an individual\u2019s lifestyle. Adopted from a sociological\nperspective, an individual expresses oneself through different\npractices, viz., eating ways, drinking behaviours, mode of\ntravel, travelling places, costume designs, body-shaping cloth\nto wear, media preferences, education choices, job preferences,\nentertainment modes, managing leisure time, means of com-\nmunication and so [152]. In all these practices, individuals\nwould like to explore and learn about what, where, how, and\nwhen factors for reading sustainable development [153]. The\nconcept of lifestyle is all about \u201chow one wants to live one\u2019s\nlife.\u201d Consumerism is the act of purchasing artifacts for soci-\netal status and is one of the thriving lifestyle factors. Certain\nstandard indicators like job, wealth, and physical and mental\nhealth determine the quality of one\u2019s life. Also, the choice\nof a healthy lifestyle moderately determines the health of an\nindividual [154]. Furthermore, few people believe that lifestyle\nre\ufb02ects their socioeconomic status. Many epidemiologic stud-\nies state that better lifestyles have dramatically reduced the\nrisk of various chronic diseases and are the primary cause\nfor their prevention [155]. The lifestyle has been de\ufb01ned\non different societal levels from individual, positional, and\nnational to global [153]. At the global level, lifestyle is adopted\nby general world-class in\ufb02uencers. In contrast, at the national\nlevel, the in\ufb02uencing factors will be the government and dif-\nferent cultural patterns across the country. The positional level\nconcerns in\ufb02uence from different status groups, age categories,\ngender groups, and social classes. And the individual level is\nin\ufb02uenced by a closely moving group of individuals concerned\nabout self-identity. The major source of information about\nthese in\ufb02uencers is the Internet through social media networks\nand personal development advertisements.\n2) Impact of GPT in Lifestyle: The most remarkable ap-\nplication of AI, the GPT, paves the way for the betterment\nof mankind in offering human-like intelligent conversation\non all whereabouts. People will always prefer to interact\nwith other peers to learn their attributes and tweak them for\nsocietal status. Various GPTs have \ufb02ourished for different\nlifestyle indicators, and they provide human-like assistance\nto all queries on \ufb01ne-tuning the lifestyle by harnessing the\npower of AI [156]. The advanced reasoning capability of GPT-\n4 serves the purpose better [147].\n\u2022 Diet Planner: Free GPT applications for maintaining\na balanced diet, helping the individual with a weight\nloss diet plan, followed by a brief list of meal plans,\nrequired shopping lists, physical activity plans targeting\nparticular body parts [157], motivational messages, and\npersonalized sleeping patterns. These apps act more like\npersonalized training assistance and help to track progress\nwith visualization charts or graphs. Fitness level, available", "mimetype": "text/plain", "start_char_idx": 3475, "end_char_idx": 6661, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "54640df1-57bf-4260-8e0b-12ff6ec0d004": {"__data__": {"id_": "54640df1-57bf-4260-8e0b-12ff6ec0d004", "embedding": null, "metadata": {"page_label": "24", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "3fbdc7e5-f123-4784-ab82-ae59036d8c90", "node_type": "4", "metadata": {"page_label": "24", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "hash": "cb7e219de3feadd722c587525207fcedc5d0675be7a8c7892256d09aa496dd78", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "7dd1b51a-f789-4ba6-b1e3-38ec61440340", "node_type": "1", "metadata": {}, "hash": "91fc7ce8f03a4aa559a4560ae9f1b99170ec623c78a76f6bf39306a8aa0992ab", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "24\nfree hours, medications taken, and available exercise\nequipment will be given as input to GPT.\n\u2022 Travel Guide and Trip Advisor: Harnessing AI models,\nGPT provides an individual\u2019s travel plan itinerary based\non information like the place(multiple cities), budget, and\nthe number of days. These GPTs provide local recom-\nmendations on restaurants, hotels, and other attractions.\nRoamAround, Roamr, and VacayChatbot are some of the\ntravel planning GPTs [158].\n\u2022 Personalized Stylist and Beauty Advisor: GPTs can\nact as personalized stylists for an individual by gen-\nerating occasion-speci\ufb01c clothing and costume prefer-\nences. GPTs can assist in organizing wardrobes based\non seasonal out\ufb01ts and provide recommendations on e-\ncommerce fashion stores for purchasing favourite brands.\nGPTs can provide tailoring design options, fabric choices,\nand design materials. Furthermore, GPTs can provide\nupdates on a stock based on the preferred searches and\nprovide insight into fabric types suitable for weather\nconditions that suit personal style.\n\u2022 Personalized CookBook: GPTs can serve as cooking\nassistants by recommending new curated recipes suiting\nthe family dietary plan, ingredients available, time, in-\ndividual\u2019s cooking skills, and new \ufb02avoured ingredients.\nChefGPT, PantryChef, and MacrosChef are some GPTs\nthat generate unique and delightful recipes [159]. Con-\nsequently, GPTs can assist in shopping list recommenda-\ntions and the nutritional value of the recipe generated.\n\u2022 Hobby Curator : GPT assists an individual in identifying\none\u2019s enjoyable leisure time activity by learning new\nskills [160]. Having a list of interests and ideas ready,\nthe GPT helps narrow down various options, instructional\nvideos to proceed, chatting and sharing with online\ncommunities, and researching the cited hobby to explore\nmore fun. Budget will also be an important factor in\nthis perspective, as learning new hobbies may require\njoining paid classes or courses. GPT provides step-by-\nstep instructions and guidelines to learn a new skill faster.\n\u2022 Dream Maker: GPTs with multimodal learning helps\nto search for a job based on one\u2019s quali\ufb01cations and\nexperience. In turn, it assists in preparing the job-speci\ufb01c\nresume, cover letters, training for the interviews (coding\nand technical queries), and grooming sessions and can\nredirect to the training place where knowledge can be\nacquired [161]. The futurist GPT models can assist in\nphase-by-phase questionnaires in the interview process\n3) Challenges: The recent version of the GPT uses both\nreinforcement and supervised learning models so it can learn\nbased on the interaction with the user and can use existing data\nto derive personalized decisions. In the context of lifestyle,\nGPTs offer the most promising solution for almost all lifestyle\nin\ufb02uencers, but the still challenging part is the trustworthiness\nof the data and copyright issues. Also, relying more on GPT\nas it solves all our problems may insipid human intelligence\nin upcoming generations. Though the GPT provides weight\nadvice, it can never be a substitute for the medical practitioner,\nas some information can be misleading. Travel planning GPTs\nsometimes require users to update information in a speci\ufb01c\nformat and may have outdated databases. GPTs cannot access\nspeci\ufb01c job openings\u2019 websites but can still provide insights\ninto acquiring them. At times, it can produce nonsensical infor-\nmation [162]. Therefore, before adopting the GPT recommen-\ndations fully, further instigation is recommended. Furthermore,\ndeveloping a large multimodal learning model abiding huge\nand dynamic datasets will be costly.\n4) Summary: GPT is a personalized assistant for improving\nan individual\u2019s lifestyle from various prospective in\ufb02uencers.\nGenerating personalized recommendations alleviates an indi-\nvidual\u2019s fear of survival in the digitized society. Individuals\nwill be personally trained to adapt to different cultural and\ntechnological shifts in the sustainable development of them-\nselves and the economy as a whole. On the other hand, more\nstringent recommendations may incur huge budget overruns\nand sometimes provoke the individual to misinterpret, leading\nto dreadful consequences. GPTs provide both positive and\nnegative recommendations based on the input fed. So, for the\neffective adoption of a GPT for lifestyle practices, adverse\ntraining and testing on extreme behaviours must be carried out.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 4412, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "7dd1b51a-f789-4ba6-b1e3-38ec61440340": {"__data__": {"id_": "7dd1b51a-f789-4ba6-b1e3-38ec61440340", "embedding": null, "metadata": {"page_label": "24", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "3fbdc7e5-f123-4784-ab82-ae59036d8c90", "node_type": "4", "metadata": {"page_label": "24", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "hash": "cb7e219de3feadd722c587525207fcedc5d0675be7a8c7892256d09aa496dd78", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "54640df1-57bf-4260-8e0b-12ff6ec0d004", "node_type": "1", "metadata": {"page_label": "24", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "hash": "92478b36fe26e21e0e5a1c0c346ef2bb3ae6686cb513b402f2cf251f1217a536", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Furthermore,\ndeveloping a large multimodal learning model abiding huge\nand dynamic datasets will be costly.\n4) Summary: GPT is a personalized assistant for improving\nan individual\u2019s lifestyle from various prospective in\ufb02uencers.\nGenerating personalized recommendations alleviates an indi-\nvidual\u2019s fear of survival in the digitized society. Individuals\nwill be personally trained to adapt to different cultural and\ntechnological shifts in the sustainable development of them-\nselves and the economy as a whole. On the other hand, more\nstringent recommendations may incur huge budget overruns\nand sometimes provoke the individual to misinterpret, leading\nto dreadful consequences. GPTs provide both positive and\nnegative recommendations based on the input fed. So, for the\neffective adoption of a GPT for lifestyle practices, adverse\ntraining and testing on extreme behaviours must be carried out.\nGPTs must be trained in the realistic and dynamic perception\nof individuals in real life.\nI. Gaming\n1) Introduction: Before the advent of technology and the\ngaming industry, entertainment was primarily centred around\nactivities such as reading, listening to music, watching plays\nand movies, participating in sports and physical games, and\nsocializing with friends and family. People also engaged in\ntraditional board games and card games, which were often\nplayed in groups and provided a fun and social way to pass\nthe time. After technology stepped into the gaming industry,\nthe way games are created, and the experience it has given\nusers have transformed tremendously. Technology has enabled\ndevelopers to create more immersive and engaging experiences\nfor players. It has contributed in various ways, like improving\ngraphics, performance, online play, and mobile gaming. Im-\nproved GPUs and other technologies allow for more detailed\nand realistic graphics, making games more visually stunning.\nFaster processors and higher amounts of RAM allow for\nsmoother gameplay and faster loading times, reducing lag and\nimproving overall performance. Technologies like AI, AR, and\nVR have created a new dimension of game development and\nexperience. Players can now immerse themselves in gaming\nworlds in a way that was not possible before. With the help\nof advanced AI techniques, game developers can create more\nsophisticated and challenging opponents for players, as well as\nNPCs with more realistic behaviours. Technology has greatly\nexpanded the possibilities of gaming and enabled developers\nto create more immersive, visually stunning, and engaging\nexperiences for players.\n2) Impact of GPT in Gaming : GPTs have the ability to\ncontribute to all sectors, including the gaming sector. GPT\nare not speci\ufb01cally designed for creating and playing games,\nbut they have the potential to improve the gaming experience\nby improving enhanced dialogue and story telling, creating", "mimetype": "text/plain", "start_char_idx": 3516, "end_char_idx": 6382, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "dc33c5a8-604b-4c82-aa1e-501133d8f731": {"__data__": {"id_": "dc33c5a8-604b-4c82-aa1e-501133d8f731", "embedding": null, "metadata": {"page_label": "25", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "ff7fad39-f51a-42e5-8dd1-9d33dd480f7c", "node_type": "4", "metadata": {"page_label": "25", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "hash": "4b34e9e585f89e26ad252edf2529eba138c42159ca0f376f35680a9a33c34639", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "cb5beda1-04c6-4cce-9f62-f982392484d2", "node_type": "1", "metadata": {}, "hash": "b59ad9c03882bfa79d2af473ae7ac10472c2758858e597b54c58678496399adb", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "25\ndynamic and personalized gaming worlds, generating more\nrealistic and engaging characters [163], game content creation,\nchatbot development.\n\u2022 Chatbot development: GPTs have been used in gaming\nthrough the development of chatbots that use NLP to\ncommunicate with players [164]. Because it allows the\nchatbot to understand and respond to a wide range of user\ninputs and queries related to the game. GPTs have been\npre-trained on a large corpus of text data, which makes\nthem adept at NLP. It can understand and respond to user\nqueries in a way that feels natural and intuitive. It can also\nunderstand the context of a user\u2019s query, which means\nthey can provide relevant and useful responses even when\nthe user\u2019s query is ambiguous or incomplete. It can\nalso generate game-related content, such as descriptions\nof game characters or settings, that can help to enrich\nthe user\u2019s gaming experience. Furthermore, it can also\npersonalize the user\u2019s experience by learning from their\nprevious interactions with the chatbot and tailoring its\nresponses accordingly.\n\u2022 Game content creation: GPTs are used in game design.\nThey are used to create game content such as levels,\nitems, and quests. If the game designer is working on a\nnew role-playing game, GPT can be used in creating char-\nacters to be used in the games. To generate new character\nclasses in the games, the developer has to give inputs that\ncontain information about the game environment, game\nsettings, player abilities, and game play mechanics. GPTs\nhas the ability to analyze the text and expectations given\nby the developer, and it can generate a list of potential\ncharacter classes based on the expectations given as text.\nThe designer then re\ufb01nes the ideas and chooses a more\nsuitable character to develop further with unique abilities\nand game mechanics. The authors in [165] have used\nGPT2 and GPT3 to procedurally generate role-playing\ngame with video game descriptions. The resultant quest\nwas evaluated by 349 online RPG players. The results\nconcluded that one of the \ufb01ve quest descriptions was\naccepted for game development.\n\u2022 Analyze player\u2019s ability and skill: GPTs can detect\nand analyze players\u2019 abilities and skill levels and tailor\nthe game accordingly. This analysis helps in making\ndynamic modi\ufb01cations to the game environment based\non the player\u2019s abilities and skill levels. This feature\nhelps achieve dynamic dif\ufb01culty balancing. GPTs can\nalso assist in identifying the player\u2019s intent. Thus, when\nplayers ascend to higher levels, it can assist in making\nthe games more challenging based on the player\u2019s abilities\nand skill levels in the previous levels\n\u2022 NPCs: NPC stands for \u201dNon-Player Character.\u201d In AI\ngames, NPCs refer to characters or entities in a game\nthat are not controlled by a player. NPCs can take on\na variety of roles within a game, such as enemies to\n\ufb01ght, quest givers, merchants, or friendly characters that\nprovide helpful information. They are often controlled\nby AI algorithms that determine their behaviour and\nactions within the game world. GPTs are not speci\ufb01cally\ndesigned for creating NPCs, but they can be used to\ngenerate dialogue and other character interactions that\ncan be incorporated into NPCs. Additionally, It can be\nused to generate character backstories and personalities,\nwhich can inform the development of NPCs. The authors\nin [166] have trained and used GPT-2 for text generation\nof video games. They have trained GPT-2 on a large\ncorpus of video game quests and used a GPT model\nto generate the dialogue for quest-giver NPCs in role-\nplaying games. The output has shown that GPT can learn\nthe structure and linguistic style of the games, and the\nquality of the content it has generated is high, making it\na good alternative to writing new RPG quests by hand.\n3) Challenges: GPTs are computationally expensive and\nrequire high computing resources to do their purpose. This\nmeans that implementing them in a game would require\npowerful hardware and this could have an impact on the\nperformance of the games. Lack of training data: GPTs require\nlarge amounts of high-quality training data to be effective.\nIn the gaming industry, this could be dif\ufb01cult to obtain, as\ngaming data are likely to be fragmented and less structured\nthan the kind of data used to train GPT models [131].", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 4301, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "cb5beda1-04c6-4cce-9f62-f982392484d2": {"__data__": {"id_": "cb5beda1-04c6-4cce-9f62-f982392484d2", "embedding": null, "metadata": {"page_label": "25", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "ff7fad39-f51a-42e5-8dd1-9d33dd480f7c", "node_type": "4", "metadata": {"page_label": "25", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "hash": "4b34e9e585f89e26ad252edf2529eba138c42159ca0f376f35680a9a33c34639", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "dc33c5a8-604b-4c82-aa1e-501133d8f731", "node_type": "1", "metadata": {"page_label": "25", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "hash": "ac059f39cd52b13f3f72e8c164504e618b9996ddcf3c3e920bd33bca2958c7fb", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "The output has shown that GPT can learn\nthe structure and linguistic style of the games, and the\nquality of the content it has generated is high, making it\na good alternative to writing new RPG quests by hand.\n3) Challenges: GPTs are computationally expensive and\nrequire high computing resources to do their purpose. This\nmeans that implementing them in a game would require\npowerful hardware and this could have an impact on the\nperformance of the games. Lack of training data: GPTs require\nlarge amounts of high-quality training data to be effective.\nIn the gaming industry, this could be dif\ufb01cult to obtain, as\ngaming data are likely to be fragmented and less structured\nthan the kind of data used to train GPT models [131]. In\naddition, GPTs can perform content creation based on patterns\nthey have learned from their training data, which means that\nthey can be unpredictable. The content generated by GPT\nmay be nonsensical or inappropriate content to the game.\nIn the context of gaming, this lack of control could lead to\nundesirable or even offensive game content. GPTs can generate\ntext based on user input, they can\u2019t interact with the game\nenvironment in the same way a human player can. This limits\ntheir usefulness in gaming and may make them less effective\nthan other AI technologies.\n4) Summary: GPTs can transform the gaming industry by\ncontributing to improved game dialogue creation, enhanced\nnon-player characters, personalized gameplay, procedural con-\ntent generation, chatbot generation, and analyzing players\u2019\nabilities. However, it also has potential challenges that are to\nbe addressed, such as the need for high computing resources, a\nlack of control over content creation, and restricted interaction\nwith the game environment. In addition, the most important\nchallenge in adopting a GPT model in gaming is a lack of\ntraining data. If the challenges are addressed and the gaming\nindustry evolves with properly structured data to train a GPT\nmodel, then GPTs can revolutionize the \ufb01eld of gaming.\nJ. Marketing\n1) Introduction: Traditional marketing primarily relied on\ntraditional media channels, such as television, radio, newspa-\npers, and magazines, to reach consumers. Companies used to\ndevelop marketing campaigns based on demographic data, and\nmass media channels were used to broadcast these campaigns\nto a broad audience. However, the advancements in technology\nhave brought about signi\ufb01cant changes in the marketing indus-\ntry, and companies are increasingly integrating new marketing\nstrategies evolved through technologies to reach and engage\nwith customers. One of the signi\ufb01cant transformations has\nbeen the rise of digital marketing channels such as social me-\ndia, search engines, Email, and mobile applications that allow", "mimetype": "text/plain", "start_char_idx": 3573, "end_char_idx": 6335, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "7c85281f-d99f-46be-a194-fb58f0c2aff4": {"__data__": {"id_": "7c85281f-d99f-46be-a194-fb58f0c2aff4", "embedding": null, "metadata": {"page_label": "26", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "41ea2a3a-10f7-4149-8948-f7581630abca", "node_type": "4", "metadata": {"page_label": "26", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "hash": "9497018af64ef6fd2eaf57fbdd4307389fa960106e0261efa5a840fc9bd80c2d", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "c6c982d6-81c0-4653-a08e-e8e1228304e9", "node_type": "1", "metadata": {}, "hash": "a4ce23d7a4b562fa259aedb575cb25d047dd0bc20d257e31eca00d01c7acabc4", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "26\ncompanies to target speci\ufb01c populations with precision and\nprovide real-time feedback on campaign performance, allow-\ning for more effective and ef\ufb01cient marketing. Technology has\nalso given rise to marketing automation tools such as customer\nrelationship management systems, chat-bots, and personalized\nemail marketing, which have made marketing more ef\ufb01cient\nand effective. Another signi\ufb01cant transformation has been the\nuse of big data and analytics to better understand customer\nbehaviour and preferences. This has allowed companies to\ncreate more personalized and targeted campaigns based on\nspeci\ufb01c customer needs and preferences.\n2) Impact of GPT in Marketing : The marketing industry\nhas evolved with various AI-powered techniques. This revo-\nlution started in marketing by providing businesses with pow-\nerful tools for generating insights, automating processes, and\nimproving customer experiences. GPTs are also being used\nin marketing to generate engaging and personalized content.\nSome of the applications of GPT in marketing include content\ncreation, customer service, and personalized advertising.\n\u2022 Content creation: GPTs can contribute to marketing in\nvarious ways, such as by improving speed and ef\ufb01ciency\nin content creation, ensuring consistency and quality of\ncontent, generating personalized content, creating multi-\nlingual content, and repurposing existing content. It can\nbe trained on a company\u2019s existing marketing materials\nand customer data, allowing it to create new content,\nsuch as blog posts, social media updates, and product\ndescriptions, in a fast and ef\ufb01cient manner. Despite its\nspeed, it maintain high standards for quality and consis-\ntency. Moreover, GPTs [162] can generate personalized\ncontent based on customer data, such as search history\nand past purchases. This helps create content that is rel-\nevant to the users\u2019 desires, leading to better engagement\nand conversion rates. GPTs can also generate content in\nvarious languages, allowing marketers to expand their\nreach across regions. Copy.ai [167] has used GPT-3 to\ngenerate human-like text that is optimized for marketing\npurposes such as website copy, social media posts, ad-\nvertisement copy, and email campaigns. This means that\nmarketer personnel no longer focus on content creation.\nInstead, they can spend productive time improving the\nother aspects of marketing.\n\u2022 Customer service: GPTs can be trained on customer ser-\nvice conversations and chat logs to generate more natural\nresponses, like humans. This can help business person-\nnel provide better customer service 24/7 and save time\nand resources. It can be trained to generate automated\nresponses for frequently asked questions, providing faster\nresponses to customers and ensuring consistency in the\nquality of replies. GPTs can also analyze customers\u2019 emo-\ntions and sentiments, enabling businesses to proactively\naddress negative feedback. This is particularly helpful in\nmaintaining customers\u2019 trust. The authors in [168] have\nused GPT-3 model for automated drafting of responses\nfor incoming mails. They used it to understand the mail,\nand then software engineering and business studies were\nused to understand the challenges encountered and \ufb01nally,\nthe response generated after a thorough understanding of\nthe context of the mail. The authors have concluded that\napplying GPT-3 to rationalize email communication is\nfeasible both technically and economically.\n\u2022 Personalized advertising: GPTs can generate personalized\ncontent such as product descriptions, blog posts, and\nsocial media captions tailored to individual customers\u2019\npreferences and interests. This can help businesses create\ncontent that resonates with their target audience, leading\nto higher engagement and conversion rates. By analyzing\ncustomer data, GPTs can segment customers according\nto their behaviour, interests, and preferences. As a result,\nbusinesses can tailor their marketing campaigns to each\nsegment and provide personalized messaging and offers\nthat are more likely to connect with each customer group.\nThe authors in [169] have proposed a generative model\nto identify the name of the product from the product text\nand use this information \ufb01lter to improve the product\nrecommendation based on the product retrieval model.\nThis method has been implemented in the dynamic prod-\nuct advertising system of Yahoo. It is observed that the\nrecommendation system has recommended the product\nbased on the user\u2019s interest, and it was evaluated using an\nA/B test to serve similar products in an ad carousel, which\ncan help the system to explore more products ef\ufb01ciently.\n\u2022 Forecast analysis: Using customer data analysis, GPTs\ncan forecast future behaviour and buying patterns.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 4718, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "c6c982d6-81c0-4653-a08e-e8e1228304e9": {"__data__": {"id_": "c6c982d6-81c0-4653-a08e-e8e1228304e9", "embedding": null, "metadata": {"page_label": "26", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "41ea2a3a-10f7-4149-8948-f7581630abca", "node_type": "4", "metadata": {"page_label": "26", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "hash": "9497018af64ef6fd2eaf57fbdd4307389fa960106e0261efa5a840fc9bd80c2d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "7c85281f-d99f-46be-a194-fb58f0c2aff4", "node_type": "1", "metadata": {"page_label": "26", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "hash": "06e3189737b227e3a67aca4a056c8c7f1c69b7b0c4b5dd2019976215f9f41a02", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "By analyzing\ncustomer data, GPTs can segment customers according\nto their behaviour, interests, and preferences. As a result,\nbusinesses can tailor their marketing campaigns to each\nsegment and provide personalized messaging and offers\nthat are more likely to connect with each customer group.\nThe authors in [169] have proposed a generative model\nto identify the name of the product from the product text\nand use this information \ufb01lter to improve the product\nrecommendation based on the product retrieval model.\nThis method has been implemented in the dynamic prod-\nuct advertising system of Yahoo. It is observed that the\nrecommendation system has recommended the product\nbased on the user\u2019s interest, and it was evaluated using an\nA/B test to serve similar products in an ad carousel, which\ncan help the system to explore more products ef\ufb01ciently.\n\u2022 Forecast analysis: Using customer data analysis, GPTs\ncan forecast future behaviour and buying patterns. This\nallows businesses to customize their marketing campaigns\nto each customer\u2019s desires based on their purchase pat-\nterns, increasing the likelihood of conversion or purchase.\nThe authors in [170] have used chatGPT to perform pre-\ndictive modelling based on past data. They have used the\nGPT model to predict the future based on the customer\u2019s\nbehaviour and buying pattern. This primarily helps the\nsystem to recommend the products to the customers as\nper their desires.\n3) Challenges: GPTs are designed to generate content that\nimitates human writing, but the content generated may not\nalign with the brand\u2019s image or message. This lack of control\ncan be a potential challenge for marketers. Another challenge\nthat applies to all learning technologies is that data bias is\npossible in GPTs [138]. Based on the large dataset of text used\nfor training, if the data is biased, it will affect the generated\ncontent, which may also exhibit the same biases. GPT is\ncomplex and dif\ufb01cult to interpret, making it challenging to\nexplain how the model arrived at its conclusions. This lack\nof transparency can lead to a lack of trust in adopting GPTs,\nand marketing teams may struggle to make improvements in\ntheir strategies. As like every AI technology, there are ethical\nconcerns associated with GPT models. For instance, the use\nof GPT in marketing could raise concerns about the use of\npersonal data and privacy, particularly if the model is used to\ngenerate targeted advertising or personalized content. To avoid\nany negative consequences, companies must ensure they use\nthese models ethically and transparently.\n4) Summary: Using GPTs in marketing can provide various\nbene\ufb01ts, such as better content creation, personalized messag-\ning, increased ef\ufb01ciency, competitive advantage, and enhanced\ncustomer experience. However, this strategy also involves", "mimetype": "text/plain", "start_char_idx": 3761, "end_char_idx": 6568, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "f39b1126-2e93-4907-9942-6402d0a4d732": {"__data__": {"id_": "f39b1126-2e93-4907-9942-6402d0a4d732", "embedding": null, "metadata": {"page_label": "27", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "bb11665f-d289-4b56-92f4-77200f9f89ae", "node_type": "4", "metadata": {"page_label": "27", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "hash": "07201db92191773bb00fff0feea4d6a3e022eada60a43f06238225c3c35d979e", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "c123dbfb-5155-4f58-896e-8e5721200106", "node_type": "1", "metadata": {}, "hash": "fea0751a077d1e6ee10a5f101ccf65a05cae2f62735655e592eaa259486615fb", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "27\npotential challenges, such as limited control, data bias, lack of\ntransparency, and ethical considerations. Therefore, companies\nmust consider the advantages and drawbacks of GPT adoption\nin marketing, and implement these models ethically and trans-\nparently to avoid negative outcomes. Successful integration\nof GPTs in marketing requires proper planning, a skilled\nworkforce, and continuous monitoring to ensure the desired\nresults and mitigate any potential risks.\nK. Finance\n1) Introduction: The \ufb01nance industry, also known as the\n\ufb01nancial sector, is a broad term that encompasses a wide range\nof institutions and businesses that provide \ufb01nancial services to\nindividuals, businesses, and governments. The \ufb01nance industry\nplays a critical role in the global economy, facilitating the \ufb02ow\nof funds between savers and investors, managing risk, and\nproviding \ufb01nancial services and products to support economic\ngrowth. The \ufb01nance industry has been the leader in technology\nadoption in recent years, with a focus on improving ef\ufb01ciency,\nreducing costs, and delivering better customer experiences.\nThe adoption of technologies like big data and analytics,\nmobile and digital payments, blockchain and distributed ledger\ntechnology, AI and ML, and cloud computing make the sector\nmore \ufb02exible, scalable, trustworthy, transparent, secured, and\neasier to access.\n2) Impact of GPT in Finance: GPT has greatly in\ufb02uenced\n\ufb01nance by automating customer support using chatbots and\nvirtual assistants, enhancing fraud detection, offering invest-\nment insights and recommendations based on \ufb01nancial data\nand news, assisting with risk assessment for investments and\nloans, impacting algorithmic trading strategies, simplifying\ncompliance with regulations by analyzing legal documents,\nimproving credit scoring and loan processes, and emphasizing\nthe importance of handling sensitive \ufb01nancial data securely\nand transparently.\n\u2022 Sentiment analysis: Sentiment analysis is a technique\nused in the \ufb01nance industry to evaluate the sentiment of\ninvestors [171] and the general public towards speci\ufb01c\ncompanies, industries, or markets by analyzing news ar-\nticles, social media posts, and other text-based sources of\ninformation. GPT has the potential to improve sentiment\nanalysis in \ufb01nance by providing more accurate and de-\ntailed analyses of \ufb01nancial data. With sentiment analysis,\nthe industry can predict stock prices by assessing the\nsentiment of news articles, social media posts, and other\nsources of information about a particular company or in-\ndustry to make informed investment decisions. By utiliz-\ning sentiment analysis, GPTs can aid \ufb01nancial institutions\nin identifying potential risks and taking appropriate action\nto mitigate them. The authors in [172] have investigated\nhow incorporating a lexicalized ontology can enhance\nthe performance of aspect-based sentiment analysis by\nextracting indirect relationships in user social data. The\ninvestigation results show that the analysis has given 98%\naccuracy.\n\u2022 Financial forecasting: GPTs can be trained on past \ufb01-\nnancial market data to predict future trends in the stock\nmarket, exchange rates, and other \ufb01nancial metrics. This\ncan help investors and \ufb01nancial organizations make more\naccurate predictions and reduce their risk exposure. With\nthe ability to analyze and process the natural language,\nGPTs can be used to analyze and interpret \ufb01nancial data,\nnews, and other related information. Financial analysts\nand researchers can use the ability to analyze natural\nlanguage to extract insights from unstructured data like\nnews articles, social media content, and other information\nthat is relevant to forecasting. This can help improve the\naccuracy of \ufb01nancial forecasting models by providing\na more comprehensive view of market trends and sen-\ntiments. This analysis may help improve the accuracy\nof prediction. Financial analysts can use the model to\nidentify the relationship between the \ufb01nancial parameters\nthat could change the market conditions in advance. This\nprediction may be helpful for investors as they make\ninvestment decisions.\n\u2022 Trading strategies: GPTs can also be used to analyze\nmarket trends and historical data to develop trading\nstrategies. This can help traders make better decisions in\nterms of trading to increase their pro\ufb01tability. GPTs can\nbe used to identify the potential risks in trading portfolios.\nBy analyzing the large volume of information related to\ntrading, GPT will get the potential to identify the risk\nparameters and provide insights into how to mitigate these\nrisks.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 4558, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "c123dbfb-5155-4f58-896e-8e5721200106": {"__data__": {"id_": "c123dbfb-5155-4f58-896e-8e5721200106", "embedding": null, "metadata": {"page_label": "27", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "bb11665f-d289-4b56-92f4-77200f9f89ae", "node_type": "4", "metadata": {"page_label": "27", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "hash": "07201db92191773bb00fff0feea4d6a3e022eada60a43f06238225c3c35d979e", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "f39b1126-2e93-4907-9942-6402d0a4d732", "node_type": "1", "metadata": {"page_label": "27", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "hash": "694a86c47d75f92d0e0c003e39885498046d18d36e2e86ea644a6ca80ddf1b77", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "This can help improve the\naccuracy of \ufb01nancial forecasting models by providing\na more comprehensive view of market trends and sen-\ntiments. This analysis may help improve the accuracy\nof prediction. Financial analysts can use the model to\nidentify the relationship between the \ufb01nancial parameters\nthat could change the market conditions in advance. This\nprediction may be helpful for investors as they make\ninvestment decisions.\n\u2022 Trading strategies: GPTs can also be used to analyze\nmarket trends and historical data to develop trading\nstrategies. This can help traders make better decisions in\nterms of trading to increase their pro\ufb01tability. GPTs can\nbe used to identify the potential risks in trading portfolios.\nBy analyzing the large volume of information related to\ntrading, GPT will get the potential to identify the risk\nparameters and provide insights into how to mitigate these\nrisks. The authors in [173] have used a popular GPT for\nstock market trend prediction. The results show that the\nmethod used is simple but the ef\ufb01ciency and accuracy of\nthe method are very effective. The prediction it has made\nis very close to the reality.\n\u2022 Risk prediction and management:The adoption of GPT\ncan enhance the process of risk prediction and manage-\nment in several ways. It can improve data analysis by\ndetecting patterns that may pose a risk. It can also help\nin enhancing fraud detection by analyzing transaction\ndata and identifying fraudulent activity based on patterns.\nAdditionally, GPT can be utilized to make better portfolio\nmanagement decisions by analyzing historical industry\ndata, company \ufb01nancial statements, and news articles, as\nwell as social media feeds. This portfolio management\nprocess can provide valuable information about the in-\nvestment risk of a given organization, enabling informed\ninvestment decisions and effective risk management.\n3) Challenges: GPTs have more challenges in the \ufb01nance\nsector. Primarily, they demand signi\ufb01cant computational re-\nsources to train and deploy, which can be expensive and time-\nconsuming for \ufb01nancial organizations to implement. Another\nchallenge is that, even though GPTs are capable of producing\nprecise predictions, they can be challenging to interpret, which\ncan present a problem for \ufb01nancial institutions seeking to\ncomprehend the reasoning behind speci\ufb01c predictions [174].\nThis lack of interpretability can harm risk management objec-\ntives.Implementing GPT in \ufb01nance sector can be vulnerable\nto adversarial attacks, which are designed to manipulate the\nmodel\u2019s output by injecting false data. This can be particularly\nproblematic for \ufb01nancial institutions that rely on GPTs for risk", "mimetype": "text/plain", "start_char_idx": 3663, "end_char_idx": 6321, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "c28529fe-bbb5-4a01-8b2a-c11421a06f61": {"__data__": {"id_": "c28529fe-bbb5-4a01-8b2a-c11421a06f61", "embedding": null, "metadata": {"page_label": "28", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "66a78f15-0021-4881-ab03-8e4c9d70d200", "node_type": "4", "metadata": {"page_label": "28", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "hash": "a52b3fc4f1709a0401209770f5676a82e219fff92d842140da5da6844c1a7c7c", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "80102867-5bec-4979-ae0d-55a907b37678", "node_type": "1", "metadata": {}, "hash": "5a8ff68e70c2c5b9e3292c089489c28a80082234bba461ef0e035ca11805bbbc", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "28\nmanagement and investment decisions. It also require large\namounts of training data to achieve high accuracy. However,\nin some cases, \ufb01nancial institutions may not have access to\nsuf\ufb01cient data to train the model effectively. GPTs can also\nbe biased if the training data used to develop the model is\nbiased. This can lead to inaccurate predictions and unintended\nconsequences.\n4) Summary: The use of GPTs in the \ufb01nance industry\nhas promising bene\ufb01ts such as improved risk management,\nenhanced fraud detection, better portfolio management deci-\nsions, and increased ef\ufb01ciency. However, it also has potential\nchallenges that need to be addressed, such as high computa-\ntional requirements, the complexity of implementation, limited\ninterpretability, vulnerability to adversarial attacks, limited\ntraining data, and bias in training data. So, the use of GPTs\nin the \ufb01nance industry presents signi\ufb01cant bene\ufb01ts but also\nrequires careful consideration of the challenges involved to\nensure the effective and secure deployment of these models.\nL. Summary On Impact of GPT models in Applications\nThe impact of GPTs in various applications and challenges\nwas highlighted. GPT with its varied usage has changed\nthe way people perceive facts such as content creation, en-\nhanced user interfaces, personalized learning, item tracking,\nself-awareness, market risk analysis, business forecasts and\nintrospection. However, there are concerns about the potential\nnegative impact of GPTs, such as the spread of fake news,\nbias in data and decision-making, not domain speci\ufb01c, ethical\nissues, data reliability, the complexity of implementation,\nmultimodal and multilingual support, security and privacy\nconcerns, vulnerable to data attacks, limited input data, ex-\nplainability of results, large model size, high computational\nrequirements and job loss. Despite these concerns, it is clear\nthat GPTs will continue to be a powerful tool for industries\nseeking to leverage the power of NLP and generative AI. As\nthe technology improves and new applications emerge, it will\nbe interesting to see how GPTs continue to shape the future\nof industries around the world.\nV. PROJECTS\nThis section presents the exciting projects developed using\nGPT model technologies for different applications mentioned\nin the above sections. Table. IV, Table. V shows the different\nlevels of such projects along with different parameters to\ncompare their characteristics leveraging the capabilities in\nmany real-life applications.\nA. SiriGPT\nSiri [175] is an intelligent digital assistant that enables\nApple device users to complete tasks more ef\ufb01ciently and\nwith ease, often anticipating their needs even before they make\nrequests. SiriGPT [176] [177] is a voice assistant powered by\na GPT model and developed entirely using shortcuts. Apple\ndevice users can utilize ChatGPT, fueled by GPT-3, by using\nan API key provided by OpenAI. This novel combination\noffers the best of both worlds, allowing users to utilize\nSiriGPT for voice commands and ChatGPT for generating\ntext. SiriGPT utilizes a tokenizer exclusively developed by\nApple that has been optimized for processing natural language\ntasks. SiriGPT\u2019s training data is not publicly available as it is\nexclusive to Apple. However, the language model is trained\non diverse text data from various sources such as books,\nnews articles, web pages, and other text data sources. This\nensures that SiriGPT can handle different natural language\ntasks accurately and ef\ufb01ciently. It has been reported that\nSiriGPT is one of the largest language models available, with\nover a trillion parameters.\nB. AI Dungeon\nLatitude, a startup based in Utah, created a groundbreaking\nonline game called AI Dungeon [178], which showcased a\nnovel type of collaboration between humans and machines.\nIt is a free-to-play, single-player, and multiplayer adventure\ngame that caught traction within the gaming community. It\ncombines fantasy and AI to create endless possibilities, e.g.,\none can take charge of a military operation to defend against\naliens or become a famous detective investigating an attempted\nmurder of the queen of the fairies. Unlike games with prede-\ntermined storylines, AI Dungeon allows you to guide the AI\nto generate unique characters and scenarios for your character\nto interact with.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 4297, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "80102867-5bec-4979-ae0d-55a907b37678": {"__data__": {"id_": "80102867-5bec-4979-ae0d-55a907b37678", "embedding": null, "metadata": {"page_label": "28", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "66a78f15-0021-4881-ab03-8e4c9d70d200", "node_type": "4", "metadata": {"page_label": "28", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "hash": "a52b3fc4f1709a0401209770f5676a82e219fff92d842140da5da6844c1a7c7c", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "c28529fe-bbb5-4a01-8b2a-c11421a06f61", "node_type": "1", "metadata": {"page_label": "28", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "hash": "6c0922e8df38055fede73a3c3062047ba8c2f7be8953ed4c8e09e3a060c3b169", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "This\nensures that SiriGPT can handle different natural language\ntasks accurately and ef\ufb01ciently. It has been reported that\nSiriGPT is one of the largest language models available, with\nover a trillion parameters.\nB. AI Dungeon\nLatitude, a startup based in Utah, created a groundbreaking\nonline game called AI Dungeon [178], which showcased a\nnovel type of collaboration between humans and machines.\nIt is a free-to-play, single-player, and multiplayer adventure\ngame that caught traction within the gaming community. It\ncombines fantasy and AI to create endless possibilities, e.g.,\none can take charge of a military operation to defend against\naliens or become a famous detective investigating an attempted\nmurder of the queen of the fairies. Unlike games with prede-\ntermined storylines, AI Dungeon allows you to guide the AI\nto generate unique characters and scenarios for your character\nto interact with. The game boasted about incorporating the\nGPT-3 text generator, but then the algorithm began producing\nunsettling narratives, including graphic depictions of sexual\nencounters involving minors [179].\nC. Copy.ai\nCopy.ai [180] is a mighty AI startup founded by Paul\nYacoubian in 2020. This project is created using GPT-3,\nmainly targeting business and marketing campaigns. It has the\nfollowing use cases: (i) For Teams: It assists with producing\ncustomized sales copy, composing long-form articles and\npages on a large scale, reusing content on various platforms,\nand creating product descriptions; (ii) For Emails: The AI-\npowered email writer takes care of the most challenging parts\nof marketing by creating email campaigns that are highly\neffective at converting leads, all with just a few clicks of\na button; (iii) For Blogs: By generating content briefs and\ncrafting one-of-a-kind SEO-focused blog articles every month,\nit can save a signi\ufb01cant amount of money for the business.\nIn addition, it\u2019s feasible to create briefs, outlines, and even\ninitial drafts in mere minutes, which can be utilized as an\nexcellent source of inspiration for writers to create high-quality\ncontent; (iv) Social Media: It aids in generating social media\nposts quickly and ef\ufb01ciently, allowing for a rapid expansion\nof the social media following. Additionally, Copy.ai includes\na suite of other tools, such as a headline analyzer, a language\ntranslator, and a content rephrase.\nD. Bond.AI\nBond.AI [181] is a company focused on AI for \ufb01nancial\ninstitutions, which has a headquarters in Little Rock, Arkansas.\nIt was established by Uday Akkarajuin in 2016 and prided", "mimetype": "text/plain", "start_char_idx": 3389, "end_char_idx": 5943, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "03921183-e74d-4d0a-b1d4-d388002f2aae": {"__data__": {"id_": "03921183-e74d-4d0a-b1d4-d388002f2aae", "embedding": null, "metadata": {"page_label": "29", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "28f3e5fb-c32d-413e-9322-adfda3096bb3", "node_type": "4", "metadata": {"page_label": "29", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "hash": "9b6a6a6dec38c26e79b4bc874bdd1384f72d56b836bb3c4f8545c1e3224a6b11", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "5955a91e-6770-4978-ae18-a028819e10da", "node_type": "1", "metadata": {}, "hash": "6b6c2d844e3bd63a41c497d0642c77300cba6d6c4fbe0988f03d812f017cf30e", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "29\nTABLE IV\nPROJECT SUMMARY TABLE .\nProject DeepScribe Meena Jukebox Uber\u2019s plato research dialogue systemPolyglot AI SiriGPTApplicationwidely used forHealthcare Lifestyle Entertainment Transport Education Lifestyle\nPurpose Medical documentationand to improve doctor-patient association\nPersonalized product rec-ommendation Enables the original mu-sic creation both artisti-cally compelling and com-mercially viable in a vari-ety of styles and genres\nEnhances user experience using Uberrides, helps drivers and riders inscheduling rides, navigating routes, pro-viding real-time updates on traf\ufb01c andweather conditions.\nenables absolute communication irre-spective of the language barrier acrossdifferent regions and cross-culturalism\nAssist with voice-based assistants\nGPT AdoptionCustomized version ofGPT\u2019s Google\u2019s seq2seqtransformer-based neuralnetwork architecturesimilar to Open AI\u2019s GPT\nGPT-2 extension called\u201dMulti-Scale Transform-ers for Music Modeling\u201d(MST) model\nGPT-2 GPT-0, GPT-1,GPT-2,GPT-3GPT-3\nDataset Not Disclosed Meena dataset over 40 bil-lion words , 341 GB cap-tured from public domainslike Reddit and social me-dia platforms\n1.2 million songs, 600,000pieces of sheet music,45,000 MIDI \ufb01les\nPersona-Chat with 160,000 conver-sational dialogues, Cornell Movie-Dialogs Corpus with 200,000 movieconversation, DailyDialog over 13,000dialogues, and\nCONLL-2003, Sentiment140 dataset,Reuters Corpus, 20 Newsgroupsdataset, WMT (Workshop on MachineTranslation) datasets and SQuAD(Stanford Question Answering Dataset)\nInformation not publisized\nBuilding BlocksRecurrent Neural Networkand Attention mechanismfueled by NLP techniques\nSeq2Seq Transformer-based Architecture Transformer-basedLanguage Model andAutoregressive model\nLanguage modeling, Dialogue model-ing, Discrete latent variabe modelingand response ranking\nLanguage Identi\ufb01cation, Named EntityRecognition (NER), Sentiment Analy-sis, Text Classi\ufb01cation, Machine Trans-lation, Question Answering\nTransformer-based neural network ar-chitecture\nEvaluation Met-rics Bleu score, perplexityBleu score, perplexityFrechet Audio Distance(FAD) and Pitch andRhythm Similarity\nBleu score, Perplexity and Distinct n-gram accuracy, precision, recall, , F1-score,Bleu score as well as cross-entropy lossor perplexity\nPerplexity, BLEU score, F1 score,ROUGE score, Human evaluation\nAddressed Chal-lenges Reduced Transcription er-rors and enhanced patientcare\nNatural and Engagingconversations Fresh orginical music con-tent creation and drasti-cally reducing the costand time by creating high-quality music contents,and also to preserve andadvance musical heritage.\ncustomer service, user experience, andoperational ef\ufb01ciency Multilingualism and Sentiment Analy-sis are the key challenges in NLP andPolyglot AI solved this problem byoffering a tool for supporting morethan40 languages and pre-trained sentimentanalysis model\nLanguage understanding and genera-tion, Data scarcity, Contextual under-standing, Text summarization, Senti-ment analysis, Named entity recogni-tion\nInput data Audio Text Audio Text Text AudioOwned By DeepScribe Google OpenAI Uber Uizard Technologies Apple\nTABLE V\nPROJECT SUMMARY TABLE (CONTINUED ).", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3178, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "5955a91e-6770-4978-ae18-a028819e10da": {"__data__": {"id_": "5955a91e-6770-4978-ae18-a028819e10da", "embedding": null, "metadata": {"page_label": "29", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "28f3e5fb-c32d-413e-9322-adfda3096bb3", "node_type": "4", "metadata": {"page_label": "29", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "hash": "9b6a6a6dec38c26e79b4bc874bdd1384f72d56b836bb3c4f8545c1e3224a6b11", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "03921183-e74d-4d0a-b1d4-d388002f2aae", "node_type": "1", "metadata": {"page_label": "29", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "hash": "3b9edba493a355cf738e4bbf7ffbfd414d22a80f40cee0d0ece0f9ac4ed7050d", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "286c4e19-b865-4046-980e-a13f80f01ec2", "node_type": "1", "metadata": {}, "hash": "c0ec90e9755e52d150e970450eccc7bcd7f557d2c39890cc5bc2f853c9963aae", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "customer service, user experience, andoperational ef\ufb01ciency Multilingualism and Sentiment Analy-sis are the key challenges in NLP andPolyglot AI solved this problem byoffering a tool for supporting morethan40 languages and pre-trained sentimentanalysis model\nLanguage understanding and genera-tion, Data scarcity, Contextual under-standing, Text summarization, Senti-ment analysis, Named entity recogni-tion\nInput data Audio Text Audio Text Text AudioOwned By DeepScribe Google OpenAI Uber Uizard Technologies Apple\nTABLE V\nPROJECT SUMMARY TABLE (CONTINUED ).\nProject AI Dungeon Copy.ai Bond AI Viable AI Channels Fire\ufb02ies.aiApplicationwidely used forGaming Business and marketingFinance Business Analytics AI Industry Business\nPurpose Interactive and engagingstorytelling experience forplayers\nhelp clients create writtencontent more quickly andeasily\nTo enhance the \ufb01nancialwell-being of clientsprovide businesses with intelligent in-sights to help them make better deci-sions\nprovide a platform for developers, datascientists, and machine learning prac-titioners to create, deploy, and managetheir AI models\nto simplify the meeting process andreduce the time and energy required fornote-taking and collaboration\nGPT AdoptionGPT-3 GPT-3 GPT-3 GPT-4 GPT-3 GPT-4Dataset Common Crawl, OpenAIGPT-2, and various textdatasets from Kaggle\nbooks, articles, and web-sites likely use of a combina-tion of publicly available\ufb01nancial datasets, propri-etary data, and client data\nInformation not publisized Users\u2019 own dataset Possible datasets: the Common V oicedataset from Mozilla having over 9,000hours of speech data in multiple lan-guagesBuilding BlocksMachine LearningModels, Text InputInterface, Game Engine,Content Database, PlayerFeedback System, CloudInfrastructure\nNLP, Language Models,Neural Networks NLP, Personalization,Conversational UserInterface, Data Analytics\nUnsupervised learning, Contextual un-derstanding, Sentiment analysis, Topicmodeling, Entity recognition\nPre-built models, Model training, Datapreparation, Collaboration Speech-to-Text Technology, NLP,Cloud Computing, Integrationtechnologies\nEvaluation Met-rics Response Coherence, Re-sponse Diversity, PlayerSatisfaction, Engagement,Realism, Novelty\nPerplexity, BLEU score,ROUGE score, F1 scoreIntent recognitionaccuracy, entity extractionaccuracy, and languagemodel perplexity\nPerplexity, Accuracy, F1 score, Wordsimilarity Accuracy, Precision and Recall, F1Score, Perplexity, User satisfactionSpeech Recognition Accuracy, NLPPerformance, Integration Performance,Task Completion Time, User Satisfac-tionAddressed Chal-lenges Narrative Generation,Content Creation,Personalization,Replayability,Accessibility, CreativeExpression\nLack of writing skills, In-consistency, Multilingualcontent creation\nPersonal \ufb01nancial man-agement, Customer en-gagement, Fraud detectionand prevention\nUnderstanding unstructureddata, Contextual understanding,Visualization and exploration of data,Customization and integration\nNatural language understanding, Scala-bility, Personalization, Integration withother systems, Maintenance and up-dates\nTime-consuming manual note-taking,Dif\ufb01culty in capturing important de-tails, Lack of visibility and accountabil-ity, Communication barriers\nInput data Text Text Audio and Text Text Text AudioOwned By Latitude Copy.ai Bond.AI Viable AI MiroMind AG Fire\ufb02ies AI\nitself on providing AI technology centred around human needs.\nThis innovative project offers a product named BondBot,\nwhich is powered by Empathy Engine 3.0 and ChatGPT, to\nenhance the \ufb01nancial health of clients. It assists \ufb01nancial insti-\ntutions and employers in promoting interconnected \ufb01nance by\noffering various tools to improve the institution\u2019s pro\ufb01tability\nand the \ufb01nancial health of its clients on a single network.\nIt uses customer data to create individual personas for every\nbank customer or small business, considering their behaviours,\nstrengths, and potential needs. This approach enables the plat-\nform to develop multiple customized pathways to holistically\nenhance clients\u2019 \ufb01nancial well-being.\nE. Viable\nViable [182] is a platform powered by GPT-4 that utilizes\nthe latest advancements in NLP and AI to offer businesses\nintelligent insights to aid their decision-making processes.\nCompanies can extract actionable insights from unstructured\ndata sources, such as social media posts, customer reviews,\nand survey responses, by employing Viable.", "mimetype": "text/plain", "start_char_idx": 2619, "end_char_idx": 7032, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "286c4e19-b865-4046-980e-a13f80f01ec2": {"__data__": {"id_": "286c4e19-b865-4046-980e-a13f80f01ec2", "embedding": null, "metadata": {"page_label": "29", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "28f3e5fb-c32d-413e-9322-adfda3096bb3", "node_type": "4", "metadata": {"page_label": "29", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "hash": "9b6a6a6dec38c26e79b4bc874bdd1384f72d56b836bb3c4f8545c1e3224a6b11", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "5955a91e-6770-4978-ae18-a028819e10da", "node_type": "1", "metadata": {"page_label": "29", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "hash": "7f99fa7e44b39521752dd729081e9745bed117949cdd567f5bd73d3782240c6e", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "It assists \ufb01nancial insti-\ntutions and employers in promoting interconnected \ufb01nance by\noffering various tools to improve the institution\u2019s pro\ufb01tability\nand the \ufb01nancial health of its clients on a single network.\nIt uses customer data to create individual personas for every\nbank customer or small business, considering their behaviours,\nstrengths, and potential needs. This approach enables the plat-\nform to develop multiple customized pathways to holistically\nenhance clients\u2019 \ufb01nancial well-being.\nE. Viable\nViable [182] is a platform powered by GPT-4 that utilizes\nthe latest advancements in NLP and AI to offer businesses\nintelligent insights to aid their decision-making processes.\nCompanies can extract actionable insights from unstructured\ndata sources, such as social media posts, customer reviews,\nand survey responses, by employing Viable. GPT assists in\ncomprehending the sentiment and context behind the data,\nresulting in valuable insights that can enhance a company\u2019s\nservices, products, and customer experience. Viable\u2019s \u201dInsight\nExplorer\u201d is a distinctive feature that enables users to interact\nwith and visualize their data via a user-friendly interface. In\naddition, the platform offers advanced analytics capabilities,\nincluding entity recognition, topic modelling, and sentiment\nanalysis. The GPT-based technology of Viable is continually\nevolving and advancing, which allows the platform to deliver\nmore precise and insightful data. Moreover, Viable provides\ncustomized integration and solutions to cater to the speci\ufb01c\nrequirements of each business.\nF . AI Channels\nAI Channels [183] is a platform that provides a comprehen-\nsive set of tools for developers, data scientists, and machine", "mimetype": "text/plain", "start_char_idx": 6183, "end_char_idx": 7892, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "d9ebe5f7-662b-47ad-87c4-6ea760a61589": {"__data__": {"id_": "d9ebe5f7-662b-47ad-87c4-6ea760a61589", "embedding": null, "metadata": {"page_label": "30", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "8e4ca1a7-db75-4585-89f7-0295395c8e7f", "node_type": "4", "metadata": {"page_label": "30", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "hash": "06735b7c02e2ad7d971812cbde1e324342f4e3acde2dfa1d9ab0b96bc33b1b4c", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "27335c1e-b2a3-4d70-9ba5-b1dd2cb21587", "node_type": "1", "metadata": {}, "hash": "27276ff1f4a1ac8d3bc13c6b5b223630f1ab4095d2c789ec4ca4def1e8d53a51", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "30\nlearning practitioners to develop, launch, and manage their AI\nmodels. The platform offers an all-in-one solution for creating\npersonalized AI models, starting from data preparation and\nmodel training to deployment and monitoring. Users can train\ntheir models on their data or, on pre-trained models provided\nby AI Channels. These models can be deployed as APIs\nor Docker containers on various infrastructures, including\ndifferent cloud platforms. It also provides a dashboard for\ntracking model performance and managing con\ufb01gurations. It\ncovers various use cases, including computer vision, NLP, and\nspeech recognition. The platform includes pre-built models for\ntasks such as image and text classi\ufb01cation, object detection,\nand sentiment analysis. Additionally, users can create their\nmodels using popular frameworks. The main objective of AI\nChannels is to make building and launching AI models more\naccessible to developers and businesses without specialized AI\nskills.\nG. Fire\ufb02ies.ai\nFire\ufb02ies AI [184] is a privately held company based in San\nFrancisco, California, founded by Krish Ramineni and Sam\nUdotong. Fire\ufb02ies AI software is powered by GPT-4 to au-\ntomate notes-taking tasks and collaborations during meetings.\nIt is compatible with various video conferencing platforms,\nincluding Zoom, Google Meet, and Microsoft Teams, and it\ncan transcribe meeting audio and video content in real time.\nIts primary function is based on speech-to-text technology,\nwhich enables it to generate a searchable transcript of the\nmeeting, which can be used for later review and to recall\nessential points and action items. Additionally, the software\nutilizes NLP capabilities that can identify signi\ufb01cant keywords\nand phrases within the conversation. Apart from note-taking,\nFire\ufb02ies AI includes collaboration tools such as assigning tasks\nand sharing notes with other team members. It can integrate\nwith project management and task tracking tools to auto-\nmatically generate tasks based on the identi\ufb01ed action items\nduring the meeting. Fire\ufb02ies AI provides several customization\noptions to suit particular use cases and work\ufb02ows. Users can\ncon\ufb01gure the software to automatically join speci\ufb01c meetings\nor capture audio only from speci\ufb01c speakers. It allows users\nto specify particular words and phrases to highlight in the\ntranscript, making it easier to identify critical points during the\nlater review. Thus, Fire\ufb02ies AI aims to simplify the meeting\nprocess and reduce the time and energy required for note-\ntaking and collaboration.\nH. Uber\u2019s Plato Research Dialogue System\nUber\u2019s AI Lab introduced Uber\u2019s Plato Research Dialogue\nSystem in 2020 developed by a team of researchers and engi-\nneers to enable the intelligence in riding experience. PLATO -\nPre-trained Dialogue Generation Model with Discrete Latent\nVariable [185]. Uber\u2019s Plato Research Dialogue System uses\nGPT-2, a large-scale language model developed by OpenAI\nin 2019. Uber\u2019s Plato Research Dialogue System project\nused several datasets to train and evaluate their conversa-\ntional agents such as Persona-Chat contains 160,000 conversa-\ntional dialogues, Cornell Movie-Dialogs Corpus with 200,000\nmovie conversations, DailyDialog over 13,000 dialogues, and\nEmpatheticDialogues over 25,000 user dialogues. The main\ncomponents in developing the GPT-powered PLATO project\nare language modelling, dialogue modelling, discrete latent\nvariable modelling and response ranking. The Plato Research\nDialogue System was trained on a massive corpus of text data\nconsisting of over 40 GB of uncompressed text while Bleu\nscore, Perplexity and Distinct n-gram are the evaluation met-\nrics used for training and testing the PLATO project. Uber\u2019s\nAI PLATO has addressed many key challenges like customer\nservice by personalizing user feedback with conversational AI\nagent, user experience using the Uber platform for scheduling\nrides, navigating routes, and providing real-time updates, and\nincreasing operational ef\ufb01ciency by reducing the need for\nhuman customer service representatives and enabling faster\nand more accurate communication between riders, drivers, and\nthe Uber app.\nI. Jukebox\nJukebox, a GPT-powered music creation, was developed\nin 2020 as an extension of Open AI\u2019s GPT language model\n[186]. Jukebox\u2019s goal is to push the boundaries of what AI can\naccomplish in the world of music creation and to investigate\nfresh applications for AI.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 4402, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "27335c1e-b2a3-4d70-9ba5-b1dd2cb21587": {"__data__": {"id_": "27335c1e-b2a3-4d70-9ba5-b1dd2cb21587", "embedding": null, "metadata": {"page_label": "30", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "8e4ca1a7-db75-4585-89f7-0295395c8e7f", "node_type": "4", "metadata": {"page_label": "30", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "hash": "06735b7c02e2ad7d971812cbde1e324342f4e3acde2dfa1d9ab0b96bc33b1b4c", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "d9ebe5f7-662b-47ad-87c4-6ea760a61589", "node_type": "1", "metadata": {"page_label": "30", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "hash": "2e40c7ec290c76931b0bdd067e53ed7312d896a3613ca7247a173d13728d8153", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Uber\u2019s\nAI PLATO has addressed many key challenges like customer\nservice by personalizing user feedback with conversational AI\nagent, user experience using the Uber platform for scheduling\nrides, navigating routes, and providing real-time updates, and\nincreasing operational ef\ufb01ciency by reducing the need for\nhuman customer service representatives and enabling faster\nand more accurate communication between riders, drivers, and\nthe Uber app.\nI. Jukebox\nJukebox, a GPT-powered music creation, was developed\nin 2020 as an extension of Open AI\u2019s GPT language model\n[186]. Jukebox\u2019s goal is to push the boundaries of what AI can\naccomplish in the world of music creation and to investigate\nfresh applications for AI. A variation of the GPT architecture,\nthe \u201dMulti-Scale Transformers for Music Modeling\u201d (MST)\nmodel, was created speci\ufb01cally to handle the intricate and\nmulti-scale nature of musical data. Additionally, Jukebox can\nproduce lyrics that match the music\u2019s tone and style. A sizable\nand varied dataset of musical recordings, lyrics, and related\nmetadata was used to train Jukebox such as 1.2 million songs\nsourced including Lakh MIDI Dataset, Free Music Archive,\nSpotify and Tidal, 600,000 pieces of sheet music were sourced\nfrom IMSLP (International Music Score Library Project),\nand 45,000 MIDI \ufb01les from Lakh MIDI Dataset and the\nMIDIworld collection. Faster training times and more effective\nuse of computational resources were made possible by the\ndistributed computing setup with 2048 TPU( Tensor Process-\ning Unit) cores used to train the Jukebox model. Training the\nmodel required signi\ufb01cant computational resources demanding\nfaster training times by the distributed computing setup with\n2048 TPU (Tensor Processing Unit) cores used to train the\nJukebox model. A combination of subjective and objective\nmetrics was used to assess and test Jukebox. In a large-scale\nsubjective assessment, more than 1,000 participants listened\nand rated each one individually determining the overall score\nfor each song produced. On the other side, objective assess-\nments were conducted by evaluating Frechet Audio Distance\n(FAD) and Pitch and Rhythm Similarity. Overall, Jukebox\nrevolutionizes with its signi\ufb01cant advancement in the music\nindustry through creative inspiration, music production, music\neducation and preservation of music heritage.\nJ. Meena\nGoogle\u2019s Meena project was developed by Google Research\nTeam in 2020 for providing personalized product recom-\nmendations [187]. The primary goals of the Meena project\nempowered the lifestyle sector to enhance the user experience", "mimetype": "text/plain", "start_char_idx": 3689, "end_char_idx": 6276, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "16b69865-7146-4a44-925c-6e91e2989467": {"__data__": {"id_": "16b69865-7146-4a44-925c-6e91e2989467", "embedding": null, "metadata": {"page_label": "31", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "dcebafd3-a3fb-47c5-9c9b-67bba01fedc6", "node_type": "4", "metadata": {"page_label": "31", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "hash": "19ace06464932326fb04f8d5f517edae5b824d26ee4251d8f3c58f5423d69437", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "85217703-6e9b-4ced-9736-6eace695355e", "node_type": "1", "metadata": {}, "hash": "d8b76ed2b64090df2fb2383cb30cfaaf99239a823c308a03487acc775df8e587", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "31\nand customer service by recommending goods and services\non a personalized basis. The project designed a GPT using\nthe seq2seq transformer-based neural network architecture,\nin particular for open-domain conversational agents. The ar-\nchitecture was pre-trained over 341 GB of text captured\nfrom Reddit and other social platforms containing over 40\nmillion words and called this massive collection as \u2019Meena\nDataset\u2019. Meena was tested using the automated performance\nmetrics known as Bleu score and perplexity on a cluster\nof HPC nodes with a total of 2048 NVIDIA V100 GPUs.\nOne of the biggest challenges solved Meena was building\ntrust and generating reliable engaging human-like conservation\nthat typically enhances user satisfaction and personalization.\nMeena has achieved state-of-the-art performance compared to\nother open-domain chatbots and revolutionized the wide range\nof applications in the lifestyle industry and a way beyond\nby providing natural and engaging responses through virtual\nassistants, customer service bots and personal shoppers.\nK. DeepScribe\nDeepScribe was a GPT-based medical project developed\nin 2019 by the student team at the University of California\nby partnering with giant US-based healthcare providers such\nas One Medical, Stanford Medicine, Mount Sinai and Sutter\nHealth [188]. The DeepScribe\u2019s technology aims at transcrib-\ning medical conversation allowing doctors to treat the patients\nrather than noting down the patient\u2019s history, enhancing the\ndoctor-patient relationship and targeting the overall quality\nof patient care. Although DeepScribe used the customized\nvariants of Open AI, the technical details of the GPT model\nused for customizing the model were not disclosed which was\noptimized for medical transcription tasks.\nL. Polyglot AI\nPolyglot AI is a communication platform designed to gen-\nerate text in multiple languages and process the data by\nperforming several tasks such as advanced NLP techniques,\ntext translation, and sentiment analysis. The potential features\nof Polyglot AI have been exploited in the following application\nareas such as language translation, chatbots, language learning\ntools, content creation, customer support, and data analysis\nacross different languages and regions. Polyglot AI is built\nbased on different variants of GPT models, and state-of-the-\nart language model architecture for NLP tasks, which uses the\nself-supervised learning approach.\nThe Polyglot AI was pre-trained using a large amount\nof textual data on multiple languages simultaneously in an\nunsupervised environment using a shared architecture, Multi-\nlingual Universal Sentence Encoder (MUSE). MUSE devel-\noped by Google, is a pre-trained DL model used for cross-\nlingual TL, that encodes the text into common vector space\nfor multiple languages. Thus, the Polyglot language model\nwas created with the following pre-training techniques as\nMasked Language Modeling (MLM), Translation Modeling\nLanguage (TML), sequence-to-sequence modelling and cross-\nlingual TL. The pre-trained language model is \ufb01ne-tuned and\nevaluated by standard benchmarks and metrics such as the\nBLEU score (Bilingual Evaluation Understudy), METEOR\n(Metric for Evaluation of Translation with Explicit ORdering)\nor F1-score. Remarkably, Facebook used new Polyglot AI\nto translate between 100 languages [189]. Thus Polyglot AI\nenables absolute communication irrespective of the language\nbarrier across different regions and cross-culturalism.\nThus, this section focused on several exciting real-life\nprojects which are developed and used for humankind. These\nprojects were discussed by presenting Table ?? highlighting\nthe details of the project with model architecture, datasets\nused, training and testing, and evaluation metrics involved with\nthe challenges addressed. The next section will discuss the\nopen research issues and future directions for the potential\nbene\ufb01ts of GPT models.\nVI. OPEN RESEARCH ISSUES AND FUTURE DIRECTIONS\nThis section highlights the various open research issues con-\ncerned with the implementation and adoption of sustainable\nGPT models. It also provides insights into future research\ndirections for the betterment of researchers in the \ufb01eld of\nGPT development. Fig. 9 outlines the many issues that can\ndevelop while using GPT models, as well as the various future\napproaches that need to be considered for the effective usage\nof GPT models.\nA. Domain Speci\ufb01c GPT models\nDomain-speci\ufb01c GPT models are mandated in almost all\napplications; developing these models is still challenging and\nan open issue within GPT.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 4563, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "85217703-6e9b-4ced-9736-6eace695355e": {"__data__": {"id_": "85217703-6e9b-4ced-9736-6eace695355e", "embedding": null, "metadata": {"page_label": "31", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "dcebafd3-a3fb-47c5-9c9b-67bba01fedc6", "node_type": "4", "metadata": {"page_label": "31", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "hash": "19ace06464932326fb04f8d5f517edae5b824d26ee4251d8f3c58f5423d69437", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "16b69865-7146-4a44-925c-6e91e2989467", "node_type": "1", "metadata": {"page_label": "31", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "hash": "2851306e43448af1fc94b15d5f140b62b5d33f0c90d8a68275e2a330a50ae133", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "The next section will discuss the\nopen research issues and future directions for the potential\nbene\ufb01ts of GPT models.\nVI. OPEN RESEARCH ISSUES AND FUTURE DIRECTIONS\nThis section highlights the various open research issues con-\ncerned with the implementation and adoption of sustainable\nGPT models. It also provides insights into future research\ndirections for the betterment of researchers in the \ufb01eld of\nGPT development. Fig. 9 outlines the many issues that can\ndevelop while using GPT models, as well as the various future\napproaches that need to be considered for the effective usage\nof GPT models.\nA. Domain Speci\ufb01c GPT models\nDomain-speci\ufb01c GPT models are mandated in almost all\napplications; developing these models is still challenging and\nan open issue within GPT. While the current GPT models have\nbeen developed to understand natural language and generate\ncontent effectively, their performance may not be equally\neffective when handling speci\ufb01c domains, such as medicine,\nagriculture, etc. One of the key challenges in adapting to a\nparticular domain is the availability of domain-speci\ufb01c data.\nIt is well known that the performance of GPTs is directly\nproportional to the quality and quantity of data used for train-\ning the model. So, obtaining such quality data for a speci\ufb01c\ndomain is expensive and time-consuming, as the data are\nheterogeneous. Also, these data accumulations may even make\nthese models much larger, sometimes catastrophic too, leading\nto forgetting the knowledge attained during the process. To\novercome this issue, pre-training tasks and domain-speci\ufb01c\nmodel generation are integrated by data augmentation [190].\nAnother challenge is \ufb01ne-tuning the model to accustom to the\nunique characteristics and vocabulary of the domain. A few\ndomain-speci\ufb01c GPT models have been developed and imple-\nmented despite these challenges. There is a growing interest\nin creating more domain-speci\ufb01c GPTs for various domains.\nMoreover, these models will be trained using the knowledge\nacquired from large language models speci\ufb01c to domains.\nTherefore, these models can be \ufb01ne-tuned for speci\ufb01c tasks\nor domain-speci\ufb01c requirements with gradually improving\nperformance. GPT models have the potential to be trained in\nany context, and researchers are exploring new approaches\nand methods to address these challenges. Furthermore, these\nmodels will be more ef\ufb01cient, enhanced interpretability, and\ndomain generability than the existing Large language models", "mimetype": "text/plain", "start_char_idx": 3791, "end_char_idx": 6262, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "f4f0daa8-e0a9-44d5-9a98-685b37000aa0": {"__data__": {"id_": "f4f0daa8-e0a9-44d5-9a98-685b37000aa0", "embedding": null, "metadata": {"page_label": "32", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "b088c9a1-a53b-4a7c-927a-46cbc370b601", "node_type": "4", "metadata": {"page_label": "32", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "hash": "f7f9f671ef2028025912611ac1556270f408295ecd80b73464b3dba075635948", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "32\nFig. 9. Challenges and Future Directions.\nas they are customized to speci\ufb01c domain concerns and can\nprovide more concise and informative solutions. TL can be\nused for developing domain-speci\ufb01c GPT models. Domain-\nspeci\ufb01c GPT models were developed to summarize products\nbased on customer reviews on an E-commerce site, where the\nlanguage model is pre-trained on the Chinese-short summa-\nrization dataset and has obtained \ufb01ne-tuned results [130]. Be-\nsides these challenges, domain-speci\ufb01c models require higher\ncomputation costs for the resources and time spent in pre-\ntraining and relearning in downstream tasks during \ufb01ne-tuning\nof pre-trained domain-speci\ufb01c models. Therefore, domain-\nspeci\ufb01c model development must focus on optimizing resource\nconsumption and \ufb01ne-tuning the pre-trained model to alleviate\nthe forgetting problem involved in existing models.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 864, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "05cbc9bb-6c11-4516-87b5-a47b6c8937bc": {"__data__": {"id_": "05cbc9bb-6c11-4516-87b5-a47b6c8937bc", "embedding": null, "metadata": {"page_label": "33", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "4fe11246-aab3-4198-8a83-1a3b0e0777b1", "node_type": "4", "metadata": {"page_label": "33", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "hash": "21449d2694e9e3e35ebec05f782c7b4f52833eb48b781689d3249e4f0dbab726", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "71aeb199-b664-4109-93a8-6e59f1df0335", "node_type": "1", "metadata": {}, "hash": "c54c0c781e24cdff70a2ffc7d9a13edc9653d04d63f3e436f4c9a75982227975", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "33\nB. High Computational requirements\nAs the Transformer model utilizes varied heterogeneous\ndatasets for training and learning from the knowledge ac-\nquired, one of the key challenges of GPT models is high\ncomputational resources for pre-training and inference. The\ncomputational requirement continuously increases as the mod-\nels become more complex and larger. Depending on the size\nand complexity of the model and the available resources, the\ntime required to train the model can take days, weeks, or\neven months. Moreover, the inference time for these models\nis typically slower, making it challenging to use them for\nreal-time applications. This poses a signi\ufb01cant obstacle to\nadopting GPT models for many practical applications. Despite\nthese challenges, signi\ufb01cant efforts are underway to overcome\nthem. To accommodate the increasing data size and pre-\ntraining computational requirement, data enhancement-based\nGPT models were developed [190] by joining the downstream\ntasks and pertaining process by reconstructing the domain-\nspeci\ufb01c text before proceeding for pre-training and utilizing\nthe empirical knowledge rather than learning for falsy domain\ndata. Researchers are exploring various ways to optimize and\nspeed up the training and inference process, such as using\nspecialized GPUs and TPUs. They are also developing more\nef\ufb01cient algorithms and attempting to reduce the model size\nwithout sacri\ufb01cing performance. In addition, ChatGPT has\nevolved to include plugins [191] that enable statistical analysis\nfor real-time applications. By integrating these plugins with\nthe help of third-party services, ChatGPT can now be used\nfor analyzing real-time applications as well.\n1) Increasing Model size and Space Constraints: Devel-\noping and training large language models, such as a GPT\nmodel, can be a challenging task due to signi\ufb01cant technical\nand computational dif\ufb01culties as discussed. The size of GPT\nmodels presents a major challenge, as the computational\nresources required for training and inference increase with\nthe number of parameters that need to be trained. As the\nmodel size increases, it also requires more memory to store\nand manipulate parameters during training and inference [76].\nAcquiring and processing vast amounts of high-quality training\ndata is another challenge in training large language models like\nGPT. For instance, GPT-4, which is the largest GPT model to\ndate with 1 trillion parameters, demands a massive amount\nof computational resources, such as specialized hardware like\nGPUs and TPUs, spatial requirements, and high-speed network\nconnections to transfer data between different parts of the\nsystem. Model evaluation and interpretation are also critical\nchallenges. Since large language models like GPT are trained\non a massive scale, understanding how the model makes\npredictions and why it generates speci\ufb01c outputs is dif\ufb01cult.\nEvaluating the quality and accuracy of the model\u2019s output and\nidentifying and addressing biases or errors in its performance\ncan also be challenging.\nAs these and other signi\ufb01cant efforts continue, we can\nexpect the challenge of computational resource requirements\nfor GPT models to transform into a strength in the future.\nC. Explainability and interpretability\nExplainability and interpretability are currently major chal-\nlenges for GPTs for speci\ufb01c applications. Explainability refers\nto providing a clear and understandable explanation of how\nthe model has arrived at any output. Interpretability, on the\nother hand, refers to the ability to understand the internal\nprocesses of the model. GPT models are highly complex\nand dif\ufb01cult to understand and interpret due to their size\nand architecture. The outcomes and decisions of the model\nare based on previous learning and training, and the models\nlearn from vast amounts of data to make decisions. These\ndecisions may not be easily explainable to humans. This lack\nof transparency and interpretability raises concerns about the\nreliability and safety of the model, particularly in critical ap-\nplications such as healthcare and \ufb01nance. Researchers are cur-\nrently conducting much research to make GPT models more\nexplainable and interpretable [192] by utilizing EXplainable\nArti\ufb01cial Intelligence (XAI) to provide explanations for the\ndecisions arrived at, speci\ufb01cally to different users at stake. As\nwell, XAI models enable interpretability by providing detailed\nexplanations for the internal process.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 4438, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "71aeb199-b664-4109-93a8-6e59f1df0335": {"__data__": {"id_": "71aeb199-b664-4109-93a8-6e59f1df0335", "embedding": null, "metadata": {"page_label": "33", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "4fe11246-aab3-4198-8a83-1a3b0e0777b1", "node_type": "4", "metadata": {"page_label": "33", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "hash": "21449d2694e9e3e35ebec05f782c7b4f52833eb48b781689d3249e4f0dbab726", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "05cbc9bb-6c11-4516-87b5-a47b6c8937bc", "node_type": "1", "metadata": {"page_label": "33", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "hash": "518ff637823d80929acd1a3dfe60135217b1b6c8e19f96060c39ce3adcf26be1", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "GPT models are highly complex\nand dif\ufb01cult to understand and interpret due to their size\nand architecture. The outcomes and decisions of the model\nare based on previous learning and training, and the models\nlearn from vast amounts of data to make decisions. These\ndecisions may not be easily explainable to humans. This lack\nof transparency and interpretability raises concerns about the\nreliability and safety of the model, particularly in critical ap-\nplications such as healthcare and \ufb01nance. Researchers are cur-\nrently conducting much research to make GPT models more\nexplainable and interpretable [192] by utilizing EXplainable\nArti\ufb01cial Intelligence (XAI) to provide explanations for the\ndecisions arrived at, speci\ufb01cally to different users at stake. As\nwell, XAI models enable interpretability by providing detailed\nexplanations for the internal process. As GPT can generate\nany type of unconstrained output for instance code generation\nfor the given problem, it requires proper justi\ufb01cations and\nexplanations for the output. So, to assure these codes by\nGPT are reliable, a metric model to evaluate and validate\nthis GPT code was developed using NLP metrics and XAI\nfor model interpretability [193]. Also, some domain-speci\ufb01c\nGPT models of GPT-3 have evolved with solutions [194] [195]\nto ensure that the GPT model\u2019s decisions are understandable,\nexplainable, and trustworthy enough to be used for critical\napplications like healthcare and \ufb01nance.\nD. Data Bias\nData bias is an open issue concerned with the adoption\nof any advancements in AI, till GPT [196]. This is also\na prominent challenge for GPT and other machine-learning\nmodels. It refers to patterns or relationships in the data that\ndo not accurately re\ufb02ect the true distribution of the target\npopulation or domain. GPT models are trained on vast amounts\nof text data which may contain bias in language use or cultural\nassumptions. Still, the source of data remains undeclared, con-\nsidering GPTs are trained using internet data which may have\nfaulty, fake, and error data, GPTs may generate biased texts or\ninformation imitating the training data [197]. Such biases can\nbe ampli\ufb01ed in the model\u2019s output, resulting in false or unfair\nresults. Data bias can arise from various sources, such as selec-\ntion bias, labelling bias, concept drift, confounding variables,\nand changes in input data distribution over time. For example,\nsuppose a dataset used to train a GPT model is dominated\nby a particular demographic group. In that case, the resulting\nmodel may be biased in its predictions towards that group,\nleading to inaccurate or unfair predictions when applied to new\ndata. This bias can have serious consequences, especially in\nhealthcare, \ufb01nance, and law enforcement, where biased results\ncan signi\ufb01cantly impact human lives. To mitigate these issues,\nresearchers have developed strategies such as diversifying the\ntraining data, debiasing the training data, modifying the model", "mimetype": "text/plain", "start_char_idx": 3576, "end_char_idx": 6529, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "10bbf59e-a196-4c26-9287-5f12dcad117a": {"__data__": {"id_": "10bbf59e-a196-4c26-9287-5f12dcad117a", "embedding": null, "metadata": {"page_label": "34", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "9e24914d-12d0-4943-a47a-c97e676704b3", "node_type": "4", "metadata": {"page_label": "34", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "hash": "4615d8d77523d2500bbc3e4c7f6efbd03e80e1a26010ceb7e800b5206182946c", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "3d61b5b3-6f11-4d07-95ae-7b16e4f5e368", "node_type": "1", "metadata": {}, "hash": "9b41f66bfc7f607d4ea07be939f5a95c2e38907c7d030b0bb386fb6ea21013e5", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "34\narchitecture, and using post-processing methods to normalize\nthe data and create more fair and inclusive GPT models.\nThe authors in [198] have made an in-depth analysis of the\nmost downloaded text generation model GPT2. By examining\nthe intersections of gender with religion, sexuality, ethnicity,\npolitical af\ufb01liation, and continental name origin, the authors\nevaluated prejudices associated with occupational associations\namong various protected categories. These biases may have\ninaccuracies in climatic data prediction or global warming\n[199]. Therefore, data bias must be of greater concern in GPT\nmodel development as the data quality of the internet is limited\nto avoiding producing disturbing content.\nE. Multimodal support\nThe challenge of developing multimodal learning ability in\nthe GPT model remains unsolved. Multimodal support refers\nto the GPT model\u2019s ability to process and generate text along\nwith other modalities, such as audio, images, and videos. GPT\nmodels have shown impressive results in generating high-\nquality text and NLP tasks, but it was primarily designed for\ntext-based tasks and cannot handle other modalities. However,\ndue to its success in text processing, users expect its integra-\ntion with other modalities, such as speech recognition, video\nsummarization, and image or video captioning [200]. Several\nresearch initiatives have been proposed to integrate multimodal\nsupport to address this issue. One approach is to feed the visual\nand audio information with the corresponding text to the model\nas input. The other is to handle this input modality process as a\nseparate model and use the output as input to GPT. Multimodal\nvideo captioning is done using GPT in the unlabelled videos\n[200]. Multimodel learning has been applied for information\nretrieval [201] and image generation for illustrating the news\n[202] to assist the GPTs. However, the primary challenge in\nboth approaches is effective integration, requiring architectural\nchanges and techniques to handle various modalities. Recently,\nOpenAI\u2019s GPT4 has launched with multimodal support, en-\nabling it to read images, analyze the input, and generate text as\noutput. It cannot create images as output, though. Nevertheless,\nthe \ufb01eld of multimodal processing is still an active area of\nresearch, and much work must be done to effectively and\nef\ufb01ciently process and understand multimodal data.\nF . Robustness\nThe robustness is a major requirement to be imposed by any\ntype of GPT model, and it is a global problem for all learning-\nbased prediction technologies. Robustness refers to the ability\nof the model to maintain high performance and accuracy even\nin the face of unexpected or adversarial inputs. Although GPT\nmodels have shown impressive performance in a wide range of\nNLP applications and have set a benchmark for high-quality\ntext generation, they are still vulnerable to certain types of\nerrors and attacks. In particular, handling adversarial inputs is a\nchallenging task in GPT models. GPT models are particularly\nsusceptible to adversarial attacks [203]. Adversarial inputs are\nspeci\ufb01cally designed to make a learning model collapse and\nmisbehave. GPT models can be highly prone to these attacks\nbecause they are trained on a large volume of text. As a\nresult, they may be in\ufb02uenced by subtle patterns or biases in\nthe training data. If such biases or patterns exist in the data,\nthe GPT model may amplify or perpetuate existing biases,\nleading to unfair outcomes. A few techniques may be used,\nsuch as adversarial training [204] [205], defensive distillation\n[206], and regularization techniques [207] such as dropout,\nweight decay, and batch normalization, to mitigate and handle\nadversarial inputs. Therefore, GPT development must focus on\ndeveloping models with more robustness, enabling them to be\ntolerant of various vulnerabilities, and thus to be used reliably\nand susceptible in a wide range of applications.\nG. Multilingual support\nWhile GPT models have demonstrated remarkable pro\ufb01-\nciency in NLP tasks for individual languages, achieving mul-\ntilingual support remains a signi\ufb01cant challenge. The primary\ndif\ufb01culty in developing multilingual GPT models lies in the\nsigni\ufb01cant differences in syntax, grammar, and vocabulary\nacross various languages. As the number of internet users\nday by day increasing irrespective of literacy rate, multilingual\nsupport will target all types of end users.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 4415, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "3d61b5b3-6f11-4d07-95ae-7b16e4f5e368": {"__data__": {"id_": "3d61b5b3-6f11-4d07-95ae-7b16e4f5e368", "embedding": null, "metadata": {"page_label": "34", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "9e24914d-12d0-4943-a47a-c97e676704b3", "node_type": "4", "metadata": {"page_label": "34", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "hash": "4615d8d77523d2500bbc3e4c7f6efbd03e80e1a26010ceb7e800b5206182946c", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "10bbf59e-a196-4c26-9287-5f12dcad117a", "node_type": "1", "metadata": {"page_label": "34", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "hash": "0242e9cfd4dc8d8e3248e38de8250a4e8ada0805d4674fb081a5d92914ee385a", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Therefore, GPT development must focus on\ndeveloping models with more robustness, enabling them to be\ntolerant of various vulnerabilities, and thus to be used reliably\nand susceptible in a wide range of applications.\nG. Multilingual support\nWhile GPT models have demonstrated remarkable pro\ufb01-\nciency in NLP tasks for individual languages, achieving mul-\ntilingual support remains a signi\ufb01cant challenge. The primary\ndif\ufb01culty in developing multilingual GPT models lies in the\nsigni\ufb01cant differences in syntax, grammar, and vocabulary\nacross various languages. As the number of internet users\nday by day increasing irrespective of literacy rate, multilingual\nsupport will target all types of end users. To create models that\ncan effectively process multiple languages, researchers need to\ntrain GPT models on extensive, diverse datasets that span a\nbroad range of languages and language families. Addition-\nally, designing language-speci\ufb01c pre-processing techniques\nto prepare input data for the model is another obstacle to\novercome. Various languages possess distinct writing systems,\nword orders, and linguistic features, necessitating specialized\npre-processing techniques to ensure that the model can process\nthe input data effectively. Despite the challenges, researchers\ncontinue to explore new methods to improve the multilingual\ncapabilities of GPT models. Some techniques involve training\nseparate models for each language or developing language-\nspeci\ufb01c \ufb01ne-tuning techniques. Others include developing\ncross-lingual TL techniques that allow the model to transfer\nknowledge and skills learned in one language to another.\nH. Limited understanding\nGPT models have a limited understanding of context and\nmeaning, despite their ability to generate coherent text. This\nproblem arises due to issues such as a lack of semantic\nunderstanding, bias, stereotyping, and handling nuances and\n\ufb01gurative language. As a result, the outputs generated by the\nmodel may contain errors or inaccuracies, even if they are\ngrammatically correct. Researchers are exploring various tech-\nniques to enhance the model\u2019s contextual understanding. Un-\nderstanding GPTs will be more reactive and may attract more\nusers for accurate results [208]. These methods include incor-\nporating external knowledge sources like knowledge graphs\nand ontologies into the training process, developing common\nsense reasoning capabilities, and improving the model\u2019s ability\nto handle nuances and idiomatic expressions. By enhancing the\ncontextual understanding of GPT models, their outputs will\nbe more accurate, relatable, sequential, less biased, and more\nuseful for a variety of applications.", "mimetype": "text/plain", "start_char_idx": 3715, "end_char_idx": 6374, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "25789815-c800-4732-8d44-651c163df013": {"__data__": {"id_": "25789815-c800-4732-8d44-651c163df013", "embedding": null, "metadata": {"page_label": "35", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "9ed06512-9e4a-425f-bdc8-5bafe6461249", "node_type": "4", "metadata": {"page_label": "35", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "hash": "6e1994f08db04e00b91deaca2169aec2c73c01eaf7539d4beba329fc1c3abaa2", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "9e40395b-071c-406a-a28f-873e96ff308b", "node_type": "1", "metadata": {}, "hash": "9ac19c8ebfb66fda5fe0e13e0097e0e5e4b7f1bbfbdfcbae7374b744adeee9b1", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "35\nI. Ethical Concerns\nThe ethical concerns in GPT models are an active area of\ndiscussion and debate due to the potential negative impacts that\nthe use of GPTs could have on society. Although GPT models\nhave demonstrated remarkable abilities in generating coherent\nand realistic text, there are concerns about the perpetuation\nof biases and stereotypes, the possibility of malicious use,\nand the effects on employment and economic inequality.\nSome of the ethical characteristics to be possessed by GPT\ninclude functional Morality, operational morality, abiding by\nthe right for explanation law, improved transparency with\nhuman involvement, unbiased data, and adhering to govern-\nment regulations on data usage [196]. The responsibility of\ndevelopers and companies to address these ethical concerns\nand ensure the ethical use of a GPT model is also a topic\nof debate. The ethical implications of GPT models are being\nactively researched and discussed in the \ufb01elds of AI, computer\nscience, and philosophy.\nJ. Security and privacy concerns\nGPT models raise concerns about security and privacy,\nparticularly as they become more widespread. One of the main\nconcerns is that GPT could be used for harmful purposes, such\nas creating fake news or deep fakes, as it can generate text that\nlooks real and convincing, making it dif\ufb01cult to distinguish\nbetween genuine and fake content. Another concern is the po-\ntential for privacy violations when using a GPT model. Large\nlanguage models like GPT require a signi\ufb01cant amount of\ntraining data, which could contain sensitive or personal infor-\nmation. This raises concerns about privacy and data protection\nas per European Union\u2019s General Data Protection Act [209],\nparticularly if the training data is not properly anonymized\nor if the models are used to generate text based on user data\nwithout their explicit consent. Some of the problems concerned\nwith con\ufb01dentiality related to the pre-training dataset are\nData tracing, Membership Inference Attacks, reconstruction\nattacks, and property inference attacks and the vulnerabilities\nconcerned with a model encoder are hyperparameter stealing\nattacks and encoder parameter stealing attacks. Poisoning,\nBackdoor, and evasion attacks are the vulnerability related to\nthe integrity of self-supervised learning. Resource depletion\nattack is one major issue with data availability, which may lead\nto tremendous effects incorrect results, and may cause greater\ndeviations too [209]. Additionally, the GPT model\u2019s ability to\ngenerate text based on user input could inadvertently disclose\nsensitive information, such as personal or \ufb01nancial details, or\ntrade secrets. This could happen if a GPT model is used in an\ninsecure environment or if it is targeted by malicious actors\nseeking to obtain sensitive information. Researchers and devel-\nopers should focus on assuring authenticity in using users\u2019 data\nin case of interactive information generation based on privacy\ndata shared. These include using differential privacy to protect\ntraining data privacy [210], implementing secure hardware or\nsoftware protocols to protect models from cyberattacks, and\ndeveloping techniques to detect and prevent the malicious use\nof GPT models. It\u2019s crucial to adopt and follow these measures\nto ensure the ethical and safe use of GPT models before using\nthem in various applications.\nTherefore, GPT model development must focus on devel-\noping more robust, reliable, safest, multi-lingual, multimodal\nsupport-enabled solutions for delivering domain-speci\ufb01c or\nhuman-speci\ufb01c solutions with optimal resource utilization.\nVII. C ONCLUSION\nThe impact of GPT and other large language models is\nfar-reaching and profound. As these technologies continue to\nevolve and improve, they have the potential to transform the\nway we interact with technology and each other. From per-\nsonalized recommendations and customer service to language\ntranslation and text generation, the possibilities are endless.\nHowever, as with any technology, there are potential ethical\nand societal concerns that must be addressed. As we continue\nto rely more heavily on these language models, we must\nensure that we are using these tools responsibly and with\nconsideration for their impact on society as a whole. These\ninclude challenges related to biases in the data used to train\nthe models, safeguarding privacy and security, understanding\nthe implications of human creativity, and the potential impact\non employment and job displacement. We need to continue to\nevaluate and re\ufb02ect on the impact of GPT and other language\nmodels, to ensure that they are being used in a way that\nbene\ufb01ts society as a whole.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 4649, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "9e40395b-071c-406a-a28f-873e96ff308b": {"__data__": {"id_": "9e40395b-071c-406a-a28f-873e96ff308b", "embedding": null, "metadata": {"page_label": "35", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "9ed06512-9e4a-425f-bdc8-5bafe6461249", "node_type": "4", "metadata": {"page_label": "35", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "hash": "6e1994f08db04e00b91deaca2169aec2c73c01eaf7539d4beba329fc1c3abaa2", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "25789815-c800-4732-8d44-651c163df013", "node_type": "1", "metadata": {"page_label": "35", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "hash": "a476bc969fe2ebf5d84e5bc43ba71363dcd4af1d1fc2484fdd541d5aafcfecf0", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "87af16b4-c6a5-4a01-bb93-8586338f8e44", "node_type": "1", "metadata": {}, "hash": "80698aaf1b060552f20633214c908674047d03ce79d0070544f19b9dcc4241a1", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "From per-\nsonalized recommendations and customer service to language\ntranslation and text generation, the possibilities are endless.\nHowever, as with any technology, there are potential ethical\nand societal concerns that must be addressed. As we continue\nto rely more heavily on these language models, we must\nensure that we are using these tools responsibly and with\nconsideration for their impact on society as a whole. These\ninclude challenges related to biases in the data used to train\nthe models, safeguarding privacy and security, understanding\nthe implications of human creativity, and the potential impact\non employment and job displacement. We need to continue to\nevaluate and re\ufb02ect on the impact of GPT and other language\nmodels, to ensure that they are being used in a way that\nbene\ufb01ts society as a whole. By doing so, we can help to ensure\nthat these technologies are used to their fullest potential while\nminimizing any negative impact that they may have.\nREFERENCES\n[1] X. Han, Z. Zhang, N. Ding, Y . Gu, X. Liu, Y . Huo, J. Qiu, Y . Yao,\nA. Zhang, L. Zhang et al. , \u201cPre-trained models: Past, present and\nfuture,\u201d AI Open, vol. 2, pp. 225\u2013250, 2021.\n[2] \u201dIntroducing OpenAI\u201d. [Accessed on 23.03.2023]. [Online]. Available:\nhttps://openai.com/blog/introducing-openai\n[3] L. Dong, S. Xu, and B. Xu, \u201cSpeech-transformer: a no-recurrence\nsequence-to-sequence model for speech recognition,\u201d in 2018 IEEE\ninternational conference on acoustics, speech and signal processing\n(ICASSP). IEEE, 2018, pp. 5884\u20135888.\n[4] B. D. Lund and T. Wang, \u201cChatting about chatgpt: how may ai and\ngpt impact academia and libraries?\u201d Library Hi Tech News , 2023.\n[5] E. Kasneci, K. Se\u00dfler, S. K \u00a8uchemann, M. Bannert, D. Dementieva,\nF. Fischer, U. Gasser, G. Groh, S. G \u00a8unnemann, E. H \u00a8ullermeier et al.,\n\u201cChatgpt for good? on opportunities and challenges of large language\nmodels for education,\u201d Learning and Individual Differences , vol. 103,\np. 102274, 2023.\n[6] X. Qiu, T. Sun, Y . Xu, Y . Shao, N. Dai, and X. Huang, \u201cPre-trained\nmodels for natural language processing: A survey,\u201d Science China\nTechnological Sciences, vol. 63, no. 10, pp. 1872\u20131897, 2020.\n[7] A. S. George, A. H. George, T. Baskar, and A. G. Martin, \u201cRevolu-\ntionizing business communication: Exploring the potential of gpt-4 in\ncorporate settings,\u201d Partners Universal International Research Journal,\nvol. 2, no. 1, pp. 149\u2013157, 2023.\n[8] C. Zhang, C. Zhang, S. Zheng, Y . Qiao, C. Li, M. Zhang, S. K. Dam,\nC. M. Thwal, Y . L. Tun, L. L. Huy et al. , \u201cA complete survey on\ngenerative ai (aigc): Is chatgpt from gpt-4 to gpt-5 all you need?\u201d\narXiv preprint arXiv:2303.11717 , 2023.\n[9] M. Zaib, Q. Z. Sheng, and W. Emma Zhang, \u201cA short survey of pre-\ntrained language models for conversational ai-a new age in nlp,\u201d in\nProceedings of the Australasian computer science week multiconfer-\nence, 2020, pp. 1\u20134.\n[10] Z. Liu, X. Yu, L. Zhang, Z. Wu, C. Cao, H. Dai, L. Zhao,\nW. Liu, D. Shen, Q. Li et al. , \u201cDeid-gpt: Zero-shot medical text de-\nidenti\ufb01cation by gpt-4,\u201d arXiv preprint arXiv:2303.11032 , 2023.", "mimetype": "text/plain", "start_char_idx": 3831, "end_char_idx": 6898, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "87af16b4-c6a5-4a01-bb93-8586338f8e44": {"__data__": {"id_": "87af16b4-c6a5-4a01-bb93-8586338f8e44", "embedding": null, "metadata": {"page_label": "35", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "9ed06512-9e4a-425f-bdc8-5bafe6461249", "node_type": "4", "metadata": {"page_label": "35", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "hash": "6e1994f08db04e00b91deaca2169aec2c73c01eaf7539d4beba329fc1c3abaa2", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "9e40395b-071c-406a-a28f-873e96ff308b", "node_type": "1", "metadata": {"page_label": "35", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "hash": "fb83a2296b2671c4ce0c7fecab6b3242ec3498f690937aacbfe369d4499add83", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "[9] M. Zaib, Q. Z. Sheng, and W. Emma Zhang, \u201cA short survey of pre-\ntrained language models for conversational ai-a new age in nlp,\u201d in\nProceedings of the Australasian computer science week multiconfer-\nence, 2020, pp. 1\u20134.\n[10] Z. Liu, X. Yu, L. Zhang, Z. Wu, C. Cao, H. Dai, L. Zhao,\nW. Liu, D. Shen, Q. Li et al. , \u201cDeid-gpt: Zero-shot medical text de-\nidenti\ufb01cation by gpt-4,\u201d arXiv preprint arXiv:2303.11032 , 2023.\n[11] P. Rivas and L. Zhao, \u201cMarketing with chatgpt: Navigating the ethical\nterrain of gpt-based chatbot technology,\u201d AI, vol. 4, no. 2, pp. 375\u2013384,\n2023.", "mimetype": "text/plain", "start_char_idx": 6477, "end_char_idx": 7053, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "1baa69df-a064-4a2d-bf65-d8775c5cdeb0": {"__data__": {"id_": "1baa69df-a064-4a2d-bf65-d8775c5cdeb0", "embedding": null, "metadata": {"page_label": "36", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "b73d52db-4305-4802-aa2e-bf1f584e2f9b", "node_type": "4", "metadata": {"page_label": "36", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "hash": "6f1c9d80779c916ee5662807b96c3a463101624e6dc2fcdd6c16d77e0d251e9d", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "65b6cc08-ca0b-435c-937c-a9fbea629c2f", "node_type": "1", "metadata": {}, "hash": "fc9b351ba35d44baed7ff8cb956497ebc1894425e8e5b07318c65629e5dd3122", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "36\nTABLE VI\nVARIOUS LESSONS LEARNED AND FUTURE RESEARCH DIRECTIONS .\nSl.No Lessons Learned Open Issues Future Directions\n1. \u25e6Huge volume of data usage\nis critical\n\u25e6Data privacy - may unknowingly reveal sensitive\ninformation\n\u25e6Varied data quality - Inconsistency in quality of\ndata used for training\n\u25e6Scalability - Models should be able to handle an\nincrease in data set size and complexity\n\u25e6Optimized architecture and algorithms\n\u25e6Cloud-based computing\n\u25e6Hardware advancements\n2. \u25e6 Importance of Proper Pre-\nprocessing of data\n\u25e6Data bias - Overrepresentation of certain groups\nor perspectives\n\u25e6Poor model performance\n\u25e6Reduced ef\ufb01ciency of the model\n\u25e6Continuous monitoring\n\u25e6Testing model for potential biases\n\u25e6Diversifying the training data\n3. \u25e6Importance of explainability\nand interpretability\n\u25e6Complexity of models\n\u25e6Inability to explain predictions\n\u25e6Need of User-tailored Explanations generation\n\u25e6Developing Interpretable models\n\u25e6Lack of transparency in the data source\n\u25e6AI governance models can be used\n\u25e6Model Summaries can be provided\n\u25e6Techniques like LIME(Local Model-Agnostic Ex-\nplanations can be used\n\u25e6 Uncertaining estimates can be obtained from a\nmodel\n4. \u25e6Ethical concerns \u25e6Data privacy and data protection\n\u25e6Misuse of data\n\u25e6Accountability and transparency concerns\n\u25e6Societal implications - displacing jobs and exacer-\nbating equalities\n\u25e6Counterfactual analysis can be used\n\u25e6Federated learning can be used\n\u25e6Ethical guidelines, Legal frameworks and regula-\ntions can be developed to avoid harmful use\n5. \u25e6 Lack of contextual under-\nstanding in AI systems\n\u25e6Possibility for ambiguous, contradictory, incorrect\nresults leads to misunderstandings\n\u25e6Inconsistency in responses or outputs\n\u25e6Lack of ability in distinguishing true and false\ninformation\n\u25e6Incorporation of knowledge graphs and semantic\nembeddings into the training process\n\u25e6Usage of attention mechanisms to focus on relevant\nparts of the input\n\u25e6Imparting reasoning and inference capabilities\n\u25e6Task or domain-based \ufb01ne-tuning\n6. \u25e6Pre-trained models may not\nperform well for Domain-\nspeci\ufb01c task\n\u25e6Possibility for ambiguous, contradictory, incorrect\nresults leads to misunderstandings\n\u25e6Inconsistency in responses or outputs\n\u25e6Lack of ability in distinguishing true and false\ninformation\n\u25e6Incorporation of knowledge graphs and semantic\nembeddings into the training process\n\u25e6Usage of attention mechanisms to focus on relevant\nparts of the input\n\u25e6Imparting reasoning and inference capabilities\n\u25e6Task or domain-based \ufb01ne-tuning\n[12] M. Leippold, \u201cThus spoke gpt-3: Interviewing a large-language model\non climate \ufb01nance,\u201dFinance Research Letters, vol. 53, p. 103617, 2023.\n[13] M. Trajtenberg, \u201cAi as the next gpt: a political-economy perspective,\u201d\nNational Bureau of Economic Research, Tech. Rep., 2018.\n[14] D. Haluza and D. Jungwirth, \u201cArti\ufb01cial intelligence and ten societal\nmegatrends: An exploratory study using gpt-3,\u201d Systems, vol. 11, no. 3,\np. 120, 2023.\n[15] L. J. Quintans-J \u00b4unior, R. Q. Gurgel, A. A. d. S. Ara \u00b4ujo, D. Correia,\nand P. R. Martins-Filho, \u201cChatgpt: the new panacea of the academic\nworld,\u201d pp. e0060\u20132023, 2023.\n[16] Q. Zhu and J. Luo, \u201cGenerative pre-trained transformer for design\nconcept generation: an exploration,\u201dProceedings of the Design Society,\nvol. 2, pp. 1825\u20131834, 2022.\n[17] \u201dGPT\u201d. [Accessed on 25.03.2023]. [Online]. Available: https:\n//aidungeon.io/\n[18] M. Kosinski, \u201cTheory of mind may have spontaneously emerged in\nlarge language models,\u201d arXiv preprint arXiv:2302.02083 , 2023.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3476, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "65b6cc08-ca0b-435c-937c-a9fbea629c2f": {"__data__": {"id_": "65b6cc08-ca0b-435c-937c-a9fbea629c2f", "embedding": null, "metadata": {"page_label": "36", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "b73d52db-4305-4802-aa2e-bf1f584e2f9b", "node_type": "4", "metadata": {"page_label": "36", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "hash": "6f1c9d80779c916ee5662807b96c3a463101624e6dc2fcdd6c16d77e0d251e9d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "1baa69df-a064-4a2d-bf65-d8775c5cdeb0", "node_type": "1", "metadata": {"page_label": "36", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "hash": "86ffa0019c06bd017f2861c7b8d77ce2df313d2b31b9a60d33c810780c564c1f", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "858c80ad-7893-479d-b229-d1c20ddf2657", "node_type": "1", "metadata": {}, "hash": "c7149e0f5e7b4d3dba43a533eeac01d882325730b908a40b828058c796df4b62", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "e0060\u20132023, 2023.\n[16] Q. Zhu and J. Luo, \u201cGenerative pre-trained transformer for design\nconcept generation: an exploration,\u201dProceedings of the Design Society,\nvol. 2, pp. 1825\u20131834, 2022.\n[17] \u201dGPT\u201d. [Accessed on 25.03.2023]. [Online]. Available: https:\n//aidungeon.io/\n[18] M. Kosinski, \u201cTheory of mind may have spontaneously emerged in\nlarge language models,\u201d arXiv preprint arXiv:2302.02083 , 2023.\n[19] \u201dGPT-1, GPT-2 and GPT-3 models explained\u201d. [Accessed on\n27.03.2023]. [Online]. Available: https://360digitmg.com/blog/types-\nof-gpt-in-arti\ufb01cial-intelligence\n[20] B. Ghojogh and A. Ghodsi, \u201cAttention mechanism, transformers, bert,\nand gpt: Tutorial and survey,\u201d 2020.\n[21] \u201dGenerative Pre-trained Transformer 3 by Ope-\nnAI\u201d. [Accessed on 23.03.2023]. [Online]. Avail-\nable: https://medium.com/@shripad.kulkarni18/generative-pre-trained-\ntransformer-3-by-openai-4abe6614c8ef\n[22] N. Williams, S. Ivanov, and D. Buhalis, \u201cAlgorithmic ghost in the re-\nsearch shell: Large language models and academic knowledge creation\nin management research,\u201d arXiv preprint arXiv:2303.07304 , 2023.\n[23] M.-T. Nguyen, P.-T. Nguyen, V .-V . Nguyen, and Q.-M. Nguyen, \u201cGen-\nerating product description with generative pre-trained transformer 2,\u201d\nin 2021 6th International Conference on Innovative Technology in\nIntelligent System and Industrial Applications (CITISIA) , 2021, pp. 1\u2013\n7.\n[24] V . Taecharungroj, \u201c\u201cwhat can chatgpt do?\u201d analyzing early reactions\nto the innovative ai chatbot on twitter,\u201d Big Data and Cognitive\nComputing, vol. 7, no. 1, p. 35, 2023.\n[25] G. Spitale, N. Biller-Andorno, and F. Germani, \u201cAi model gpt-3 (dis)\ninforms us better than humans,\u201d arXiv preprint arXiv:2301.11924 ,\n2023.\n[26] J. Ye, X. Chen, N. Xu, C. Zu, Z. Shao, S. Liu, Y . Cui, Z. Zhou,\nC. Gong, Y . Shenet al., \u201cA comprehensive capability analysis of gpt-3\nand gpt-3.5 series models,\u201d arXiv preprint arXiv:2303.10420 , 2023.\n[27] J. Liu, D. Shen, Y . Zhang, B. Dolan, L. Carin, and W. Chen,\n\u201cWhat makes good in-context examples for gpt- 3?\u201d arXiv preprint\narXiv:2101.06804, 2021.\n[28] M. Bommarito II and D. M. Katz, \u201cGpt takes the bar exam,\u201d arXiv\npreprint arXiv:2212.14402, 2022.\n[29] T. Hagendorff, S. Fabi, and M. Kosinski, \u201cMachine intuition: Uncov-\nering human-like intuitive decision-making in gpt-3.5,\u201d arXiv preprint\narXiv:2212.05206, 2022.\n[30] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N.\nGomez, \u0141. Kaiser, and I. Polosukhin, \u201cAttention is all you need,\u201d\nAdvances in neural information processing systems , vol. 30, 2017.\n[31] W. Hou and Z. Ji, \u201cGeneturing tests gpt models in genomics,\u201d bioRxiv,\npp. 2023\u201303, 2023.", "mimetype": "text/plain", "start_char_idx": 3074, "end_char_idx": 5703, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "858c80ad-7893-479d-b229-d1c20ddf2657": {"__data__": {"id_": "858c80ad-7893-479d-b229-d1c20ddf2657", "embedding": null, "metadata": {"page_label": "36", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "b73d52db-4305-4802-aa2e-bf1f584e2f9b", "node_type": "4", "metadata": {"page_label": "36", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "hash": "6f1c9d80779c916ee5662807b96c3a463101624e6dc2fcdd6c16d77e0d251e9d", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "65b6cc08-ca0b-435c-937c-a9fbea629c2f", "node_type": "1", "metadata": {"page_label": "36", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "hash": "703a70a48ca8337221726edbedc899d5d406bb723d324eb0513b0b319794c300", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "[29] T. Hagendorff, S. Fabi, and M. Kosinski, \u201cMachine intuition: Uncov-\nering human-like intuitive decision-making in gpt-3.5,\u201d arXiv preprint\narXiv:2212.05206, 2022.\n[30] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N.\nGomez, \u0141. Kaiser, and I. Polosukhin, \u201cAttention is all you need,\u201d\nAdvances in neural information processing systems , vol. 30, 2017.\n[31] W. Hou and Z. Ji, \u201cGeneturing tests gpt models in genomics,\u201d bioRxiv,\npp. 2023\u201303, 2023.\n[32] S. Edunov, A. Baevski, and M. Auli, \u201cPre-trained language model\nrepresentations for language generation,\u201d in Proceedings of the 2019\nConference of the North American Chapter of the Association for\nComputational Linguistics: Human Language Technologies, Volume\n1 (Long and Short Papers) . Minneapolis, Minnesota: Association\nfor Computational Linguistics, Jun. 2019, pp. 4052\u20134059. [Online].\nAvailable: https://aclanthology.org/N19-1409\n[33] A. Rahali and M. A. Akhlou\ufb01, \u201cEnd-to-end transformer-based models\nin textual-based nlp,\u201d AI, vol. 4, no. 1, pp. 54\u2013110, 2023.", "mimetype": "text/plain", "start_char_idx": 5239, "end_char_idx": 6275, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "e751d589-4b59-4388-8e3f-fc142876d3f5": {"__data__": {"id_": "e751d589-4b59-4388-8e3f-fc142876d3f5", "embedding": null, "metadata": {"page_label": "37", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "d46a39e9-2645-4958-9f89-40a9e13426b6", "node_type": "4", "metadata": {"page_label": "37", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "hash": "37a89bb976bf641251045fa34e708df555b6ea0be180ba665a801bf9cf389363", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "13be8a57-dcee-46c2-91d0-596e0dca8a2c", "node_type": "1", "metadata": {}, "hash": "d616647722fd290c7c649c90e159b1e246c9d5ef10ad4b47818258d37025e7da", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "37\n[34] J. R. Stevens, R. Venkatesan, S. Dai, B. Khailany, and A. Raghunathan,\n\u201cSoftermax: Hardware/software co-design of an ef\ufb01cient softmax for\ntransformers,\u201d in 2021 58th ACM/IEEE Design Automation Conference\n(DAC). IEEE, 2021, pp. 469\u2013474.\n[35] M. Bangura, K. Barabashova, A. Karnysheva, S. Semczuk, and\nY . Wang, \u201cAutomatic generation of german drama texts using \ufb01ne tuned\ngpt-2 models,\u201d arXiv preprint arXiv:2301.03119 , 2023.\n[36] J. Savelka, A. Agarwal, C. Bogart, and M. Sakr, \u201cLarge language\nmodels (gpt) struggle to answer multiple-choice questions about code,\u201d\narXiv preprint arXiv:2303.08033 , 2023.\n[37] H. Liu, Y . Cai, Z. Lin, Z. Ou, Y . Huang, and J. Feng, \u201cVariational latent-\nstate gpt for semi-supervised task-oriented dialog systems,\u201d IEEE/ACM\nTransactions on Audio, Speech, and Language Processing , vol. 31, pp.\n970\u2013984, 2023.\n[38] \u201dGPT-3, explained: This new language AI is uncanny, funny \u2014\nand a big deal\u201d. [Accessed on 23.03.2023]. [Online]. Available:\nhttps://www.computerhope.com/jargon/g/gpt.html\n[39] A. Hendy, M. Abdelrehim, A. Sharaf, V . Raunak, M. Gabr, H. Mat-\nsushita, Y . J. Kim, M. A\ufb01fy, and H. H. Awadalla, \u201cHow good are\ngpt models at machine translation? a comprehensive evaluation,\u201d arXiv\npreprint arXiv:2302.09210, 2023.\n[40] \u201dOpenAI GPT-n models: Shortcomings & Advantages in 2023\u201d.\n[Accessed on 23.03.2023]. [Online]. Available: https://research.\naimultiple.com/gpt/\n[41] S. Pramanik and S. K. Bandyopadhyay, \u201cAnalysis of big data,\u201d in\nEncyclopedia of Data Science and Machine Learning . IGI Global,\n2023, pp. 97\u2013115.\n[42] A. Zaremba and E. Demir, \u201cChatgpt: Unlocking the future of nlp in\n\ufb01nance,\u201d Available at SSRN 4323643 , 2023.\n[43] N. Aleksi \u00b4c, M. Arnelid, D. Lisy, A. Balachandran, M. Belfrage,\nA. Br \u00a8annstr\u00a8om, M. Busarello, S. A. Carretta, K. Cotton, S. de Heer\net al., \u201cDeep learning as a gpt and disruptor in innovation processes.\u201d\n[44] S. Bubeck, V . Chandrasekaran, R. Eldan, J. Gehrke, E. Horvitz,\nE. Kamar, P. Lee, Y . T. Lee, Y . Li, S. Lundberg et al. , \u201cSparks of\narti\ufb01cial general intelligence: Early experiments with gpt-4,\u201d arXiv\npreprint arXiv:2303.12712, 2023.\n[45] D. M. Katz, M. J. Bommarito, S. Gao, and P. Arredondo, \u201cGpt-4 passes\nthe bar exam,\u201d Available at SSRN 4389233 , 2023.\n[46] D. O. Beerbaum, \u201cGenerative arti\ufb01cial intelligence (gai) ethics\ntaxonomy-applying chat gpt for robotic process automation (gai-rpa)\nas business case,\u201d Available at SSRN 4385025 , 2023.\n[47] H. A. Dida, D. Chakravarthy, and F. Rabbi, \u201cChatgpt and big data:\nEnhancing text-to-speech conversion,\u201d Mesopotamian Journal of Big\nData, vol. 2023, pp. 33\u201337, 2023.\n[48] V .", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2621, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "13be8a57-dcee-46c2-91d0-596e0dca8a2c": {"__data__": {"id_": "13be8a57-dcee-46c2-91d0-596e0dca8a2c", "embedding": null, "metadata": {"page_label": "37", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "d46a39e9-2645-4958-9f89-40a9e13426b6", "node_type": "4", "metadata": {"page_label": "37", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "hash": "37a89bb976bf641251045fa34e708df555b6ea0be180ba665a801bf9cf389363", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "e751d589-4b59-4388-8e3f-fc142876d3f5", "node_type": "1", "metadata": {"page_label": "37", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "hash": "36cf8d369a6bd01de80bc2fb8f252dbdfa5ba2011a34dcde97cc7c594a6ab1b8", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "de400218-79f5-465d-93a1-f5e7aed0f955", "node_type": "1", "metadata": {}, "hash": "7c6872b9d7d97c6b68617b3116c81c7303fbc3bf5e6d34585dd790e304cca5e0", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "[45] D. M. Katz, M. J. Bommarito, S. Gao, and P. Arredondo, \u201cGpt-4 passes\nthe bar exam,\u201d Available at SSRN 4389233 , 2023.\n[46] D. O. Beerbaum, \u201cGenerative arti\ufb01cial intelligence (gai) ethics\ntaxonomy-applying chat gpt for robotic process automation (gai-rpa)\nas business case,\u201d Available at SSRN 4385025 , 2023.\n[47] H. A. Dida, D. Chakravarthy, and F. Rabbi, \u201cChatgpt and big data:\nEnhancing text-to-speech conversion,\u201d Mesopotamian Journal of Big\nData, vol. 2023, pp. 33\u201337, 2023.\n[48] V . Pereira, E. Hadjielias, M. Christo\ufb01, and D. Vrontis, \u201cA systematic\nliterature review on the impact of arti\ufb01cial intelligence on workplace\noutcomes: A multi-process perspective,\u201dHuman Resource Management\nReview, vol. 33, no. 1, p. 100857, 2023.\n[49] M. Trajtenberg, \u201cArti\ufb01cial intelligence as the next gpt: A political-\neconomy perspective,\u201d in The economics of arti\ufb01cial intelligence: An\nagenda. University of Chicago Press, 2018, pp. 175\u2013186.\n[50] S. Tu, A. Cyphert, and S. Perl, \u201cLimits of using arti\ufb01cial intelligence\nand gpt-3 in patent prosecution,\u201d Tex. Tech L. Rev. , vol. 54, p. 255,\n2021.\n[51] A. Mathew, \u201cIs arti\ufb01cial intelligence a world changer? a case study of\nopenai\u2019s chat gpt,\u201d Recent Progress in Science and Technology Vol. 5 ,\npp. 35\u201342, 2023.\n[52] R. Reed, \u201cThe theology of gpt-2: Religion and arti\ufb01cial intelligence,\u201d\nReligion Compass, vol. 15, no. 11, p. e12422, 2021.\n[53] H. Akbar, M. Zubair, and M. S. Malik, \u201cThe security issues and\nchallenges in cloud computing,\u201d International Journal for Electronic\nCrime Investigation, vol. 7, no. 1, pp. 13\u201332, 2023.\n[54] K. D. Gupta et al., \u201cA review of generative ai from historical perspec-\ntives,\u201d 2023.\n[55] R. Sajja, Y . Sermet, D. Cwiertny, and I. Demir, \u201cPlatform-independent\nand curriculum-oriented intelligent assistant for higher education,\u201d\narXiv preprint arXiv:2302.09294 , 2023.\n[56] F. Etro, \u201cThe economic consequences of the diffusion of cloud comput-\ning,\u201d Dutta, Soumitra; Mia, Irene. The Global Information Technology\nReport, vol. 2010, 2009.\n[57] K. Y AMAOKA, K. W ATANABE, K. KISE, A. DENGEL, and S. ISHI-\nMARU, \u201cExperience is the best teacher: Personalized vocabulary\nbuilding within the context of instagram posts and sentences from gpt-\n3,\u201d 2022.\n[58] R. Ressmeyer, S. Masling, and M. Liao, \u201c\u201cdeep faking\u201d political twitter\nusing transfe r learning and gpt-2,\u201d 2019.\n[59] S. Balkus and D. Yan, \u201cImproving short text classi\ufb01cation with\naugmented data using gpt-3,\u201d arXiv preprint arXiv:2205.10981 , 2022.\n[60] H. Hua, Y . Li, T. Wang, N. Dong, W. Li, and J. Cao, \u201cEdge computing\nwith arti\ufb01cial intelligence: A machine learning perspective,\u201d ACM\nComputing Surveys, vol. 55, no. 9, pp. 1\u201335, 2023.\n[61] J. Yao, S. Zhang, Y . Yao, F. Wang, J. Ma, J. Zhang, Y .", "mimetype": "text/plain", "start_char_idx": 2129, "end_char_idx": 4865, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "de400218-79f5-465d-93a1-f5e7aed0f955": {"__data__": {"id_": "de400218-79f5-465d-93a1-f5e7aed0f955", "embedding": null, "metadata": {"page_label": "37", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "d46a39e9-2645-4958-9f89-40a9e13426b6", "node_type": "4", "metadata": {"page_label": "37", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "hash": "37a89bb976bf641251045fa34e708df555b6ea0be180ba665a801bf9cf389363", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "13be8a57-dcee-46c2-91d0-596e0dca8a2c", "node_type": "1", "metadata": {"page_label": "37", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "hash": "2c67c886a1b6f3b7954b4ca2ecbc0c045aa3651c74dbe6d872f7af951cfc2f9b", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "97936bd6-9f93-4873-9b00-e2ee608dd859", "node_type": "1", "metadata": {}, "hash": "a3d5998ff9986907dc71fe85cae4e1ba044fe1583b5f4e31309cb9082085896f", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "[59] S. Balkus and D. Yan, \u201cImproving short text classi\ufb01cation with\naugmented data using gpt-3,\u201d arXiv preprint arXiv:2205.10981 , 2022.\n[60] H. Hua, Y . Li, T. Wang, N. Dong, W. Li, and J. Cao, \u201cEdge computing\nwith arti\ufb01cial intelligence: A machine learning perspective,\u201d ACM\nComputing Surveys, vol. 55, no. 9, pp. 1\u201335, 2023.\n[61] J. Yao, S. Zhang, Y . Yao, F. Wang, J. Ma, J. Zhang, Y . Chu, L. Ji,\nK. Jia, T. Shen, A. Wu, F. Zhang, Z. Tan, K. Kuang, C. Wu, F. Wu,\nJ. Zhou, and H. Yang, \u201cEdge-cloud polarization and collaboration: A\ncomprehensive survey for ai,\u201d IEEE Transactions on Knowledge and\nData Engineering, pp. 1\u20131, 2022.\n[62] Y . Yu and S. Lee, \u201cMeasurements of the bene\ufb01ts of edge computing\non autonomous driving,\u201d in 2022 13th International Conference on\nInformation and Communication Technology Convergence (ICTC) .\nIEEE, 2022, pp. 2155\u20132159.\n[63] D. Yuan, L. Cui, M. Xie, Z. Su et al., \u201cParatra: A parallel transformer\ninference framework for gpus in edge computing.\u201d\n[64] X. Zhou, H. Liu, C. Shi, and J. Liu, Deep Learning on Edge Computing\nDevices: Design Challenges of Algorithm and Architecture . Elsevier,\n2022.\n[65] K. Li, K. Chen, S. Luo, H. Zhang, and P. Fan, \u201cUbinn: A commu-\nnication ef\ufb01cient framework for distributed machine learning in edge\ncomputing,\u201d IEEE Transactions on Network Science and Engineering ,\n2023.\n[66] C. Benza \u00a8\u0131d, T. Taleb, and M. Z. Farooqi, \u201cTrust in 5g and beyond\nnetworks,\u201d IEEE Network, vol. 35, no. 3, pp. 212\u2013222, 2021.\n[67] J. S. Wey and J. Zhang, \u201cPassive optical networks for 5g transport:\nTechnology and standards,\u201d Journal of Lightwave Technology, vol. 37,\nno. 12, pp. 2830\u20132837, 2019.\n[68] S. Zhang, W. Y . B. Lim, W. C. Ng, Z. Xiong, D. Niyato, X. S. Shen,\nand C. Miao, \u201cTowards green metaverse networking: Technologies,\nadvancements and future directions,\u201d IEEE Network, 2023.\n[69] Z. Li, M. A. Uusitalo, H. Shariatmadari, and B. Singh, \u201c5g urllc:\nDesign challenges and system concepts,\u201d in 2018 15th International\nSymposium on Wireless Communication Systems (ISWCS) , 2018, pp.\n1\u20136.\n[70] A. Gonzalez Fanfalone et al., \u201cThe road to 5g networks: experience to\ndate and future developments,\u201d 2019.\n[71] Y . Rogers, H. Sharp, and J. Preece, Interaction design: beyond human-\ncomputer interaction. John Wiley & Sons, 2023.\n[72] Y . Liu, M. Yu, M. Jiang, and Y . Huang, \u201cCreative research question\ngeneration for human-computer interaction research,\u201d 2023.\n[73] P. H \u00a8am\u00a8al\u00a8ainen, M. Tavast, and A. Kunnari, \u201cEvaluating large language\nmodels in generating synthetic hci research data: a case study,\u201d in ACM\nSIGCHI Annual Conference on Human Factors in Computing Systems .\nACM, 2023.\n[74] A. Shafeeg, I. Shazhaev, D. Mihaylov, A. Tularov, and I. Shazhaev,\n\u201cV oice assistant integrated with chat gpt,\u201d Indonesian Journal of\nComputer Science, vol. 12, no. 1, 2023.", "mimetype": "text/plain", "start_char_idx": 4476, "end_char_idx": 7296, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "97936bd6-9f93-4873-9b00-e2ee608dd859": {"__data__": {"id_": "97936bd6-9f93-4873-9b00-e2ee608dd859", "embedding": null, "metadata": {"page_label": "37", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "d46a39e9-2645-4958-9f89-40a9e13426b6", "node_type": "4", "metadata": {"page_label": "37", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "hash": "37a89bb976bf641251045fa34e708df555b6ea0be180ba665a801bf9cf389363", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "de400218-79f5-465d-93a1-f5e7aed0f955", "node_type": "1", "metadata": {"page_label": "37", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "hash": "156f65ff8e8a86ede0fe4228396c6c1436636290387c3195e56a7bc72a8a6a5d", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "John Wiley & Sons, 2023.\n[72] Y . Liu, M. Yu, M. Jiang, and Y . Huang, \u201cCreative research question\ngeneration for human-computer interaction research,\u201d 2023.\n[73] P. H \u00a8am\u00a8al\u00a8ainen, M. Tavast, and A. Kunnari, \u201cEvaluating large language\nmodels in generating synthetic hci research data: a case study,\u201d in ACM\nSIGCHI Annual Conference on Human Factors in Computing Systems .\nACM, 2023.\n[74] A. Shafeeg, I. Shazhaev, D. Mihaylov, A. Tularov, and I. Shazhaev,\n\u201cV oice assistant integrated with chat gpt,\u201d Indonesian Journal of\nComputer Science, vol. 12, no. 1, 2023.\n[75] J. Zhang, J. Pu, J. Xue, M. Yang, X. Xu, X. Wang, and F.-Y .\nWang, \u201cHivegpt: Human-machine-augmented intelligent vehicles with\ngenerative pre-trained transformer,\u201d IEEE Transactions on Intelligent\nVehicles, 2023.\n[76] H. Nori, N. King, S. M. McKinney, D. Carignan, and E. Horvitz,\n\u201cCapabilities of gpt-4 on medical challenge problems,\u201d arXiv preprint\narXiv:2303.13375, 2023.\n[77] A. Tack and C. Piech, \u201cThe ai teacher test: Measuring the pedagogical\nability of blender and gpt-3 in educational dialogues,\u201d arXiv preprint\narXiv:2205.07540, 2022.\n[78] A. Lecler, L. Duron, and P. Soyer, \u201cRevolutionizing radiology with gpt-\nbased models: Current applications, future possibilities and limitations\nof chatgpt,\u201d Diagnostic and Interventional Imaging , 2023.\n[79] D. Baidoo-Anu and L. Owusu Ansah, \u201cEducation in the era of gen-\nerative arti\ufb01cial intelligence (ai): Understanding the potential bene\ufb01ts\nof chatgpt in promoting teaching and learning,\u201d Available at SSRN\n4337484, 2023.\n[80] A. O\u2019Cain, B. D. Fedoruk, Z. Masri, R. Frost, and A. Alahmar, \u201cA\nsystem for the improvement of educational assessment using intelligent\nconversational agents,\u201d Available at SSRN 4393234 , 2023.\n[81] A. Alam, \u201cPossibilities and challenges of compounding arti\ufb01cial intel-\nligence in india\u2019s educational landscape,\u201d Alam, A.(2020). Possibilities\nand Challenges of Compounding Arti\ufb01cial Intelligence in India\u2019s\nEducational Landscape. International Journal of Advanced Science and\nTechnology, vol. 29, no. 5, pp. 5077\u20135094, 2020.\n[82] H. Chen, O. Engkvist, Y . Wang, M. Olivecrona, and T. Blaschke, \u201cThe\nrise of deep learning in drug discovery,\u201d Drug discovery today, vol. 23,\nno. 6, pp. 1241\u20131250, 2018.", "mimetype": "text/plain", "start_char_idx": 6734, "end_char_idx": 8983, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "5f8f0398-320d-4921-8ce5-285ec3c472ce": {"__data__": {"id_": "5f8f0398-320d-4921-8ce5-285ec3c472ce", "embedding": null, "metadata": {"page_label": "38", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "b803ec6c-2f3a-4872-b187-598e950ef79e", "node_type": "4", "metadata": {"page_label": "38", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "hash": "f4d4e57f7ae9eaa3babdfbb42d4f1146dd4dea7c9401314bfb00d5f44a903ff5", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "c1ad9021-2965-46a2-be50-ac38b16ab146", "node_type": "1", "metadata": {}, "hash": "a76eb4b2cc88b761efe0fd1b33ba9297e5d5f801dabf11d9e1f6ac2d60aad5f2", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "38\n[83] N. Pillai, A. Dasgupta, S. Sudaskorn, J. Fretland, and P. D. Mavroudis,\n\u201cMachine-learning-guided early drug discovery of small molecules,\u201d\nDrug Discovery Today, 2022.\n[84] Y . Kim, J.-H. Kim, J. M. Lee, M. J. Jang, Y . J. Yum, S. Kim, U. Shin,\nY .-M. Kim, H. J. Joo, and S. Song, \u201cA pre-trained bert for korean\nmedical natural language processing,\u201d Scienti\ufb01c Reports, vol. 12, no. 1,\npp. 1\u201310, 2022.\n[85] K. S. Kalyan, A. Rajasekharan, and S. Sangeetha, \u201cAmmu: a survey\nof transformer-based biomedical pretrained language models,\u201d Journal\nof biomedical informatics , vol. 126, p. 103982, 2022.\n[86] Z. Liu, R. A. Roberts, M. Lal-Nag, X. Chen, R. Huang, and W. Tong,\n\u201cAi-based language models powering drug discovery and develop-\nment,\u201d Drug Discovery Today, vol. 26, no. 11, pp. 2593\u20132607, 2021.\n[87] J. Vamathevan, D. Clark, P. Czodrowski, I. Dunham, E. Ferran, G. Lee,\nB. Li, A. Madabhushi, P. Shah, M. Spitzer et al. , \u201cApplications of\nmachine learning in drug discovery and development,\u201d Nature reviews\nDrug discovery, vol. 18, no. 6, pp. 463\u2013477, 2019.\n[88] E. Gawehn, J. A. Hiss, and G. Schneider, \u201cDeep learning in drug\ndiscovery,\u201dMolecular informatics, vol. 35, no. 1, pp. 3\u201314, 2016.\n[89] A. Lavecchia, \u201cDeep learning in drug discovery: opportunities, chal-\nlenges and future prospects,\u201d Drug discovery today , vol. 24, no. 10,\npp. 2017\u20132032, 2019.\n[90] F. Urbina, F. Lentzos, C. Invernizzi, and S. Ekins, \u201cDual use of\narti\ufb01cial-intelligence-powered drug discovery,\u201d Nature Machine Intel-\nligence, vol. 4, no. 3, pp. 189\u2013191, 2022.\n[91] M. H. Segler, T. Kogej, C. Tyrchan, and M. P. Waller, \u201cGenerating\nfocused molecule libraries for drug discovery with recurrent neural\nnetworks,\u201d ACS central science , vol. 4, no. 1, pp. 120\u2013131, 2018.\n[92] M. Ahsan, M. Rahaman, N. Anjum et al. , \u201cFrom chatgpt-3 to gpt-4:\nA signi\ufb01cant leap in ai-driven nlp tools,\u201d Saidur and Anjum, Nishath,\nFrom ChatGPT-3 to GPT-4: A Signi\ufb01cant Leap in AI-Driven NLP Tools\n(March 27, 2023) , 2023.\n[93] D. M. Levine, R. Tuwani, B. Kompa, A. Varma, S. G. Finlayson,\nA. Mehrotra, and A. Beam, \u201cThe diagnostic and triage accuracy of\nthe gpt-3 arti\ufb01cial intelligence model,\u201d medRxiv, pp. 2023\u201301, 2023.\n[94] I. Alghanmi, L. Espinosa-Anke, and S. Schockaert, \u201cProbing pre-\ntrained language models for disease knowledge,\u201d arXiv preprint\narXiv:2106.07285, 2021.\n[95] H. Ali, \u201cThe potential of gpt-4 as a personalized virtual assistant for\nbariatric surgery patients,\u201d Obesity Surgery, pp. 1\u20131, 2023.\n[96] D.-M. Vulturar, M. A. Neag, S. C. Vesa, A.-D.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2532, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "c1ad9021-2965-46a2-be50-ac38b16ab146": {"__data__": {"id_": "c1ad9021-2965-46a2-be50-ac38b16ab146", "embedding": null, "metadata": {"page_label": "38", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "b803ec6c-2f3a-4872-b187-598e950ef79e", "node_type": "4", "metadata": {"page_label": "38", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "hash": "f4d4e57f7ae9eaa3babdfbb42d4f1146dd4dea7c9401314bfb00d5f44a903ff5", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "5f8f0398-320d-4921-8ce5-285ec3c472ce", "node_type": "1", "metadata": {"page_label": "38", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "hash": "a1ca7a1bcee0f7aca9317e67212d435fb341350af93d095d849a7dc9a4f7f7b1", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "b1ab3b83-5095-4ac5-b092-ce2aba1a8b54", "node_type": "1", "metadata": {}, "hash": "4794a58109f32a27b8ad9d67a724d7b189d886428bd06e4ee117e9b0d0598778", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "2023\u201301, 2023.\n[94] I. Alghanmi, L. Espinosa-Anke, and S. Schockaert, \u201cProbing pre-\ntrained language models for disease knowledge,\u201d arXiv preprint\narXiv:2106.07285, 2021.\n[95] H. Ali, \u201cThe potential of gpt-4 as a personalized virtual assistant for\nbariatric surgery patients,\u201d Obesity Surgery, pp. 1\u20131, 2023.\n[96] D.-M. Vulturar, M. A. Neag, S. C. Vesa, A.-D. Maierean, D. Gherman,\nA. D. Buzoianu, O. H. Or \u02d8asan, and D.-A. Todea, \u201cTherapeutic ef\ufb01cacy\nand outcomes of remdesivir versus remdesivir with tocilizumab in se-\nvere sars-cov-2 infection,\u201dInternational Journal of Molecular Sciences,\nvol. 23, no. 22, p. 14462, 2022.\n[97] B. Wang, Q. Xie, J. Pei, P. Tiwari, Z. Li et al., \u201cPre-trained language\nmodels in biomedical domain: A systematic survey,\u201d arXiv preprint\narXiv:2110.05006, 2021.\n[98] S. Arslan, \u201cExploring the potential of chat gpt in personalized obesity\ntreatment,\u201d Annals of Biomedical Engineering , pp. 1\u20132, 2023.\n[99] A. Blanchard and M. Taddeo, \u201cEthical challenges of using arti\ufb01cal\nintelligence for intelligence analysis,\u201d Available at SSRN 4226631 ,\n2022.\n[100] B. Balsmeier and M. Woerter, \u201cIs this time different? how digitalization\nin\ufb02uences job creation and destruction,\u201d Research policy, vol. 48, no. 8,\np. 103765, 2019.\n[101] F. Pesapane, M. Codari, and F. Sardanelli, \u201cArti\ufb01cial intelligence\nin medical imaging: threat or opportunity? radiologists again at the\nforefront of innovation in medicine,\u201dEuropean radiology experimental,\nvol. 2, pp. 1\u201310, 2018.\n[102] I. Carvalho and S. Ivanov, \u201cChatgpt for tourism: applications, bene\ufb01ts\nand risks,\u201d Tourism Review, 2023.\n[103] R. S. Rathore, S. Sangwan, and O. Kaiwartya, \u201cTowards trusted green\ncomputing for wireless sensor networks: Multi metric optimization\napproach.\u201d Adhoc & Sensor Wireless Networks , vol. 49, 2021.\n[104] S. Shah, H. Ghomeshi, E. Vakaj, E. Cooper, and R. Mohammad, \u201cAn\nensemble-learning-based technique for bimodal sentiment analysis,\u201d\nBig Data and Cognitive Computing , vol. 7, no. 2, p. 85, 2023.\n[105] J. Salminen, C. Kandpal, A. M. Kamel, S.-g. Jung, and B. J. Jansen,\n\u201cCreating and detecting fake reviews of online products,\u201d Journal of\nRetailing and Consumer Services , vol. 64, p. 102771, 2022.\n[106] A. S. George and A. H. George, \u201cA review of chatgpt ai\u2019s impact on\nseveral business sectors,\u201d Partners Universal International Innovation\nJournal, vol. 1, no. 1, pp. 9\u201323, 2023.\n[107] A. El-Ansari and A. Beni-Hssane, \u201cSentiment analysis for personalized\nchatbots in e-commerce applications,\u201d Wireless Personal Communica-\ntions, vol. 129, no. 3, pp. 1623\u20131644, 2023.\n[108] K. Goei, M. Hendriksen, M. de Rijke et al. , \u201cTackling attribute \ufb01ne-\ngrainedness in cross-modal fashion search with multi-level features,\u201d\nin SIGIR 2021 Workshop on eCommerce. ACM , 2021.\n[109] S. G. Bouschery, V .", "mimetype": "text/plain", "start_char_idx": 2173, "end_char_idx": 4965, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "b1ab3b83-5095-4ac5-b092-ce2aba1a8b54": {"__data__": {"id_": "b1ab3b83-5095-4ac5-b092-ce2aba1a8b54", "embedding": null, "metadata": {"page_label": "38", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "b803ec6c-2f3a-4872-b187-598e950ef79e", "node_type": "4", "metadata": {"page_label": "38", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "hash": "f4d4e57f7ae9eaa3babdfbb42d4f1146dd4dea7c9401314bfb00d5f44a903ff5", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "c1ad9021-2965-46a2-be50-ac38b16ab146", "node_type": "1", "metadata": {"page_label": "38", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "hash": "006e52a73e01b193653f629b499222b6b98ba1735bc70956fdfa8240fe077704", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "a09830d7-eef3-4ba8-b66d-228765342ed0", "node_type": "1", "metadata": {}, "hash": "e2586ca5f4520f53cc8cfec25204d3b5d9eb6a5363635125c8ec5d2bb93ab16c", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "1, no. 1, pp. 9\u201323, 2023.\n[107] A. El-Ansari and A. Beni-Hssane, \u201cSentiment analysis for personalized\nchatbots in e-commerce applications,\u201d Wireless Personal Communica-\ntions, vol. 129, no. 3, pp. 1623\u20131644, 2023.\n[108] K. Goei, M. Hendriksen, M. de Rijke et al. , \u201cTackling attribute \ufb01ne-\ngrainedness in cross-modal fashion search with multi-level features,\u201d\nin SIGIR 2021 Workshop on eCommerce. ACM , 2021.\n[109] S. G. Bouschery, V . Blazevic, and F. T. Piller, \u201cAugmenting human\ninnovation teams with arti\ufb01cial intelligence: Exploring transformer-\nbased language models,\u201d Journal of Product Innovation Management ,\nvol. 40, no. 2, pp. 139\u2013153, 2023.\n[110] R. Bommasani, D. A. Hudson, E. Adeli, R. Altman, S. Arora, S. von\nArx, M. S. Bernstein, J. Bohg, A. Bosselut, E. Brunskill et al. , \u201cOn\nthe opportunities and risks of foundation models,\u201d arXiv preprint\narXiv:2108.07258, 2021.\n[111] J. Cowls, A. Tsamados, M. Taddeo, and L. Floridi, \u201cThe\nai gambit: leveraging arti\ufb01cial intelligence to combat climate\nchange\u2014opportunities, challenges, and recommendations,\u201d Ai & So-\nciety, pp. 1\u201325, 2021.\n[112] H. Benbya, T. H. Davenport, and S. Pachidi, \u201cArti\ufb01cial intelligence in\norganizations: Current state and future opportunities,\u201d MIS Quarterly\nExecutive, vol. 19, no. 4, 2020.\n[113] Y . Liu, T. Han, S. Ma, J. Zhang, Y . Yang, J. Tian, H. He, A. Li,\nM. He, Z. Liu et al. , \u201cSummary of chatgpt/gpt-4 research and per-\nspective towards the future of large language models,\u201d arXiv preprint\narXiv:2304.01852, 2023.\n[114] S. Biswas, \u201cImportance of chat gpt in agriculture: According to chat\ngpt,\u201d Available at SSRN 4405391 , 2023.\n[115] M. S. Farooq, S. Riaz, A. Abid, K. Abid, and M. A. Naeem, \u201cA\nsurvey on the role of iot in agriculture for the implementation of smart\nfarming,\u201d Ieee Access, vol. 7, pp. 156 237\u2013156 271, 2019.\n[116] H. Wang, H. Wu, H. Zhu, Y . Miao, Q. Wang, S. Qiao, H. Zhao,\nC. Chen, and J. Zhang, \u201cA residual lstm and seq2seq neural network\nbased on gpt for chinese rice-related question and answer system,\u201d\nAgriculture, vol. 12, no. 6, p. 813, 2022.\n[117] Y . K. Dwivedi, N. Kshetri, L. Hughes, E. L. Slade, A. Jeyaraj, A. K.\nKar, A. M. Baabdullah, A. Koohang, V . Raghavan, M. Ahuja et al. ,\n\u201c\u201cso what if chatgpt wrote it?\u201d multidisciplinary perspectives on op-\nportunities, challenges and implications of generative conversational ai\nfor research, practice and policy,\u201d International Journal of Information\nManagement, vol. 71, p. 102642, 2023.\n[118] S. Biswas, \u201cProspective role of chat gpt in the military: According to\nchatgpt,\u201d Qeios, 2023.\n[119] P. Helo and A. Shamsuzzoha, \u201cReal-time supply chain\u2014a blockchain\narchitecture for project deliveries,\u201d Robotics and Computer-Integrated\nManufacturing, vol. 63, p. 101909, 2020.", "mimetype": "text/plain", "start_char_idx": 4530, "end_char_idx": 7277, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "a09830d7-eef3-4ba8-b66d-228765342ed0": {"__data__": {"id_": "a09830d7-eef3-4ba8-b66d-228765342ed0", "embedding": null, "metadata": {"page_label": "38", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "b803ec6c-2f3a-4872-b187-598e950ef79e", "node_type": "4", "metadata": {"page_label": "38", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "hash": "f4d4e57f7ae9eaa3babdfbb42d4f1146dd4dea7c9401314bfb00d5f44a903ff5", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "b1ab3b83-5095-4ac5-b092-ce2aba1a8b54", "node_type": "1", "metadata": {"page_label": "38", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "hash": "48c04daa032657396e558b73aebbcac41daaf7943ba7bccbbf4b5105268ebde0", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Raghavan, M. Ahuja et al. ,\n\u201c\u201cso what if chatgpt wrote it?\u201d multidisciplinary perspectives on op-\nportunities, challenges and implications of generative conversational ai\nfor research, practice and policy,\u201d International Journal of Information\nManagement, vol. 71, p. 102642, 2023.\n[118] S. Biswas, \u201cProspective role of chat gpt in the military: According to\nchatgpt,\u201d Qeios, 2023.\n[119] P. Helo and A. Shamsuzzoha, \u201cReal-time supply chain\u2014a blockchain\narchitecture for project deliveries,\u201d Robotics and Computer-Integrated\nManufacturing, vol. 63, p. 101909, 2020.\n[120] R. Kadel, H. Shrestha, A. Shrestha, P. Sharma, N. Shrestha, J. Bashyal,\nand S. Shrestha, \u201cEmergence of ai in cyber security,\u201d International\nResearch Journal of Modernization in Engineering Technology and\nScience, 2022.\n[121] H. Benbya, S. Pachidi, and S. Jarvenpaa, \u201cSpecial issue editorial:\nArti\ufb01cial intelligence in organizations: Implications for information\nsystems research,\u201d Journal of the Association for Information Systems ,\nvol. 22, no. 2, p. 10, 2021.\n[122] T. Zheng, M. Ardolino, A. Bacchetti, and M. Perona, \u201cThe applications\nof industry 4.0 technologies in manufacturing context: a systematic lit-\nerature review,\u201dInternational Journal of Production Research, vol. 59,\nno. 6, pp. 1922\u20131954, 2021.\n[123] B. Rathore, \u201cDigital transformation 4.0: Integration of arti\ufb01cial in-\ntelligence & metaverse in marketing,\u201d Eduzone: International Peer\nReviewed/Refereed Multidisciplinary Journal, vol. 12, no. 1, pp. 42\u201348,\n2023.\n[124] J. Bulchand-Gidumal, \u201cImpact of arti\ufb01cial intelligence in travel,\ntourism, and hospitality,\u201d in Handbook of e-Tourism. Springer, 2022,\npp. 1943\u20131962.\n[125] N. Gillani, R. Eynon, C. Chiabaut, and K. Finkel, \u201cUnpacking the\n\u201cblack box\u201d of ai in education,\u201d Educational Technology & Society ,\nvol. 26, no. 1, pp. 99\u2013111, 2023.\n[126] N. Mehrabi, F. Morstatter, N. Saxena, K. Lerman, and A. Galstyan,\n\u201cA survey on bias and fairness in machine learning,\u201d ACM Computing\nSurveys (CSUR), vol. 54, no. 6, pp. 1\u201335, 2021.\n[127] F. T. Tschang and E. Almirall, \u201cArti\ufb01cial intelligence as augmenting\nautomation: Implications for employment,\u201d Academy of Management\nPerspectives, vol. 35, no. 4, pp. 642\u2013659, 2021.\n[128] V . Jain, B. Malviya, and S. Arya, \u201cAn overview of electronic commerce\n(e-commerce),\u201d Journal of Contemporary Issues in Business and Gov-\nernment\u2014 Vol , vol. 27, no. 3, p. 666, 2021.\n[129] B. Feijoo and A. Garc \u00b4\u0131a Gonz\u00b4alez, \u201cOnline shopping routines among\nchilean children: level of expansion and main causes,\u201d 2020.", "mimetype": "text/plain", "start_char_idx": 6713, "end_char_idx": 9243, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "c9269c6e-122f-4e12-9068-81c32dc57e1f": {"__data__": {"id_": "c9269c6e-122f-4e12-9068-81c32dc57e1f", "embedding": null, "metadata": {"page_label": "39", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "9b2ed34c-c574-4e52-b340-35075978d238", "node_type": "4", "metadata": {"page_label": "39", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "hash": "d1f96bda86e399156678171dd4866c2964b8d49dd06356ef0907d15c2d96948b", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "06055c5d-a657-4a6c-b66a-7a8e433a6728", "node_type": "1", "metadata": {}, "hash": "fa51cd8b5cd3792ee676354aa1c90a0ff4e5e49ce0c04630d01d43adb2b576b7", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "39\n[130] X. Zhang, Y . Jiang, Y . Shang, Z. Cheng, C. Zhang, X. Fan, Y . Xiao, and\nB. Long, \u201cDsgpt: Domain-speci\ufb01c generative pre-training of transform-\ners for text generation in e-commerce title and review summarization,\u201d\nin Proceedings of the 44th International ACM SIGIR Conference on\nResearch and Development in Information Retrieval , 2021, pp. 2146\u2013\n2150.\n[131] A. Radford, J. Wu, R. Child, D. Luan, D. Amodei, I. Sutskever et al.,\n\u201cLanguage models are unsupervised multitask learners,\u201d OpenAI blog,\nvol. 1, no. 8, p. 9, 2019.\n[132] T. Eloundou, S. Manning, P. Mishkin, and D. Rock, \u201cGpts are gpts:\nAn early look at the labor market impact potential of large language\nmodels,\u201d arXiv preprint arXiv:2303.10130 , 2023.\n[133] P. Maddigan and T. Susnjak, \u201cChat2vis: Generating data visualisations\nvia natural language using chatgpt, codex and gpt-3 large language\nmodels,\u201d IEEE Access, 2023.\n[134] N. Jain, S. Vaidyanath, A. Iyer, N. Natarajan, S. Parthasarathy, S. Ra-\njamani, and R. Sharma, \u201cJigsaw: Large language models meet program\nsynthesis,\u201d in Proceedings of the 44th International Conference on\nSoftware Engineering, 2022, pp. 1219\u20131231.\n[135] A. Haleem, M. Javaid, and R. P. Singh, \u201cAn era of chatgpt as a\nsigni\ufb01cant futuristic support tool: A study on features, abilities, and\nchallenges,\u201d BenchCouncil transactions on benchmarks, standards and\nevaluations, vol. 2, no. 4, p. 100089, 2022.\n[136] N. Brand, W. Odom, and S. Barnett, \u201cEnvisioning and understanding\norientations to introspective ai: Exploring a design space with meta.\naware,\u201d inProceedings of the 2023 CHI Conference on Human Factors\nin Computing Systems , 2023, pp. 1\u201318.\n[137] N. Dehouche, \u201cPlagiarism in the age of massive generative pre-trained\ntransformers (gpt-3),\u201d Ethics in Science and Environmental Politics ,\nvol. 21, pp. 17\u201323, 2021.\n[138] B. D. Lund, T. Wang, N. R. Mannuru, B. Nie, S. Shimray, and Z. Wang,\n\u201cChatgpt and a new academic reality: Arti\ufb01cial intelligence-written\nresearch papers and the ethics of the large language models in scholarly\npublishing,\u201d Journal of the Association for Information Science and\nTechnology, 2023.\n[139] M. Javaid, A. Haleem, and R. P. Singh, \u201cChatgpt for healthcare ser-\nvices: An emerging stage for an innovative perspective,\u201d BenchCouncil\nTransactions on Benchmarks, Standards and Evaluations , p. 100105,\n2023.\n[140] P. P. Ray, \u201cChatgpt: A comprehensive review on background, appli-\ncations, key challenges, bias, ethics, limitations and future scope,\u201d\nInternet of Things and Cyber-Physical Systems , 2023.\n[141] E. G. Wilcox, J. Gauthier, J. Hu, P. Qian, and R. Levy, \u201cOn the\npredictive power of neural language models for human real-time\ncomprehension behavior,\u201d arXiv preprint arXiv:2006.01912 , 2020.\n[142] R. Sridhar and D. Yang, \u201cExplaining toxic text via knowledge enhanced\ntext generation,\u201d in Proceedings of the 2022 Conference of the North\nAmerican Chapter of the Association for Computational Linguistics:\nHuman Language Technologies, 2022, pp. 811\u2013826.\n[143] J. Bryant and P. V orderer, Psychology of entertainment . Routledge,\n2013.\n[144] H. H. Thorp, \u201cChatgpt is fun, but not an author,\u201d pp. 313\u2013313, 2023.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 3151, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "06055c5d-a657-4a6c-b66a-7a8e433a6728": {"__data__": {"id_": "06055c5d-a657-4a6c-b66a-7a8e433a6728", "embedding": null, "metadata": {"page_label": "39", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "9b2ed34c-c574-4e52-b340-35075978d238", "node_type": "4", "metadata": {"page_label": "39", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "hash": "d1f96bda86e399156678171dd4866c2964b8d49dd06356ef0907d15c2d96948b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "c9269c6e-122f-4e12-9068-81c32dc57e1f", "node_type": "1", "metadata": {"page_label": "39", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "hash": "8f680c4a343a2b08bb87758c96d73dfdedb9d1ba0c125110ddd2eaf4cba91b1b", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "599d5077-4e0e-4564-af46-71831e865bfb", "node_type": "1", "metadata": {}, "hash": "2911d380c5a6326fc42dd7b14f23395bb53ae7dfc8a691f807d34a92a932fa66", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "[141] E. G. Wilcox, J. Gauthier, J. Hu, P. Qian, and R. Levy, \u201cOn the\npredictive power of neural language models for human real-time\ncomprehension behavior,\u201d arXiv preprint arXiv:2006.01912 , 2020.\n[142] R. Sridhar and D. Yang, \u201cExplaining toxic text via knowledge enhanced\ntext generation,\u201d in Proceedings of the 2022 Conference of the North\nAmerican Chapter of the Association for Computational Linguistics:\nHuman Language Technologies, 2022, pp. 811\u2013826.\n[143] J. Bryant and P. V orderer, Psychology of entertainment . Routledge,\n2013.\n[144] H. H. Thorp, \u201cChatgpt is fun, but not an author,\u201d pp. 313\u2013313, 2023.\n[145] S. Shahriar and K. Hayawi, \u201cLet\u2019s have a chat! a conversation with\nchatgpt: Technology, applications, and limitations,\u201d arXiv preprint\narXiv:2302.13817, 2023.\n[146] M. U. Haque, I. Dharmadasa, Z. T. Sworna, R. N. Rajapakse, and\nH. Ahmad, \u201c\u201d i think this is the most disruptive technology\u201d: Exploring\nsentiments of chatgpt early adopters using twitter data,\u201d arXiv preprint\narXiv:2212.05856, 2022.\n[147] O. AI. [Online]. Available: https://openai.com/product/gpt-4\n[148] opchatsgpt, \u201cImpact of chat gpt on the entertainment industry,\u201d\nMar 2023. [Online]. Available: https://opchatsgpt.com/chat-gpt-in-\nentertainment/\n[149] \u201cThe Power of Chat GPT: Creating Personalized Marketing\nand Ef\ufb01cient Customer Support. \u2014 linkedin.com,\u201d https:\n//www.linkedin.com/pulse/power-chat-gpt-creating-personalized-\nmarketing-customer-bundhoo/, [Accessed 24-Apr-2023].\n[150] \u201cChat GPT-4 in the Film Industry: Scriptwriting, Editing, and More;\nTS2 SPACE \u2014 ts2.space,\u201d https://ts2.space/en/chat-gpt-4-in-the-\n\ufb01lm-industry-scriptwriting-editing-and-more/#: \u223c:text=GPT\\%2D4\\\n%20has\\%20the\\%20potential,and\\%20consistency\\%20than\\\n%20ever\\%20before., 2023, [Accessed 24-Apr-2023].\n[151] E. i. bd, \u201cChatgpt: The impact of chat gpt on the entertainment\nindustry - march 24, 2023 educationsinbd,\u201d Mar 2023. [Online].\nAvailable: https://educationsinbd.com/the-impact-of-chat-gpt-on-the-\nentertainment-industry/\n[152] A. J. Veal, \u201cThe concept of lifestyle: a review,\u201d Leisure Studies, vol. 12,\nno. 4, pp. 233\u2013252, 1993.\n[153] M. Jensen, \u201cDe\ufb01ning lifestyle,\u201d Environmental sciences, vol. 4, no. 2,\npp. 63\u201373, 2007.\n[154] P. Contoyannis and A. M. Jones, \u201cSocio-economic status, health and\nlifestyle,\u201d Journal of health economics , vol. 23, no. 5, pp. 965\u2013995,\n2004.\n[155] M. J. Reeves and A. P. Rafferty, \u201cHealthy lifestyle characteristics\namong adults in the united states, 2000,\u201d Archives of internal medicine,\nvol. 165, no. 8, pp. 854\u2013857, 2005.\n[156] Y . H. Yeo, J. S. Samaan, W. H. Ng, P.-S. Ting, H. Trivedi, A. Vipani,\nW. Ayoub, J. D. Yang, O. Liran, B. Spiegel et al. , \u201cAssessing the\nperformance of chatgpt in answering questions regarding cirrhosis and\nhepatocellular carcinoma,\u201d medRxiv, pp. 2023\u201302, 2023.\n[157] S. S. Biswas, \u201cRole of chat gpt in public health,\u201d Annals of Biomedical\nEngineering, pp.", "mimetype": "text/plain", "start_char_idx": 2538, "end_char_idx": 5438, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "599d5077-4e0e-4564-af46-71831e865bfb": {"__data__": {"id_": "599d5077-4e0e-4564-af46-71831e865bfb", "embedding": null, "metadata": {"page_label": "39", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "9b2ed34c-c574-4e52-b340-35075978d238", "node_type": "4", "metadata": {"page_label": "39", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "hash": "d1f96bda86e399156678171dd4866c2964b8d49dd06356ef0907d15c2d96948b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "06055c5d-a657-4a6c-b66a-7a8e433a6728", "node_type": "1", "metadata": {"page_label": "39", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "hash": "505cd3070008d64b13d31c8e84bd6b4960d9a0eaaeec777f6499fb96c069e696", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "013efaeb-0953-47f4-b292-e4ab0ab9ec86", "node_type": "1", "metadata": {}, "hash": "409308dc5b194c9566eb0096990c45e5c364c6114d357b554b5f52e352b04c6b", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "165, no. 8, pp. 854\u2013857, 2005.\n[156] Y . H. Yeo, J. S. Samaan, W. H. Ng, P.-S. Ting, H. Trivedi, A. Vipani,\nW. Ayoub, J. D. Yang, O. Liran, B. Spiegel et al. , \u201cAssessing the\nperformance of chatgpt in answering questions regarding cirrhosis and\nhepatocellular carcinoma,\u201d medRxiv, pp. 2023\u201302, 2023.\n[157] S. S. Biswas, \u201cRole of chat gpt in public health,\u201d Annals of Biomedical\nEngineering, pp. 1\u20132, 2023.\n[158] M. Patkar, \u201c5 Free Travel Planning AI and ChatGPT Apps to Get an\nInstant Itinerary \u2014 makeuseof.com,\u201d https://www.makeuseof.com/free-\ntravel-planning-ai-chatgpt-apps/, [Accessed 24-Apr-2023].\n[159] \u201cYour ai-powered personal chef.\u201d [Online]. Available: https://www.\nchefgpt.xyz/\n[160] lechjaLearnCrafts, \u201cLearn Crafts & Hobbies w/ GPT Chat \u2014\nlechja.com,\u201d https://www.lechja.com/ai/learn-crafts-hobbies-w-gpt-\nchat, 2023, [Accessed 24-Apr-2023].\n[161] \u201cHow to use chatgpt in your job search \u2014 indeed.com.\u201d [On-\nline]. Available: https://www.indeed.com/career-advice/news/chatgpt-\njob-search\n[162] L. Floridi and M. Chiriatti, \u201cGpt-3: Its nature, scope, limits, and\nconsequences,\u201d Minds and Machines , vol. 30, pp. 681\u2013694, 2020.\n[163] S. Toshniwal, S. Wiseman, K. Livescu, and K. Gimpel, \u201cLearning chess\nblindfolded,\u201d 2021.\n[164] J. Freiknecht and W. Effelsberg, \u201cProcedural generation of interactive\nstories using language models,\u201d in Proceedings of the 15th Interna-\ntional Conference on the Foundations of Digital Games , 2020, pp.\n1\u20138.\n[165] S. V \u00a8artinen, P. H \u00a8am\u00a8al\u00a8ainen, and C. Guckelsberger, \u201cGenerating role-\nplaying game quests with gpt language models,\u201d IEEE Transactions on\nGames, pp. 1\u201312, 2022.\n[166] J. van Stegeren and J. Myunde\ufb01nedliwiec, \u201cFine-tuning gpt-2 on\nannotated rpg quests for npc dialogue generation,\u201d in Proceedings\nof the 16th International Conference on the Foundations of Digital\nGames, ser. FDG \u201921. New York, NY , USA: Association for\nComputing Machinery, 2021. [Online]. Available: https://doi.org/10.\n1145/3472538.3472595\n[167] P. Roetzer and M. Kaput, Marketing Arti\ufb01cial Intelligence: AI, Mar-\nketing, and the Future of Business . BenBella Books, 2022.\n[168] J. Thiergart, S. Huber, and T. \u00a8Ubellacker, \u201cUnderstanding emails\nand drafting responses\u2013an approach using gpt-3,\u201d arXiv preprint\narXiv:2102.03062, 2021.\n[169] X. Bai, L. Duan, R. Tang, G. Batra, and R. Agrawal, \u201cImproving text-\nbased similar product recommendation for dynamic product advertising\nat yahoo,\u201d in Proceedings of the 31st ACM International Conference on\nInformation & Knowledge Management , ser. CIKM \u201922. New York,\nNY , USA: Association for Computing Machinery, 2022, p. 2883\u20132892.\n[Online]. Available: https://doi.org/10.1145/3511808.3557129\n[170] P. S. Neves, \u201cChat gpt ais \u201cinterview\u201d 1, december 2022,\u201d AIS-\nArchitecture Image Studies, vol. 3, no. 2, pp. 58\u201367, 2022.\n[171] X.-R. Gong, J.-X.", "mimetype": "text/plain", "start_char_idx": 5044, "end_char_idx": 7861, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "013efaeb-0953-47f4-b292-e4ab0ab9ec86": {"__data__": {"id_": "013efaeb-0953-47f4-b292-e4ab0ab9ec86", "embedding": null, "metadata": {"page_label": "39", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "9b2ed34c-c574-4e52-b340-35075978d238", "node_type": "4", "metadata": {"page_label": "39", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "hash": "d1f96bda86e399156678171dd4866c2964b8d49dd06356ef0907d15c2d96948b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "599d5077-4e0e-4564-af46-71831e865bfb", "node_type": "1", "metadata": {"page_label": "39", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "hash": "4f955b634e8520b8bf2d315e852a204e8471f7659967264290852ec9c37b7cbd", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "[169] X. Bai, L. Duan, R. Tang, G. Batra, and R. Agrawal, \u201cImproving text-\nbased similar product recommendation for dynamic product advertising\nat yahoo,\u201d in Proceedings of the 31st ACM International Conference on\nInformation & Knowledge Management , ser. CIKM \u201922. New York,\nNY , USA: Association for Computing Machinery, 2022, p. 2883\u20132892.\n[Online]. Available: https://doi.org/10.1145/3511808.3557129\n[170] P. S. Neves, \u201cChat gpt ais \u201cinterview\u201d 1, december 2022,\u201d AIS-\nArchitecture Image Studies, vol. 3, no. 2, pp. 58\u201367, 2022.\n[171] X.-R. Gong, J.-X. Jin, and T. Zhang, \u201cSentiment analysis using autore-\ngressive language modeling and broad learning system,\u201d in 2019 IEEE\nInternational Conference on Bioinformatics and Biomedicine (BIBM) .\nIEEE, 2019, pp. 1130\u20131134.\n[172] A. H. Sweidan, N. El-Bendary, and H. Al-Feel, \u201cSentence-level aspect-\nbased sentiment analysis for classifying adverse drug reactions (adrs)\nusing hybrid ontology-xlnet transfer learning,\u201d IEEE Access, vol. 9, pp.\n90 828\u201390 846, 2021.\n[173] F. Wei and U. T. Nguyen, \u201cStock trend prediction using \ufb01nancial market\nnews and bert,\u201d Wall Street Journal, 2018.\n[174] T. Yue, D. Au, C. C. Au, and K. Y . Iu, \u201cDemocratizing \ufb01nancial knowl-\nedge with chatgpt by openai: Unleashing the power of technology,\u201d\nAvailable at SSRN 4346152 , 2023.\n[175] \u201dSiri\u201d. [Accessed on 25.03.2023]. [Online]. Available: https://www.\napple.com/in/siri/\n[176] \u201dSiri ChatGPT\u201d. [Accessed on 25.03.2023]. [Online]. Available:\nhttps://support.apple.com/en-in/guide/shortcuts/apd07c25bb38/ios\n[177] \u201dSiri ChatGPT\u201d. [Accessed on 25.03.2023]. [Online]. Available:\nhttps://gpt3demo.com/apps/chatgpt-sirigpt-apple-ios", "mimetype": "text/plain", "start_char_idx": 7305, "end_char_idx": 8963, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "c89a50d6-2ce7-4171-a280-a52601857a1b": {"__data__": {"id_": "c89a50d6-2ce7-4171-a280-a52601857a1b", "embedding": null, "metadata": {"page_label": "40", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "6ae76f48-416b-4355-b014-9da1999e6092", "node_type": "4", "metadata": {"page_label": "40", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "hash": "86054b54bebdcc529a6b080c68fa1939081750707843928bf22b3f422a11e08b", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "c55c0697-5756-459f-99da-83f17cf672a4", "node_type": "1", "metadata": {}, "hash": "cfcabcdf53c0a7978f790ca3b0963f8debf4b96808cafd8b921cd07efe136cda", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "40\n[178] \u201dAI Dungeon: A text-based adventure-story game you direct (and\nstar in) while the AI brings it to life.\u201d. [Accessed on 30.03.2023].\n[Online]. Available: https://aidungeon.io/\n[179] \u201dIt Began as an AI-Fueled Dungeon Game. It Got Much\nDarker\u201d. [Accessed on 25.03.2023]. [Online]. Available: https:\n//www.wired.com/story/ai-fueled-dungeon-game-got-much-darker/\n[180] \u201dWhatever you want to ask, our chat has the answers\u201d. [Accessed on\n25.03.2023]. [Online]. Available: https://www.copy.ai/\n[181] \u201dIntroducing, The BOND Network.\u201d. [Accessed on 25.03.2023].\n[Online]. Available: https://www.bond.ai/\n[182] \u201dSave hundreds of hours analyzing feedback.\u201d. [Accessed on\n29.03.2023]. [Online]. Available: https://www.askviable.com/\n[183] \u201dai\u2014channels: make contact with intelligent minds\u201d. [Accessed on\n30.03.2023]. [Online]. Available: https://aichannels.app/\n[184] \u201dAutomate your meeting notes\u201d. [Accessed on 30.03.2023]. [Online].\nAvailable: https://\ufb01re\ufb02ies.ai/\n[185] A. Papangelis, M. Namazifar, C. Khatri, Y .-C. Wang, P. Molino, and\nG. Tur, \u201cPlato dialogue system: A \ufb02exible conversational ai research\nplatform,\u201d arXiv preprint arXiv:2001.06463 , 2020.\n[186] P. Dhariwal, H. Jun, C. Payne, J. W. Kim, A. Radford, and\nI. Sutskever, \u201cJukebox: A generative model for music,\u201d arXiv preprint\narXiv:2005.00341, 2020.\n[187] D. Adiwardana, M.-T. Luong, D. R. So, J. Hall, N. Fiedel, R. Thop-\npilan, Z. Yang, A. Kulshreshtha, G. Nemade, Y . Lu et al. , \u201cTowards\na human-like open-domain chatbot,\u201d arXiv preprint arXiv:2001.09977,\n2020.\n[188] M. M. van Buchem, H. Boosman, M. P. Bauer, I. M. Kant, S. A.\nCammel, and E. W. Steyerberg, \u201cThe digital scribe in clinical practice:\na scoping review and research agenda,\u201d NPJ digital medicine , vol. 4,\nno. 1, p. 57, 2021.\n[189] K. Hao, \u201cFacebook\u2019s new polyglot ai can translate between 100\nlanguages,\u201d 2020.\n[190] Y . Gan, G. Lu, Z. Su, L. Wang, J. Zhou, J. Jiang, and D. Chen, \u201cA\njoint domain-speci\ufb01c pre-training method based on data enhancement,\u201d\nApplied Sciences, vol. 13, no. 7, p. 4115, 2023.\n[191] \u201cChatgpt plugins,\u201d Mar 2023. [Online]. Available: https://openai.com/\nblog/chatgpt-plugins\n[192] B. Bhattarai, O.-C. Granmo, and L. Jiao, \u201cConvtexttm: An explainable\nconvolutional tsetlin machine framework for text classi\ufb01cation,\u201d in\nProceedings of the Thirteenth Language Resources and Evaluation\nConference, 2022, pp. 3761\u20133770.\n[193] A. Narasimhan, K. P. A. V . Rao et al., \u201cCgems: A metric model for au-\ntomatic code generation using gpt-3,\u201darXiv preprint arXiv:2108.10168,\n2021.\n[194] J. E. Zini and M. Awad, \u201cOn the explainability of natural language\nprocessing deep models,\u201d ACM Computing Surveys, vol. 55, no. 5, pp.\n1\u201331, 2022.", "mimetype": "text/plain", "start_char_idx": 0, "end_char_idx": 2678, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "c55c0697-5756-459f-99da-83f17cf672a4": {"__data__": {"id_": "c55c0697-5756-459f-99da-83f17cf672a4", "embedding": null, "metadata": {"page_label": "40", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "6ae76f48-416b-4355-b014-9da1999e6092", "node_type": "4", "metadata": {"page_label": "40", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "hash": "86054b54bebdcc529a6b080c68fa1939081750707843928bf22b3f422a11e08b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "c89a50d6-2ce7-4171-a280-a52601857a1b", "node_type": "1", "metadata": {"page_label": "40", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "hash": "10bd4245c432dfd44b9a7b4b1179edea288830d8b409ed7a11fc99cb61b9614e", "class_name": "RelatedNodeInfo"}, "3": {"node_id": "6d7ec912-b086-4d2b-afd6-2943346e20f6", "node_type": "1", "metadata": {}, "hash": "715ca813cb4a2f04a5d0769d824844be3409b58e062d9494d398130c15db45ba", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "Granmo, and L. Jiao, \u201cConvtexttm: An explainable\nconvolutional tsetlin machine framework for text classi\ufb01cation,\u201d in\nProceedings of the Thirteenth Language Resources and Evaluation\nConference, 2022, pp. 3761\u20133770.\n[193] A. Narasimhan, K. P. A. V . Rao et al., \u201cCgems: A metric model for au-\ntomatic code generation using gpt-3,\u201darXiv preprint arXiv:2108.10168,\n2021.\n[194] J. E. Zini and M. Awad, \u201cOn the explainability of natural language\nprocessing deep models,\u201d ACM Computing Surveys, vol. 55, no. 5, pp.\n1\u201331, 2022.\n[195] R. K. Yadav, L. Jiao, O.-C. Granmo, and M. Goodwin, \u201cAn inter-\npretable word sense classi\ufb01er for human explainable chatbot,\u201d inAgents\nand Arti\ufb01cial Intelligence: 13th International Conference, ICAART\n2021, Virtual Event, February 4\u20136, 2021, Revised Selected Papers .\nSpringer, 2022, pp. 236\u2013249.\n[196] A. Chan, \u201cGpt-3 and instructgpt: technological dystopianism, utopi-\nanism, and \u201ccontextual\u201d perspectives in ai ethics and industry,\u201d AI and\nEthics, pp. 1\u201312, 2022.\n[197] M. Zhang and J. Li, \u201cA commentary of gpt-3 in mit technology review\n2021,\u201d Fundamental Research, vol. 1, no. 6, pp. 831\u2013833, 2021.\n[198] H. R. Kirk, Y . Jun, F. V olpin, H. Iqbal, E. Benussi, F. Dreyer,\nA. Shtedritski, and Y . Asano, \u201cBias out-of-the-box: An empirical\nanalysis of intersectional occupational biases in popular generative\nlanguage models,\u201d Advances in neural information processing systems ,\nvol. 34, pp. 2611\u20132624, 2021.\n[199] S. S. Biswas, \u201cPotential use of chat gpt in global warming,\u201d Annals of\nbiomedical engineering, pp. 1\u20132, 2023.\n[200] P. H. Seo, A. Nagrani, A. Arnab, and C. Schmid, \u201cEnd-to-end genera-\ntive pretraining for multimodal video captioning,\u201d inProceedings of the\nIEEE/CVF Conference on Computer Vision and Pattern Recognition ,\n2022, pp. 17 959\u201317 968.\n[201] W. Ji, Y . Wei, Z. Zheng, H. Fei, and T.-s. Chua, \u201cDeep multimodal\nlearning for information retrieval,\u201d in ACM International Conference\non Multimedia, 2023.\n[202] V . Liu, H. Qiao, and L. Chilton, \u201cOpal: Multimodal image generation\nfor news illustration,\u201d in Proceedings of the 35th Annual ACM Sympo-\nsium on User Interface Software and Technology , 2022, pp. 1\u201317.\n[203] C. Guo, A. Sablayrolles, H. J \u00b4egou, and D. Kiela, \u201cGradient-\nbased adversarial attacks against text transformers,\u201d arXiv preprint\narXiv:2104.13733, 2021.\n[204] A. Shafahi, M. Najibi, A. Ghiasi, Z. Xu, J. P. Dickerson, C. Studer,\nL. S. Davis, G. Taylor, and T. Goldstein, \u201cAdversarial training\nfor free!\u201d CoRR, vol. abs/1904.12843, 2019. [Online]. Available:\nhttp://arxiv.org/abs/1904.12843\n[205] T. Bai, J. Luo, J. Zhao, B. Wen, and Q. Wang, \u201cRecent advances\nin adversarial training for adversarial robustness,\u201d CoRR, vol.\nabs/2102.01356, 2021. [Online]. Available: https://arxiv.org/abs/2102.", "mimetype": "text/plain", "start_char_idx": 2159, "end_char_idx": 4919, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}, "6d7ec912-b086-4d2b-afd6-2943346e20f6": {"__data__": {"id_": "6d7ec912-b086-4d2b-afd6-2943346e20f6", "embedding": null, "metadata": {"page_label": "40", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "excluded_embed_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "excluded_llm_metadata_keys": ["file_name", "file_type", "file_size", "creation_date", "last_modified_date", "last_accessed_date"], "relationships": {"1": {"node_id": "6ae76f48-416b-4355-b014-9da1999e6092", "node_type": "4", "metadata": {"page_label": "40", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "hash": "86054b54bebdcc529a6b080c68fa1939081750707843928bf22b3f422a11e08b", "class_name": "RelatedNodeInfo"}, "2": {"node_id": "c55c0697-5756-459f-99da-83f17cf672a4", "node_type": "1", "metadata": {"page_label": "40", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}, "hash": "82d40982c5cb65eb082fa0abb5cebd0dcd758dcdf6788e4953bba1eaa5733a5f", "class_name": "RelatedNodeInfo"}}, "metadata_template": "{key}: {value}", "metadata_separator": "\n", "text": "[204] A. Shafahi, M. Najibi, A. Ghiasi, Z. Xu, J. P. Dickerson, C. Studer,\nL. S. Davis, G. Taylor, and T. Goldstein, \u201cAdversarial training\nfor free!\u201d CoRR, vol. abs/1904.12843, 2019. [Online]. Available:\nhttp://arxiv.org/abs/1904.12843\n[205] T. Bai, J. Luo, J. Zhao, B. Wen, and Q. Wang, \u201cRecent advances\nin adversarial training for adversarial robustness,\u201d CoRR, vol.\nabs/2102.01356, 2021. [Online]. Available: https://arxiv.org/abs/2102.\n01356\n[206] M. Verma, \u201cIntegration of ai-based chatbot(chatgpt) and supply chain\nmanagement solution to enhance tracking and queries response,\u201d 02\n2023.\n[207] Y . Kubo and T. Trappenberg, Mitigating Over\ufb01tting Using Regulariza-\ntion to Defend Networks Against Adversarial Examples , 04 2019, pp.\n400\u2013405.\n[208] X. Liu, Y . Zheng, Z. Du, M. Ding, Y . Qian, Z. Yang, and J. Tang, \u201cGpt\nunderstands, too,\u201d arXiv preprint arXiv:2103.10385 , 2021.\n[209] J. Jia, H. Liu, and N. Z. Gong, \u201c10 security and privacy problems in\nself-supervised learning,\u201d arXiv preprint arXiv:2110.15444 , 2021.\n[210] M. Abadi, A. Chu, I. Goodfellow, H. B. McMahan, I. Mironov,\nK. Talwar, and L. Zhang, \u201cDeep learning with differential privacy,\u201d\nin Proceedings of the 2016 ACM SIGSAC conference on computer and\ncommunications security, 2016, pp. 308\u2013318.", "mimetype": "text/plain", "start_char_idx": 4480, "end_char_idx": 5746, "metadata_seperator": "\n", "text_template": "{metadata_str}\n\n{content}", "class_name": "TextNode"}, "__type__": "1"}}, "docstore/ref_doc_info": {"c20b184d-c51b-45a8-b944-6f76ec4da2c4": {"node_ids": ["45a274e6-b714-499c-a9af-30f043edaa0c", "58517bf7-738a-46d9-a7cc-00465ade224a"], "metadata": {"page_label": "1", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}}, "5929e1d3-b915-43c9-a58e-b66c7ea53bac": {"node_ids": ["d46101c2-147d-438d-b516-5ea1af1ccb4c", "b415a11b-46ec-48f2-ad7f-50fdd92194e3"], "metadata": {"page_label": "2", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}}, "c10a68e2-bc15-4867-b386-97876057fb71": {"node_ids": ["bf9727bd-6606-4172-b370-de2a92f3900e", "e6a59dff-414a-430b-8037-eb9fd2219dd7"], "metadata": {"page_label": "3", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}}, "4fc80f34-49c4-44e2-a5fd-727769911b22": {"node_ids": ["3b72150e-4e50-4ff4-b40d-e9e9cb78202e"], "metadata": {"page_label": "4", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}}, "fe64afdc-7e3d-43d8-a28a-81b97b1a7e86": {"node_ids": ["020129aa-5932-4877-950b-4bb9cda6d1e7", "7464d452-7b13-4f4c-8aad-3b2b50d013fd"], "metadata": {"page_label": "5", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}}, "e95e46ac-8b4e-4142-960f-071b417c25a6": {"node_ids": ["58cf4218-a39d-41f2-b9f1-871cb5aaf0b3"], "metadata": {"page_label": "6", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}}, "07ac71b4-c757-4ee8-8124-a1b240204ab3": {"node_ids": ["d1e24863-0ebc-4e86-b9bb-b1685dc1ef96", "5422f5e2-c0e8-42ea-a1ba-6b0d12d47895"], "metadata": {"page_label": "7", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}}, "f65f9461-731e-4942-9cec-9171159ebc40": {"node_ids": ["c7837b45-8ace-437a-bdfc-def98f479236", "252343ae-4dfc-461f-8a84-aed39aa67153"], "metadata": {"page_label": "8", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}}, "ccfbbb65-8c20-45bc-9a2c-bb8f38abcff0": {"node_ids": ["2f08b76d-df37-4d22-8715-d6e27ecd2390"], "metadata": {"page_label": "9", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}}, "9ace5584-5ddc-4b8b-816b-3894866bea0a": {"node_ids": ["ab3e382c-ffd7-43fe-acf3-18e801ec4b74"], "metadata": {"page_label": "10", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}}, "f02d1f0a-580c-41db-860e-c054105d3f75": {"node_ids": ["397b1bc5-ce1c-4267-ab80-2da2a7e5e8fb"], "metadata": {"page_label": "11", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}}, "ac38aec3-0a63-4149-9cd9-65ea511cddd9": {"node_ids": ["f2d9276d-c9b9-4337-a30a-309320501f8f", "874d0fb0-3e00-4bdb-a433-fa73656c6b55"], "metadata": {"page_label": "12", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}}, "6bb2dc81-714d-49af-942e-afe3611e8e91": {"node_ids": ["74072635-7a7b-4b0b-b46d-49dd2bedca98", "d636174b-d028-4789-a77f-5fb695a0a775"], "metadata": {"page_label": "13", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}}, "54332bd4-83e3-434b-9b1b-fa1cacc15342": {"node_ids": ["95763818-3c38-45cc-b334-b32db4dabd66"], "metadata": {"page_label": "14", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}}, "5a51ab6b-9793-46b3-a18f-c0b471eee741": {"node_ids": ["111a9ca7-6a44-4f9b-b8fa-2f4d3b4fae1a", "9f47f532-5a97-4881-bb7e-f9d99fa93652"], "metadata": {"page_label": "15", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}}, "4c6bccd2-4e2d-40a1-ad0a-0527c721d7cf": {"node_ids": ["d324e843-8b82-4c70-acf0-a949b51bf423", "810801b7-fbee-4cd6-943e-ee6036264a25"], "metadata": {"page_label": "16", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}}, "2ebcfe31-8007-414d-b2c2-d46f1534c625": {"node_ids": ["c89036c3-e386-45df-a657-c7b4bb8c5e49", "df849252-73c8-4ce6-9233-c8333629921a"], "metadata": {"page_label": "17", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}}, "fb85337e-8c32-42bd-93e9-101ce548c238": {"node_ids": ["8f892045-1b9b-4bee-8248-3f5d85b5e2fd", "f7fbcbed-6040-44b3-8580-853f9770e635"], "metadata": {"page_label": "18", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}}, "558c49cd-b1b2-49d3-aa0e-82328822695e": {"node_ids": ["89df1068-6713-4e14-ac11-1595fb9747c4", "6805d554-1155-4b86-9c58-80aad740ed16"], "metadata": {"page_label": "19", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}}, "8f978440-ce79-4065-8cbc-754adab97c80": {"node_ids": ["8218b2f8-fba7-4866-9d2b-6789bee1e280", "b80fb0e0-baf4-4998-9ca9-2f96b389e04b"], "metadata": {"page_label": "20", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}}, "4d47f922-9432-41e0-879b-8a5198abebf4": {"node_ids": ["3407d69d-6868-4d61-8bb5-673e0ba63574", "0b8beeea-f3a0-4132-ba18-a280cfb754b5"], "metadata": {"page_label": "21", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}}, "cb471448-20a9-4f2b-8a36-667ddeb76802": {"node_ids": ["994fe664-6027-4bb5-81cf-127e336961c3", "318c557d-9675-42c7-af4a-1798c83ff92e"], "metadata": {"page_label": "22", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}}, "9244cbb3-441d-4c60-8238-e675e6b93caf": {"node_ids": ["bf4b4467-d8a2-4d21-ab41-a3453ef26365", "e1b7cb24-1324-4f64-b9a5-4b0ca5d21de8"], "metadata": {"page_label": "23", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}}, "3fbdc7e5-f123-4784-ab82-ae59036d8c90": {"node_ids": ["54640df1-57bf-4260-8e0b-12ff6ec0d004", "7dd1b51a-f789-4ba6-b1e3-38ec61440340"], "metadata": {"page_label": "24", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}}, "ff7fad39-f51a-42e5-8dd1-9d33dd480f7c": {"node_ids": ["dc33c5a8-604b-4c82-aa1e-501133d8f731", "cb5beda1-04c6-4cce-9f62-f982392484d2"], "metadata": {"page_label": "25", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}}, "41ea2a3a-10f7-4149-8948-f7581630abca": {"node_ids": ["7c85281f-d99f-46be-a194-fb58f0c2aff4", "c6c982d6-81c0-4653-a08e-e8e1228304e9"], "metadata": {"page_label": "26", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}}, "bb11665f-d289-4b56-92f4-77200f9f89ae": {"node_ids": ["f39b1126-2e93-4907-9942-6402d0a4d732", "c123dbfb-5155-4f58-896e-8e5721200106"], "metadata": {"page_label": "27", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}}, "66a78f15-0021-4881-ab03-8e4c9d70d200": {"node_ids": ["c28529fe-bbb5-4a01-8b2a-c11421a06f61", "80102867-5bec-4979-ae0d-55a907b37678"], "metadata": {"page_label": "28", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}}, "28f3e5fb-c32d-413e-9322-adfda3096bb3": {"node_ids": ["03921183-e74d-4d0a-b1d4-d388002f2aae", "5955a91e-6770-4978-ae18-a028819e10da", "286c4e19-b865-4046-980e-a13f80f01ec2"], "metadata": {"page_label": "29", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}}, "8e4ca1a7-db75-4585-89f7-0295395c8e7f": {"node_ids": ["d9ebe5f7-662b-47ad-87c4-6ea760a61589", "27335c1e-b2a3-4d70-9ba5-b1dd2cb21587"], "metadata": {"page_label": "30", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}}, "dcebafd3-a3fb-47c5-9c9b-67bba01fedc6": {"node_ids": ["16b69865-7146-4a44-925c-6e91e2989467", "85217703-6e9b-4ced-9736-6eace695355e"], "metadata": {"page_label": "31", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}}, "b088c9a1-a53b-4a7c-927a-46cbc370b601": {"node_ids": ["f4f0daa8-e0a9-44d5-9a98-685b37000aa0"], "metadata": {"page_label": "32", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}}, "4fe11246-aab3-4198-8a83-1a3b0e0777b1": {"node_ids": ["05cbc9bb-6c11-4516-87b5-a47b6c8937bc", "71aeb199-b664-4109-93a8-6e59f1df0335"], "metadata": {"page_label": "33", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}}, "9e24914d-12d0-4943-a47a-c97e676704b3": {"node_ids": ["10bbf59e-a196-4c26-9287-5f12dcad117a", "3d61b5b3-6f11-4d07-95ae-7b16e4f5e368"], "metadata": {"page_label": "34", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}}, "9ed06512-9e4a-425f-bdc8-5bafe6461249": {"node_ids": ["25789815-c800-4732-8d44-651c163df013", "9e40395b-071c-406a-a28f-873e96ff308b", "87af16b4-c6a5-4a01-bb93-8586338f8e44"], "metadata": {"page_label": "35", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}}, "b73d52db-4305-4802-aa2e-bf1f584e2f9b": {"node_ids": ["1baa69df-a064-4a2d-bf65-d8775c5cdeb0", "65b6cc08-ca0b-435c-937c-a9fbea629c2f", "858c80ad-7893-479d-b229-d1c20ddf2657"], "metadata": {"page_label": "36", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}}, "d46a39e9-2645-4958-9f89-40a9e13426b6": {"node_ids": ["e751d589-4b59-4388-8e3f-fc142876d3f5", "13be8a57-dcee-46c2-91d0-596e0dca8a2c", "de400218-79f5-465d-93a1-f5e7aed0f955", "97936bd6-9f93-4873-9b00-e2ee608dd859"], "metadata": {"page_label": "37", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}}, "b803ec6c-2f3a-4872-b187-598e950ef79e": {"node_ids": ["5f8f0398-320d-4921-8ce5-285ec3c472ce", "c1ad9021-2965-46a2-be50-ac38b16ab146", "b1ab3b83-5095-4ac5-b092-ce2aba1a8b54", "a09830d7-eef3-4ba8-b66d-228765342ed0"], "metadata": {"page_label": "38", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}}, "9b2ed34c-c574-4e52-b340-35075978d238": {"node_ids": ["c9269c6e-122f-4e12-9068-81c32dc57e1f", "06055c5d-a657-4a6c-b66a-7a8e433a6728", "599d5077-4e0e-4564-af46-71831e865bfb", "013efaeb-0953-47f4-b292-e4ab0ab9ec86"], "metadata": {"page_label": "39", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}}, "6ae76f48-416b-4355-b014-9da1999e6092": {"node_ids": ["c89a50d6-2ce7-4171-a280-a52601857a1b", "c55c0697-5756-459f-99da-83f17cf672a4", "6d7ec912-b086-4d2b-afd6-2943346e20f6"], "metadata": {"page_label": "40", "file_name": "GPT-paper.pdf", "file_path": "c:\\Users\\User\\Desktop\\LlamaIndex\\tutorials\\Indexing_embedding\\..\\..\\data\\GPT-paper.pdf", "file_type": "application/pdf", "file_size": 3250309, "creation_date": "2025-02-12", "last_modified_date": "2025-01-21"}}}}
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LlamaIndex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the first tutorial on LlamaIndex to aks questions from documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM is explicitly disabled. Using MockLLM.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ignoring wrong pointing object 8 0 (offset 0)\n",
      "Ignoring wrong pointing object 10 0 (offset 0)\n",
      "Ignoring wrong pointing object 12 0 (offset 0)\n",
      "Ignoring wrong pointing object 14 0 (offset 0)\n",
      "Ignoring wrong pointing object 16 0 (offset 0)\n",
      "Ignoring wrong pointing object 19 0 (offset 0)\n",
      "Ignoring wrong pointing object 25 0 (offset 0)\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, Settings\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "\n",
    "# Disable LLM \n",
    "Settings.llm = None\n",
    "\n",
    "# embedding model\n",
    "embed_model = HuggingFaceEmbedding(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# Set as default embedding model\n",
    "Settings.embed_model = embed_model\n",
    "\n",
    "# Load documents\n",
    "documents = SimpleDirectoryReader(\"data\").load_data()\n",
    "\n",
    "# index with local embeddings\n",
    "index = VectorStoreIndex.from_documents(documents)\n",
    "\n",
    "# query engine\n",
    "query_engine = index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context information is below.\n",
      "---------------------\n",
      "page_label: 1\n",
      "file_path: /Users/koyiljonvaliev/Desktop/LlamaIndex/introduction/data/Koyiljon_Portfolio.pdf\n",
      "\n",
      "PORTFOLIO\n",
      "1. Multimodal Effective Video Search and Interaction with RAG\n",
      "As part of the Multimodal RAG: Chat with Videos course by DeepLearning.AI in collaboration with \n",
      "Intel, I developed a Multimodal Retrieval-Augmented Generation (RAG) system designed to enable \n",
      "intelligent querying and interaction with video content. This system leverages multimodal AI \n",
      "techniques including video frame extraction, transcription, multimodal embedding, and retrieval.  \n",
      "Technical Strategy:\n",
      "• Video Preprocessing: Developed video preprocessing scripts to handle three different video \n",
      "input types (video with transcript, video with audio but no transcript, and video with no audio \n",
      "or transcript). This included extracting video frames and generating transcriptions using \n",
      "OpenAI's Whisper and LLaV A models.\n",
      "• Vector Store Ingestion: Implemented ingestion into LanceDB vector database using \n",
      "BridgeTower embeddings. Experimented with augmenting fragmented transcripts to improve \n",
      "the quality of the data used for retrieval.\n",
      "• RAG System Implementation: Used LangChain to create a multimodal retrieval-augmented \n",
      "generation (RAG) system, enabling video-based querying and interaction. Implemented both \n",
      "text-based and web interface querying systems using Python and Gradio.\n",
      "Project Deliverables:\n",
      "• Video Frame Extraction: Developed a system that extracts frames from videos and associates \n",
      "them with metadata such as transcript and video segment information.\n",
      "• Multimodal Data Ingestion: Processed and ingested video and transcript data into a vector \n",
      "store to make it searchable.\n",
      "• RAG System: Enabled users to ask multimodal queries about video content using a \n",
      "combination of video frames, transcripts, and embeddings.\n",
      "Tools Used:\n",
      "• LangChain: To run multimodal RAG system\n",
      "• OpenAI Whisper: For transcription\n",
      "• MoviePy: For audio extraction from videos\n",
      "• LLaV A Model: For generating captions from video frames\n",
      "• LanceDB: For vector storage\n",
      "API Keys Used:\n",
      "• OpenAI API: For natural language processing\n",
      "• Prediction Guard API: For model predictions\n",
      "ML Algorithms:\n",
      "• BridgeTower Embeddings: For vectorizing transcripts\n",
      "• RAG System: For querying video data\n",
      "View Certiﬁcate of Completion  |  Project Link\n",
      "\n",
      "page_label: 1\n",
      "file_path: /Users/koyiljonvaliev/Desktop/LlamaIndex/introduction/data/Koyiljon_CV.pdf\n",
      "\n",
      "Summary \n",
      "Koyilbek Valiev  \n",
      "E-mail: valievkoyiljon112@gmail.com       Phone:   +(82)-010-2253-3010 \n",
      "Github: github.com/koyilbek     Website: koyiljon.github.io \n",
      "Hello! I’m Koyilbek from Uzbekistan, a passionate AI engineer dedicated to building intelligent systems and \n",
      "leveraging cuNng-edge technologies to solve real-world problems. With over three years of experience in diverse, \n",
      "hands-on projects, I bring a proven ability to tackle challenges and drive impacRul soluSons. I am deeply commiTed \n",
      "to conSnuous learning and growth, currently expanding my exper Sse in mul Smodal AI, including Large Language \n",
      "Models (LLMs) and Large Vision Models (LVMs). I thrive on crea Sng innovaSve soluSons that contribute to societal \n",
      "progress.   \n",
      "Experiences \n",
      "AI Research Intern                                                                                                       Recs Innova+on Ltd, Naju, South Korea                      \n",
      "July 2024 – Present \n",
      "Op;mal Bidding Predic;on: \n",
      "• Engineered an ML-based bidding opSmizaSon system for energy projects integraSng supervised learning and \n",
      "Sme series analysis: \n",
      " - Built comprehensive data pipeline with automated cleaning, anomaly detecSon, and feature engineering. \n",
      " - Achieved 0.0017 % predicSon error rate through Hybrid ML algorithms based on data distribuSon. \n",
      "• Increased bid winning probability by 15x . \n",
      "Solar Power Genera;on Predic;on Project:\n",
      "• Developed an end-to-end solar power forecasSng system achieving 6-8% forecast error rate through hyper \n",
      "parameter tuning and weather forecast data integraSon. \n",
      "• Designed and implemented a comprehensive predicSon framework uSlizing: \n",
      "- Advanced neural networks: Custom LSTM-CNN hybrid architecture, GRU with aTenSon mechanisms, and \n",
      "transformer-based models. \n",
      "- Classical ML models: OpSmized implementaSons of Linear Regression, XGBoost, and Random Forest \n",
      "algorithms. \n",
      "- Reinforcement learning: Developed custom OpenAI Gym environments to implement reinforcement \n",
      "learning algorithms (PPO, A2C, DDPG) with PyTorch and Stable-Baselines3 for power predicSon.  \n",
      "• Successfully integrated the opSmized predicSon model into Sun-Q Energy Management System (EMS), enabling \n",
      "real-Sme power generaSon forecasSng capabiliSes. \n",
      "AI  Lead  Intern                                                                                                              Recs Innova+on Ltd, Naju, South Korea  \n",
      "March 2024 – July 2024 (5 months)\n",
      "• Led development of an advanced unsupervised anomaly detecSon system for photovoltaic sensors, \n",
      "successfully integrated into Sun-Q Energy Management System (EMS). \n",
      "• Implemented state-of-the-art deep learning architectures (LSTM Autoencoder, LSTM-VAE, TranAD) while \n",
      "overseeing team development of GNN and USAD models. \n",
      "• Built automated data pipeline processing 1.3M+ daily sensor readings, reducing preprocessing Sme from 3 \n",
      "hours to 15 minutes. \n",
      "• Established MLﬂow experimentaSon framework for systemaSc model evaluaSon and opSmizaSon, tracking \n",
      "key performance metrics (recall, precision, F1-score)  across mulSple architectures.\n",
      "---------------------\n",
      "Given the context information and not prior knowledge, answer the query.\n",
      "Query:  Please tell me about projects of Koyilbek related to LLM and RAG applications\n",
      "Answer: \n"
     ]
    }
   ],
   "source": [
    "#Query\n",
    "response = query_engine.query(\" Please tell me about projects of Koyilbek related to LLM and RAG applications\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LlamaIndex_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Querying "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you've loaded your data, built an index, and stored that index for later, you're ready to get to the most significant part of an LLM application: querying.\n",
    "\n",
    "At its simplest, querying is just a prompt call to an LLM: it can be a question and get an answer, or a request for summarization, or a much more complex instruction.\n",
    "\n",
    "More complex querying could involve repeated/chained prompt + LLM calls, or even a reasoning loop across multiple components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.12it/s]\n",
      "Parsing nodes: 100%|██████████| 40/40 [00:00<00:00, 506.33it/s]\n",
      "Generating embeddings: 100%|██████████| 83/83 [00:03<00:00, 25.46it/s]\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import VectorStoreIndex , SimpleDirectoryReader, Settings\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.llms.huggingface import HuggingFaceLLM\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# local embedding\n",
    "Settings.embed_model = HuggingFaceEmbedding(model_name = \"BAAI/bge-small-en-v1.5\")\n",
    "\n",
    "# First create the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"microsoft/phi-2\",\n",
    "    padding_side=\"right\",\n",
    "    pad_token=\"<|endoftext|>\"  # Define custom pad token\n",
    ")\n",
    "# Add pad token to tokenizer\n",
    "tokenizer.add_special_tokens({'pad_token': '<|endoftext|>'})\n",
    "\n",
    "# local LLM\n",
    "Settings.llm = HuggingFaceLLM(\n",
    "    model_name=\"microsoft/phi-2\",  # This is a smaller model that works well for most tasks\n",
    "    tokenizer_name=\"microsoft/phi-2\",\n",
    "    context_window=2048,\n",
    "    max_new_tokens=1024,\n",
    "    generate_kwargs={\"temperature\": 0.2, \"do_sample\": True, \"pad_token_id\": tokenizer.pad_token_id},\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "documents = SimpleDirectoryReader(\"../../data\").load_data()\n",
    "index = VectorStoreIndex.from_documents(documents, show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "This is a friendly reminder - the current text generation call will exceed the model's predefined maximum length (2048). Depending on the model, you may observe exceptions, performance degradation, or nothing at all.\n"
     ]
    }
   ],
   "source": [
    "query_engine = index.as_query_engine( \n",
    "                                    # similarity_top_k=1,\n",
    "                                    response_mode=\"tree_summarize\",)\n",
    "\n",
    "response = query_engine.query(\n",
    "    \"write me short essay based on the given document about GPT\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GPT (Generative Pre-trained Transformer) is a language model that has been developed by OpenAI. It is an artificial intelligence system that can generate human-like text based on the input it receives. GPT has been used in various applications, including chatbots, content creation, and research writing.\n",
      "\n",
      "GPT has several advantages in the healthcare sector. It can be used to generate personalized medical reports, which can help healthcare professionals make more informed decisions about patient care. GPT can also be used to generate medical research papers, which can help researchers share their findings more quickly and efficiently. Additionally, GPT can be used to generate patient education materials, which can help patients better understand their medical conditions and treatment options.\n",
      "\n",
      "However, there are also challenges to consider when using GPT in healthcare. One challenge is ensuring the accuracy and reliability of the information generated by GPT. Another challenge is ensuring the privacy and security of patient data. Finally, there is a need for human oversight to ensure that the information generated by GPT is appropriate and ethical.\n",
      "\n",
      "In conclusion, GPT has the potential to revolutionize the healthcare sector by improving the efﬁciency and quality of healthcare services. However, there are also challenges to consider when using GPT in healthcare, including ensuring the accuracy and reliability of the information generated by GPT and ensuring the privacy and security of patient data.\n",
      "\n",
      "Follow-up exercises:\n",
      "1) How can GPT be used to generate personalized medical reports?\n",
      "2) What are some potential ethical concerns associated with using GPT in healthcare?\n",
      "3) How can GPT be used to generate patient education materials?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

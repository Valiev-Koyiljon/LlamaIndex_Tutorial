{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding Model using LlamaIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\anaconda3\\envs\\llm\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM is explicitly disabled. Using MockLLM.\n"
     ]
    }
   ],
   "source": [
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.core import Settings, SimpleDirectoryReader, VectorStoreIndex\n",
    "\n",
    "Settings.embed_model = HuggingFaceEmbedding(\n",
    "    model_name=\"BAAI/bge-small-en-v1.5\"\n",
    ") \n",
    "Settings.llm = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = SimpleDirectoryReader(\"../../data\").load_data()\n",
    "\n",
    "index = VectorStoreIndex.from_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = index.as_query_engine()\n",
    "response = query_engine.query(\"Tell me about GPT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Response(response='Context information is below.\\n---------------------\\npage_label: 20\\nfile_path: c:\\\\Users\\\\User\\\\Desktop\\\\LlamaIndex\\\\tutorials\\\\embeddings\\\\..\\\\..\\\\data\\\\GPT-paper.pdf\\n\\nGPTs can offer real-time updates, effective route optimization,\\nand customized recommendations in the travel and transporta-\\ntion industries, enhancing the overall travel experience and\\nincreasing operational effectiveness. Adopting them, however,\\ncomes with some difﬁculties. As speciﬁc roles are replaced\\nby automation, GPTs may result in job displacement [127].\\nAdditionally, the computational and memory requirements\\nfor GPTs make their deployment on compact or low-power\\ndevices difﬁcult. GPTs may not be accessible to growing\\nbusinesses due to the high costs associated with obtaining and\\nusing them. Despite these obstacles, attempts are being done to\\novercome them and improve the usability and value of GPTs\\nfor a larger range of users.\\nF . E-Commerce\\n1) Introduction: Electronic commerce, commonly referred\\nto as e-commerce, is a way for conducting economic trans-\\nactions and create relationships between groups of people\\nand entities using digital information processes and electronic\\ncommunications [128]. Globally, this type of trade has experi-\\nenced substantial growth, particularly in the retail sector. The\\npreference for internet shopping, especially among younger\\nmillennials, is a prominent trend in consumer behaviour.\\nMobile devices have consequently taken over as the main\\nmethod for carrying out internet transactions [129]. Therefore,\\nit is crucial for e-commerce companies to give the customer\\nexperience in their mobile applications top priority. The pro-\\nvision of brief text summaries for titles and reviews is an\\nessential component of this. These summaries are essential\\nfor optimizing search results, helping consumers identify ap-\\npropriate items, and ultimately raising customer happiness in\\nthe online purchasing space [130].\\n2) Impact of GPT in E-Commerce Realms: The e-\\ncommerce sector could signiﬁcantly advance with the intro-\\nduction of GPTs. GPTs can be accessed by users or customers\\nand are intended to answer commonly asked questions and\\ngive in-depth details about many elements of the e-commerce\\nprocess, such as products, delivery, refunds, and more [107].\\nOne of the main beneﬁts of GPTs is their capacity for quick\\nresponses, which decreases the amount of time customers must\\nwait to hear back from businesses [131]. By taking care of an\\nimportant number of client inquiries, this function not only\\nincreases customer happiness but also lessens the workload\\non support workers. Customers will ultimately have a better\\npurchasing experience as a result of being able to quickly\\nacquire the information they require and interact with GPTs\\n[106].\\n• Proofreading: To improve the calibre and accuracy of\\nwritten content in e-commerce, GPTs can be used for\\nproofreading. Written content is essential for product\\n\\npage_label: 3\\nfile_path: c:\\\\Users\\\\User\\\\Desktop\\\\LlamaIndex\\\\tutorials\\\\embeddings\\\\..\\\\..\\\\data\\\\GPT-paper.pdf\\n\\nHence, this is the ﬁrst-of-its-kind survey that presents the\\nextensive information, by comparing existing surveys with our\\nsurvey and summarized in Table II.\\nC. Systematic Literature Survey\\nIn this review of GPT, we conducted a thorough literature\\nreview using various reputable sources. Our search was pri-\\nmarily focused on peer-reviewed journals, and high-quality\\narticles from reputed national and international conferences,\\nseminars, books, symposiums, and journals. To ensure the\\ncredibility of our sources, we referred to well-known archives\\nsuch as Google Scholar and arXiv, and publications from top\\ndatabases like IEEE, Springer, Elsevier, Taylor & Francis, and\\nWiley. To identify relevant GPT references and publications,\\nwe used keywords such as NLPGPT, GPT architecture, DL for\\nGPT, Pretraining GPT, Fine-tuning AI GPT and GPT vertical\\napplications. We then screened all the retrieved articles based\\non their titles, excluding any papers with poor-quality material.\\nNext, we reviewed the abstracts of the remaining articles to\\ndetermine their contributions. In the ﬁnal step of our literature\\nreview, we extracted the necessary data for our analysis. By\\nfollowing these phases, we ensured that our study was based\\non high-quality and credible sources.\\nD. Paper Organization\\nThe structure of this paper’s organization is illustrated in\\nFig. 1. Section 2 presents the preliminaries of GPT models\\nsuch as the deﬁnition of GPT, its evolution and architecture,\\nhow it works and presents the comparison of various GPT\\nmodels. Section 3 discusses the key enabling technologies for\\nGPT models. The impact of GPT models in various applica-\\ntions are presented in Section 4. In Section 5, we highlighted\\nsome of the exciting GPT projects that are currently developed.\\nSection 6 includes open issues, other technical challenges\\nand future research directions in the ﬁeld of GPT. Finally,\\nwe conclude the paper in Section 7, by summarizing the\\nkey ﬁndings and contributions of this study. The list of key\\nacronyms are listed in Table I.\\nII. P RELIMINARIES\\nIn this section, the evolution of GPT models, the architecture\\nof GPT, working process of GPT models are discussed and\\nﬁnally, different versions of GPT models are compared.\\nA. Generative Pre-trained Transformer\\nThe GPT model produces enormous quantities of pertinent\\nand complicated machine-generated text from a small amount\\nof text as input. GPT models can be identiﬁed as a language\\nmodel that mimics human text using a DL techniques and it\\nacts as an autoregressive model in which the present value is\\nbased on the previous value [15].\\n---------------------\\nGiven the context information and not prior knowledge, answer the query.\\nQuery: Tell me about GPT\\nAnswer: ', source_nodes=[NodeWithScore(node=TextNode(id_='ff452f4a-e1c6-4685-a23a-7ebaae52cfc3', embedding=None, metadata={'page_label': '20', 'file_name': 'GPT-paper.pdf', 'file_path': 'c:\\\\Users\\\\User\\\\Desktop\\\\LlamaIndex\\\\tutorials\\\\embeddings\\\\..\\\\..\\\\data\\\\GPT-paper.pdf', 'file_type': 'application/pdf', 'file_size': 3250309, 'creation_date': '2025-02-12', 'last_modified_date': '2025-01-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='b0dad149-7791-4cb2-b00c-2323feff69b4', node_type='4', metadata={'page_label': '20', 'file_name': 'GPT-paper.pdf', 'file_path': 'c:\\\\Users\\\\User\\\\Desktop\\\\LlamaIndex\\\\tutorials\\\\embeddings\\\\..\\\\..\\\\data\\\\GPT-paper.pdf', 'file_type': 'application/pdf', 'file_size': 3250309, 'creation_date': '2025-02-12', 'last_modified_date': '2025-01-21'}, hash='c52df6ca5e7c1feb28a206169e51460f8f4c5da0b68b27e990262281fbe19a44'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='ba8a6931-e226-4c30-87e8-6e68f01746c5', node_type='1', metadata={'page_label': '20', 'file_name': 'GPT-paper.pdf', 'file_path': 'c:\\\\Users\\\\User\\\\Desktop\\\\LlamaIndex\\\\tutorials\\\\embeddings\\\\..\\\\..\\\\data\\\\GPT-paper.pdf', 'file_type': 'application/pdf', 'file_size': 3250309, 'creation_date': '2025-02-12', 'last_modified_date': '2025-01-21'}, hash='79922aec192cf4bfc38ce5b17f80a7ad761294af05c47947be20775259893719')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='GPTs can offer real-time updates, effective route optimization,\\nand customized recommendations in the travel and transporta-\\ntion industries, enhancing the overall travel experience and\\nincreasing operational effectiveness. Adopting them, however,\\ncomes with some difﬁculties. As speciﬁc roles are replaced\\nby automation, GPTs may result in job displacement [127].\\nAdditionally, the computational and memory requirements\\nfor GPTs make their deployment on compact or low-power\\ndevices difﬁcult. GPTs may not be accessible to growing\\nbusinesses due to the high costs associated with obtaining and\\nusing them. Despite these obstacles, attempts are being done to\\novercome them and improve the usability and value of GPTs\\nfor a larger range of users.\\nF . E-Commerce\\n1) Introduction: Electronic commerce, commonly referred\\nto as e-commerce, is a way for conducting economic trans-\\nactions and create relationships between groups of people\\nand entities using digital information processes and electronic\\ncommunications [128]. Globally, this type of trade has experi-\\nenced substantial growth, particularly in the retail sector. The\\npreference for internet shopping, especially among younger\\nmillennials, is a prominent trend in consumer behaviour.\\nMobile devices have consequently taken over as the main\\nmethod for carrying out internet transactions [129]. Therefore,\\nit is crucial for e-commerce companies to give the customer\\nexperience in their mobile applications top priority. The pro-\\nvision of brief text summaries for titles and reviews is an\\nessential component of this. These summaries are essential\\nfor optimizing search results, helping consumers identify ap-\\npropriate items, and ultimately raising customer happiness in\\nthe online purchasing space [130].\\n2) Impact of GPT in E-Commerce Realms: The e-\\ncommerce sector could signiﬁcantly advance with the intro-\\nduction of GPTs. GPTs can be accessed by users or customers\\nand are intended to answer commonly asked questions and\\ngive in-depth details about many elements of the e-commerce\\nprocess, such as products, delivery, refunds, and more [107].\\nOne of the main beneﬁts of GPTs is their capacity for quick\\nresponses, which decreases the amount of time customers must\\nwait to hear back from businesses [131]. By taking care of an\\nimportant number of client inquiries, this function not only\\nincreases customer happiness but also lessens the workload\\non support workers. Customers will ultimately have a better\\npurchasing experience as a result of being able to quickly\\nacquire the information they require and interact with GPTs\\n[106].\\n• Proofreading: To improve the calibre and accuracy of\\nwritten content in e-commerce, GPTs can be used for\\nproofreading. Written content is essential for product', mimetype='text/plain', start_char_idx=3635, end_char_idx=6390, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.7368726780534646), NodeWithScore(node=TextNode(id_='82406c4e-7b92-4094-8a5d-6e2c00818a91', embedding=None, metadata={'page_label': '3', 'file_name': 'GPT-paper.pdf', 'file_path': 'c:\\\\Users\\\\User\\\\Desktop\\\\LlamaIndex\\\\tutorials\\\\embeddings\\\\..\\\\..\\\\data\\\\GPT-paper.pdf', 'file_type': 'application/pdf', 'file_size': 3250309, 'creation_date': '2025-02-12', 'last_modified_date': '2025-01-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='04f44b90-50df-484d-a246-8c6a8008f5ff', node_type='4', metadata={'page_label': '3', 'file_name': 'GPT-paper.pdf', 'file_path': 'c:\\\\Users\\\\User\\\\Desktop\\\\LlamaIndex\\\\tutorials\\\\embeddings\\\\..\\\\..\\\\data\\\\GPT-paper.pdf', 'file_type': 'application/pdf', 'file_size': 3250309, 'creation_date': '2025-02-12', 'last_modified_date': '2025-01-21'}, hash='1f0500c52c56f1b425ed4c8dbbd63a6fde917c22f508483c576fb589d891136e'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='efbe8aa6-d157-44e6-9439-ca05f198773a', node_type='1', metadata={'page_label': '3', 'file_name': 'GPT-paper.pdf', 'file_path': 'c:\\\\Users\\\\User\\\\Desktop\\\\LlamaIndex\\\\tutorials\\\\embeddings\\\\..\\\\..\\\\data\\\\GPT-paper.pdf', 'file_type': 'application/pdf', 'file_size': 3250309, 'creation_date': '2025-02-12', 'last_modified_date': '2025-01-21'}, hash='5c6989654249b4ac035687d1f28077a4b74ff0a4260f489a90afb9c01d7fc54c')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='Hence, this is the ﬁrst-of-its-kind survey that presents the\\nextensive information, by comparing existing surveys with our\\nsurvey and summarized in Table II.\\nC. Systematic Literature Survey\\nIn this review of GPT, we conducted a thorough literature\\nreview using various reputable sources. Our search was pri-\\nmarily focused on peer-reviewed journals, and high-quality\\narticles from reputed national and international conferences,\\nseminars, books, symposiums, and journals. To ensure the\\ncredibility of our sources, we referred to well-known archives\\nsuch as Google Scholar and arXiv, and publications from top\\ndatabases like IEEE, Springer, Elsevier, Taylor & Francis, and\\nWiley. To identify relevant GPT references and publications,\\nwe used keywords such as NLPGPT, GPT architecture, DL for\\nGPT, Pretraining GPT, Fine-tuning AI GPT and GPT vertical\\napplications. We then screened all the retrieved articles based\\non their titles, excluding any papers with poor-quality material.\\nNext, we reviewed the abstracts of the remaining articles to\\ndetermine their contributions. In the ﬁnal step of our literature\\nreview, we extracted the necessary data for our analysis. By\\nfollowing these phases, we ensured that our study was based\\non high-quality and credible sources.\\nD. Paper Organization\\nThe structure of this paper’s organization is illustrated in\\nFig. 1. Section 2 presents the preliminaries of GPT models\\nsuch as the deﬁnition of GPT, its evolution and architecture,\\nhow it works and presents the comparison of various GPT\\nmodels. Section 3 discusses the key enabling technologies for\\nGPT models. The impact of GPT models in various applica-\\ntions are presented in Section 4. In Section 5, we highlighted\\nsome of the exciting GPT projects that are currently developed.\\nSection 6 includes open issues, other technical challenges\\nand future research directions in the ﬁeld of GPT. Finally,\\nwe conclude the paper in Section 7, by summarizing the\\nkey ﬁndings and contributions of this study. The list of key\\nacronyms are listed in Table I.\\nII. P RELIMINARIES\\nIn this section, the evolution of GPT models, the architecture\\nof GPT, working process of GPT models are discussed and\\nﬁnally, different versions of GPT models are compared.\\nA. Generative Pre-trained Transformer\\nThe GPT model produces enormous quantities of pertinent\\nand complicated machine-generated text from a small amount\\nof text as input. GPT models can be identiﬁed as a language\\nmodel that mimics human text using a DL techniques and it\\nacts as an autoregressive model in which the present value is\\nbased on the previous value [15].', mimetype='text/plain', start_char_idx=3517, end_char_idx=6114, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.7356827408624644)], metadata={'ff452f4a-e1c6-4685-a23a-7ebaae52cfc3': {'page_label': '20', 'file_name': 'GPT-paper.pdf', 'file_path': 'c:\\\\Users\\\\User\\\\Desktop\\\\LlamaIndex\\\\tutorials\\\\embeddings\\\\..\\\\..\\\\data\\\\GPT-paper.pdf', 'file_type': 'application/pdf', 'file_size': 3250309, 'creation_date': '2025-02-12', 'last_modified_date': '2025-01-21'}, '82406c4e-7b92-4094-8a5d-6e2c00818a91': {'page_label': '3', 'file_name': 'GPT-paper.pdf', 'file_path': 'c:\\\\Users\\\\User\\\\Desktop\\\\LlamaIndex\\\\tutorials\\\\embeddings\\\\..\\\\..\\\\data\\\\GPT-paper.pdf', 'file_type': 'application/pdf', 'file_size': 3250309, 'creation_date': '2025-02-12', 'last_modified_date': '2025-01-21'}})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data (Ingestion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before your chosen LLM can act on your data, you first need to process the data and load it. This has parallels to data cleaning/feature engineering pipelines in the ML world, or ETL pipelines in the traditional data setting.\n",
    "\n",
    "This ingestion pipeline typically consists of three main stages:\n",
    "\n",
    "- Load the data\n",
    "- Transform the data\n",
    "- Index and store the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SimpleDirectoryReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "\n",
    "documents = SimpleDirectoryReader(\"../../data\").load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Readers from LlamaHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import download_loader\n",
    "from llama_index.readers.database import DatabaseReader\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "reader = DatabaseReader(\n",
    "    scheme = os.getenv(\"DB_SCHEME\"),\n",
    "    host=os.getenv(\"DB_HOST\"),\n",
    "    port=os.getenv(\"DB_PORT\"),\n",
    "    user=os.getenv(\"DB_USER\"),\n",
    "    password=os.getenv(\"DB_PASS\"),\n",
    "    dbname=os.getenv(\"DB_NAME\"),\n",
    "    \n",
    ")\n",
    "\n",
    "query = \"SELECT * FROM users\"\n",
    "documents = reader.load_data(query=query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating Documents directly\n",
    "Instead of using a loader, you can also use a Document directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Document\n",
    "\n",
    "doc = Document(text = \"This is the longer piece of text\", metadata = {\"source\":\"example.txt\", \"author\":\"Koyilbek\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(id_='b0d18c3e-dcfd-468b-966b-1f695c32d391', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Text', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data (Ingestion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before your chosen LLM can act on your data, you first need to process the data and load it. This has parallels to data cleaning/feature engineering pipelines in the ML world, or ETL pipelines in the traditional data setting.\n",
    "\n",
    "This ingestion pipeline typically consists of three main stages:\n",
    "\n",
    "- Load the data\n",
    "- Transform the data\n",
    "- Index and store the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SimpleDirectoryReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "\n",
    "documents = SimpleDirectoryReader(\"../../data\").load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Readers from LlamaHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import download_loader\n",
    "from llama_index.readers.database import DatabaseReader\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "reader = DatabaseReader(\n",
    "    scheme = os.getenv(\"DB_SCHEME\"),\n",
    "    host=os.getenv(\"DB_HOST\"),\n",
    "    port=os.getenv(\"DB_PORT\"),\n",
    "    user=os.getenv(\"DB_USER\"),\n",
    "    password=os.getenv(\"DB_PASS\"),\n",
    "    dbname=os.getenv(\"DB_NAME\"),\n",
    "    \n",
    ")\n",
    "\n",
    "query = \"SELECT * FROM users\"\n",
    "documents = reader.load_data(query=query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating Documents directly\n",
    "Instead of using a loader, you can also use a Document directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Document\n",
    "\n",
    "doc = Document(text = \"This is the longer piece of text\", metadata = {\"source\":\"example.txt\", \"author\":\"Koyilbek\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(id_='b0d18c3e-dcfd-468b-966b-1f695c32d391', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Text', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformations\n",
    "After the data is loaded, you then need to process and transform your data before putting it into a storage system. These transformations include chunking, extracting metadata, and embedding each chunk. This is necessary to make sure that the data can be retrieved, and used optimally by the LLM.\n",
    "\n",
    "Transformation input/outputs are Node objects (a Document is a subclass of a Node). Transformations can also be stacked and reordered.\n",
    "\n",
    "We have both a high-level and lower-level API for transforming documents.\n",
    "\n",
    "### High-Level Transformation API\n",
    "Indexes have a .from_documents() method which accepts an array of Document objects and will correctly parse and chunk them up. However, sometimes you will want greater control over how your documents are split up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.24s/it]\n",
      "c:\\Users\\User\\anaconda3\\envs\\llm\\lib\\site-packages\\llama_index\\core\\indices\\base.py:110: DeprecationWarning: Call to deprecated method get_doc_id. ('get_doc_id' is deprecated, access the 'id_' property instead.) -- Deprecated since version 0.12.2.\n",
      "  docstore.set_document_hash(doc.get_doc_id(), doc.hash)\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, Settings\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.llms.huggingface import HuggingFaceLLM\n",
    "import warnings\n",
    "warnings.resetwarnings()\n",
    "\n",
    "\n",
    "# local embedding\n",
    "Settings.embed_model = HuggingFaceEmbedding(model_name = \"BAAI/bge-small-en-v1.5\")\n",
    "\n",
    "# local LLM\n",
    "Settings.llm = HuggingFaceLLM(\n",
    "    model_name=\"microsoft/phi-2\",  # This is a smaller model that works well for most tasks\n",
    "    tokenizer_name=\"microsoft/phi-2\",\n",
    "    context_window=2048,\n",
    "    max_new_tokens=256,\n",
    "    generate_kwargs={\"temperature\": 0.7, \"do_sample\": True},\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "# laod and index your document\n",
    "documents = SimpleDirectoryReader(\"../../data\").load_data()\n",
    "vector_index = VectorStoreIndex.from_documents(documents)\n",
    "query_engine =  vector_index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "This is a friendly reminder - the current text generation call will exceed the model's predefined maximum length (2048). Depending on the model, you may observe exceptions, performance degradation, or nothing at all.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Response(response=\"------------\\nGiven the new context, refine the original answer to better answer the query. If the context isn't useful, return the original answer.\\nQuery: What are the main topics discussed in these documents\\nAnswer: ------------\\nGiven the new context, refine the original answer to better answer the query. If the context isn't useful, return the original answer.\\nQuery: What are the main topics discussed in these documents\\nAnswer: ------------\\nGiven the new context, refine the original answer to better answer the query. If the context isn't useful, return the original answer.\\nQuery: What are the main topics discussed in these documents\\nAnswer: ------------\\nGiven the new context, refine the original answer to better answer the query. If the context isn't useful, return the original answer.\\nQuery: What are the main topics discussed in these documents\\nAnswer: ------------\\nGiven the new context, refine the original answer to better answer the query. If the context isn't useful, return the original answer.\\nQuery: What are the main topics discussed in these documents\\nAnswer: ------------\\nGiven the new context, refine the original answer to better answer the query. If the context isn't useful, return the original answer.\\nQuery\", source_nodes=[NodeWithScore(node=TextNode(id_='64a633f6-863c-4c91-9b24-93d4d9c57ad5', embedding=None, metadata={'page_label': '39', 'file_name': 'GPT-paper.pdf', 'file_path': 'c:\\\\Users\\\\User\\\\Desktop\\\\LlamaIndex\\\\tutorials\\\\loading_data\\\\..\\\\..\\\\data\\\\GPT-paper.pdf', 'file_type': 'application/pdf', 'file_size': 3250309, 'creation_date': '2025-02-12', 'last_modified_date': '2025-01-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='697160f8-3e96-4ece-a7e2-8b0db4d3a820', node_type='4', metadata={'page_label': '39', 'file_name': 'GPT-paper.pdf', 'file_path': 'c:\\\\Users\\\\User\\\\Desktop\\\\LlamaIndex\\\\tutorials\\\\loading_data\\\\..\\\\..\\\\data\\\\GPT-paper.pdf', 'file_type': 'application/pdf', 'file_size': 3250309, 'creation_date': '2025-02-12', 'last_modified_date': '2025-01-21'}, hash='d1f96bda86e399156678171dd4866c2964b8d49dd06356ef0907d15c2d96948b'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='8f93862b-d113-4fd5-8246-0d84d45e1deb', node_type='1', metadata={'page_label': '39', 'file_name': 'GPT-paper.pdf', 'file_path': 'c:\\\\Users\\\\User\\\\Desktop\\\\LlamaIndex\\\\tutorials\\\\loading_data\\\\..\\\\..\\\\data\\\\GPT-paper.pdf', 'file_type': 'application/pdf', 'file_size': 3250309, 'creation_date': '2025-02-12', 'last_modified_date': '2025-01-21'}, hash='26c5fbb99f6e8c841c515d1dd79cad009dd0e716d24c0cc6647e9126e76b0886'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='d8bb8081-21ab-4cda-b9bf-393197de1b57', node_type='1', metadata={}, hash='409308dc5b194c9566eb0096990c45e5c364c6114d357b554b5f52e352b04c6b')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='165, no. 8, pp. 854–857, 2005.\\n[156] Y . H. Yeo, J. S. Samaan, W. H. Ng, P.-S. Ting, H. Trivedi, A. Vipani,\\nW. Ayoub, J. D. Yang, O. Liran, B. Spiegel et al. , “Assessing the\\nperformance of chatgpt in answering questions regarding cirrhosis and\\nhepatocellular carcinoma,” medRxiv, pp. 2023–02, 2023.\\n[157] S. S. Biswas, “Role of chat gpt in public health,” Annals of Biomedical\\nEngineering, pp. 1–2, 2023.\\n[158] M. Patkar, “5 Free Travel Planning AI and ChatGPT Apps to Get an\\nInstant Itinerary — makeuseof.com,” https://www.makeuseof.com/free-\\ntravel-planning-ai-chatgpt-apps/, [Accessed 24-Apr-2023].\\n[159] “Your ai-powered personal chef.” [Online]. Available: https://www.\\nchefgpt.xyz/\\n[160] lechjaLearnCrafts, “Learn Crafts & Hobbies w/ GPT Chat —\\nlechja.com,” https://www.lechja.com/ai/learn-crafts-hobbies-w-gpt-\\nchat, 2023, [Accessed 24-Apr-2023].\\n[161] “How to use chatgpt in your job search — indeed.com.” [On-\\nline]. Available: https://www.indeed.com/career-advice/news/chatgpt-\\njob-search\\n[162] L. Floridi and M. Chiriatti, “Gpt-3: Its nature, scope, limits, and\\nconsequences,” Minds and Machines , vol. 30, pp. 681–694, 2020.\\n[163] S. Toshniwal, S. Wiseman, K. Livescu, and K. Gimpel, “Learning chess\\nblindfolded,” 2021.\\n[164] J. Freiknecht and W. Effelsberg, “Procedural generation of interactive\\nstories using language models,” in Proceedings of the 15th Interna-\\ntional Conference on the Foundations of Digital Games , 2020, pp.\\n1–8.\\n[165] S. V ¨artinen, P. H ¨am¨al¨ainen, and C. Guckelsberger, “Generating role-\\nplaying game quests with gpt language models,” IEEE Transactions on\\nGames, pp. 1–12, 2022.\\n[166] J. van Stegeren and J. Myundeﬁnedliwiec, “Fine-tuning gpt-2 on\\nannotated rpg quests for npc dialogue generation,” in Proceedings\\nof the 16th International Conference on the Foundations of Digital\\nGames, ser. FDG ’21. New York, NY , USA: Association for\\nComputing Machinery, 2021. [Online]. Available: https://doi.org/10.\\n1145/3472538.3472595\\n[167] P. Roetzer and M. Kaput, Marketing Artiﬁcial Intelligence: AI, Mar-\\nketing, and the Future of Business . BenBella Books, 2022.\\n[168] J. Thiergart, S. Huber, and T. ¨Ubellacker, “Understanding emails\\nand drafting responses–an approach using gpt-3,” arXiv preprint\\narXiv:2102.03062, 2021.\\n[169] X. Bai, L. Duan, R. Tang, G. Batra, and R. Agrawal, “Improving text-\\nbased similar product recommendation for dynamic product advertising\\nat yahoo,” in Proceedings of the 31st ACM International Conference on\\nInformation & Knowledge Management , ser. CIKM ’22. New York,\\nNY , USA: Association for Computing Machinery, 2022, p. 2883–2892.\\n[Online]. Available: https://doi.org/10.1145/3511808.3557129\\n[170] P. S. Neves, “Chat gpt ais “interview” 1, december 2022,” AIS-\\nArchitecture Image Studies, vol. 3, no. 2, pp. 58–67, 2022.\\n[171] X.-R. Gong, J.-X.', mimetype='text/plain', start_char_idx=5044, end_char_idx=7861, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.628496433308969), NodeWithScore(node=TextNode(id_='9fea320a-6114-4182-a629-3c6c113ab23d', embedding=None, metadata={'page_label': '38', 'file_name': 'GPT-paper.pdf', 'file_path': 'c:\\\\Users\\\\User\\\\Desktop\\\\LlamaIndex\\\\tutorials\\\\loading_data\\\\..\\\\..\\\\data\\\\GPT-paper.pdf', 'file_type': 'application/pdf', 'file_size': 3250309, 'creation_date': '2025-02-12', 'last_modified_date': '2025-01-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='5cfe4436-8ade-4f8c-acb7-3148f16764ee', node_type='4', metadata={'page_label': '38', 'file_name': 'GPT-paper.pdf', 'file_path': 'c:\\\\Users\\\\User\\\\Desktop\\\\LlamaIndex\\\\tutorials\\\\loading_data\\\\..\\\\..\\\\data\\\\GPT-paper.pdf', 'file_type': 'application/pdf', 'file_size': 3250309, 'creation_date': '2025-02-12', 'last_modified_date': '2025-01-21'}, hash='f4d4e57f7ae9eaa3babdfbb42d4f1146dd4dea7c9401314bfb00d5f44a903ff5'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='b6ee86e3-beea-47a1-8fb7-2b76693ed980', node_type='1', metadata={'page_label': '38', 'file_name': 'GPT-paper.pdf', 'file_path': 'c:\\\\Users\\\\User\\\\Desktop\\\\LlamaIndex\\\\tutorials\\\\loading_data\\\\..\\\\..\\\\data\\\\GPT-paper.pdf', 'file_type': 'application/pdf', 'file_size': 3250309, 'creation_date': '2025-02-12', 'last_modified_date': '2025-01-21'}, hash='12c2005cf0268f5c1b502191a091abe38fc6a662d6d1dd04ff0357113f2f5f85')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='Raghavan, M. Ahuja et al. ,\\n““so what if chatgpt wrote it?” multidisciplinary perspectives on op-\\nportunities, challenges and implications of generative conversational ai\\nfor research, practice and policy,” International Journal of Information\\nManagement, vol. 71, p. 102642, 2023.\\n[118] S. Biswas, “Prospective role of chat gpt in the military: According to\\nchatgpt,” Qeios, 2023.\\n[119] P. Helo and A. Shamsuzzoha, “Real-time supply chain—a blockchain\\narchitecture for project deliveries,” Robotics and Computer-Integrated\\nManufacturing, vol. 63, p. 101909, 2020.\\n[120] R. Kadel, H. Shrestha, A. Shrestha, P. Sharma, N. Shrestha, J. Bashyal,\\nand S. Shrestha, “Emergence of ai in cyber security,” International\\nResearch Journal of Modernization in Engineering Technology and\\nScience, 2022.\\n[121] H. Benbya, S. Pachidi, and S. Jarvenpaa, “Special issue editorial:\\nArtiﬁcial intelligence in organizations: Implications for information\\nsystems research,” Journal of the Association for Information Systems ,\\nvol. 22, no. 2, p. 10, 2021.\\n[122] T. Zheng, M. Ardolino, A. Bacchetti, and M. Perona, “The applications\\nof industry 4.0 technologies in manufacturing context: a systematic lit-\\nerature review,”International Journal of Production Research, vol. 59,\\nno. 6, pp. 1922–1954, 2021.\\n[123] B. Rathore, “Digital transformation 4.0: Integration of artiﬁcial in-\\ntelligence & metaverse in marketing,” Eduzone: International Peer\\nReviewed/Refereed Multidisciplinary Journal, vol. 12, no. 1, pp. 42–48,\\n2023.\\n[124] J. Bulchand-Gidumal, “Impact of artiﬁcial intelligence in travel,\\ntourism, and hospitality,” in Handbook of e-Tourism. Springer, 2022,\\npp. 1943–1962.\\n[125] N. Gillani, R. Eynon, C. Chiabaut, and K. Finkel, “Unpacking the\\n“black box” of ai in education,” Educational Technology & Society ,\\nvol. 26, no. 1, pp. 99–111, 2023.\\n[126] N. Mehrabi, F. Morstatter, N. Saxena, K. Lerman, and A. Galstyan,\\n“A survey on bias and fairness in machine learning,” ACM Computing\\nSurveys (CSUR), vol. 54, no. 6, pp. 1–35, 2021.\\n[127] F. T. Tschang and E. Almirall, “Artiﬁcial intelligence as augmenting\\nautomation: Implications for employment,” Academy of Management\\nPerspectives, vol. 35, no. 4, pp. 642–659, 2021.\\n[128] V . Jain, B. Malviya, and S. Arya, “An overview of electronic commerce\\n(e-commerce),” Journal of Contemporary Issues in Business and Gov-\\nernment— Vol , vol. 27, no. 3, p. 666, 2021.\\n[129] B. Feijoo and A. Garc ´ıa Gonz´alez, “Online shopping routines among\\nchilean children: level of expansion and main causes,” 2020.', mimetype='text/plain', start_char_idx=6713, end_char_idx=9243, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.6241788738592242)], metadata={'64a633f6-863c-4c91-9b24-93d4d9c57ad5': {'page_label': '39', 'file_name': 'GPT-paper.pdf', 'file_path': 'c:\\\\Users\\\\User\\\\Desktop\\\\LlamaIndex\\\\tutorials\\\\loading_data\\\\..\\\\..\\\\data\\\\GPT-paper.pdf', 'file_type': 'application/pdf', 'file_size': 3250309, 'creation_date': '2025-02-12', 'last_modified_date': '2025-01-21'}, '9fea320a-6114-4182-a629-3c6c113ab23d': {'page_label': '38', 'file_name': 'GPT-paper.pdf', 'file_path': 'c:\\\\Users\\\\User\\\\Desktop\\\\LlamaIndex\\\\tutorials\\\\loading_data\\\\..\\\\..\\\\data\\\\GPT-paper.pdf', 'file_type': 'application/pdf', 'file_size': 3250309, 'creation_date': '2025-02-12', 'last_modified_date': '2025-01-21'}})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response1 = query_engine.query(\"What are the main topics discussed in these documents\")\n",
    "response1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Under the hood, this splits your Document into Node objects, which are similar to Documents (they contain text and metadata) but have a relationship to their parent Document.\n",
    "\n",
    "If you want to customize core components, like the text splitter, through this abstraction you can pass in a custom transformations list or apply to the global Settings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\anaconda3\\envs\\llm\\lib\\site-packages\\llama_index\\core\\indices\\base.py:110: DeprecationWarning: Call to deprecated method get_doc_id. ('get_doc_id' is deprecated, access the 'id_' property instead.) -- Deprecated since version 0.12.2.\n",
      "  docstore.set_document_hash(doc.get_doc_id(), doc.hash)\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.core import Settings, VectorStoreIndex, SimpleDirectoryReader\n",
    "\n",
    "# Create the text splitter\n",
    "text_splitter = SentenceSplitter(chunk_size=512, chunk_overlap=10)\n",
    "\n",
    "# Set it globally\n",
    "Settings.text_splitter = text_splitter\n",
    "\n",
    "# Load documents\n",
    "documents = SimpleDirectoryReader(\"../../data\").load_data()\n",
    "\n",
    "# Create index - note the correct syntax here\n",
    "index = VectorStoreIndex.from_documents(\n",
    "    documents,  # Just pass documents directly\n",
    "    transformations=[text_splitter]\n",
    ")\n",
    "\n",
    "# Now you can create a query engine and use it\n",
    "query_engine = index.as_query_engine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lower-Level Transformation API\n",
    "You can also define these steps explicitly.\n",
    "\n",
    "You can do this by either using our transformation modules (text splitters, metadata extractors, etc.) as standalone components, or compose them in our declarative Transformation Pipeline interface.\n",
    "\n",
    "Let's walk through the steps below.\n",
    "\n",
    "Splitting Your Documents into Nodes#\n",
    "A key step to process your documents is to split them into \"chunks\"/Node objects. The key idea is to process your data into bite-sized pieces that can be retrieved / fed to the LLM.\n",
    "\n",
    "LlamaIndex has support for a wide range of text splitters, ranging from paragraph/sentence/token based splitters to file-based splitters like HTML, JSON.\n",
    "\n",
    "These can be used on their own or as part of an ingestion pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "from llama_index.core.node_parser import TokenTextSplitter\n",
    "from llama_index.core.ingestion import IngestionPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading documents\n",
    "documents = SimpleDirectoryReader(\"../../data\").load_data()\n",
    "\n",
    "# pipeline with text splitter \n",
    "pipeline = IngestionPipeline(\n",
    "    transformations=[TokenTextSplitter(), ])\n",
    "\n",
    "# processing documents into nodes\n",
    "nodes =  pipeline.run(documents=documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "GPT (Generative Pre-trained Transformer) – A\n",
      "Com\n",
      "Generative Pre-trained Transformer\n",
      "GPU Graphics Pr\n",
      "2\n",
      "machines in a more natural way. The evolution of\n",
      "These\n",
      "GPT models have demonstrated great potential\n",
      "3\n",
      "they concluded the paper by highlighting the key\n",
      "material.\n",
      "Next, we reviewed the abstracts of the r\n",
      "4\n",
      "SECTION-1:INTRODUCTION\n",
      "MOTIVATION RELATED SURVEY\n",
      "5\n",
      "TABLE II\n",
      "COMPARISON OF THIS SURVEY WITH THE EXIS\n",
      "major\n",
      "success as a result of its pre-training. Thi\n",
      "6\n",
      "ELIZA-1960\n",
      "Pattern matching &\n",
      "replacement\n",
      "Helps \n",
      "7\n",
      "model [30]. The Transformer model uses self-atte\n",
      "that enables a model to discover\n",
      "the statistical c\n",
      "8\n",
      "TABLE III\n",
      "COMPARSION OF DIFFERENT VERSIONS OF GP\n",
      "GPT models capture the\n",
      "variations in language usag\n",
      "9\n",
      "Add & Norm\n",
      "Multi-Head\n",
      "Attention \n",
      "Softmax\n",
      "Linear \n",
      "10\n",
      "Layer Norm\n",
      "Feed\n",
      "Forward \n",
      "Text & Position\n",
      "Embedd\n",
      "11\n",
      "HUMAN\n",
      "INSTRUCTION GPT TEXT RESULTS\n",
      "Data\n",
      "Input O\n",
      "12\n",
      "and any breakdown in connectivity may result in\n",
      "devices, cloud servers, and end-users [69].\n",
      "Though\n",
      "13\n",
      "thereby improving its reliability and accuracy.\n",
      "also analyze student\n",
      "performance data and generate\n",
      "14\n",
      "Education\n",
      "Healthcare\n",
      "Agriculture\n",
      "Lifestyle\n",
      "Mark\n",
      "15\n",
      "ized learning materials and exercises based on \n",
      "medical devices, and phar-\n",
      "maceuticals have underg\n",
      "16\n",
      "known compounds [86]. GPT can be trained on lar\n",
      "is security and privacy issues.\n",
      "As it is a model t\n",
      "17\n",
      "may be examined to uncover insightful informati\n",
      "in a variety of sectors, including manufacturing\n",
      "a\n",
      "18\n",
      "because these continuing efforts raise the depl\n",
      "data to optimize timing\n",
      "and dosage of intervention\n",
      "19\n",
      "soil variations across ﬁelds, allowing for site\n",
      "receive\n",
      "precise updates on their shipments using t\n",
      "20\n",
      "possible by this real-time accessibility. This \n",
      "entities using digital information processes and e\n",
      "21\n",
      "descriptions, marketing materials, customer rev\n",
      "to increase customer happiness.\n",
      "Segmenting consume\n",
      "22\n",
      "preferences, issues, and opinions regarding the\n",
      "improved by providing dynamic\n",
      "and more realistic r\n",
      "23\n",
      "• Realistic Gaming Interactions: GPT helps to g\n",
      "indicators like job, wealth, and physical and ment\n",
      "24\n",
      "free hours, medications taken, and available ex\n",
      "individuals in real life.\n",
      "I. Gaming\n",
      "1) Introductio\n",
      "25\n",
      "dynamic and personalized gaming worlds, generat\n",
      "have learned from their training data, which means\n",
      "26\n",
      "companies to target speciﬁc populations with pr\n",
      "campaigns\n",
      "to each customer’s desires based on thei\n",
      "27\n",
      "potential challenges, such as limited control, \n",
      "a popular GPT for\n",
      "stock market trend prediction. T\n",
      "28\n",
      "management and investment decisions. It also re\n",
      "[179].\n",
      "C. Copy.ai\n",
      "Copy.ai [180] is a mighty AI sta\n",
      "29\n",
      "TABLE IV\n",
      "PROJECT SUMMARY TABLE .\n",
      "Project DeepSc\n",
      "from Mozilla having over 9,000hours of speech data\n",
      "30\n",
      "learning practitioners to develop, launch, and \n",
      "Transformers for Music Modeling” (MST)\n",
      "model, was \n",
      "31\n",
      "and customer service by recommending goods and \n",
      "their performance may not be equally\n",
      "effective whe\n",
      "32\n",
      "Fig. 9. Challenges and Future Directions.\n",
      "as th\n",
      "33\n",
      "B. High Computational requirements\n",
      "As the Trans\n",
      "to assure these codes by\n",
      "GPT are reliable, a metri\n",
      "34\n",
      "architecture, and using post-processing methods\n",
      "researchers need to\n",
      "train GPT models on extensive,\n",
      "35\n",
      "I. Ethical Concerns\n",
      "The ethical concerns in GPT\n",
      "while\n",
      "minimizing any negative impact that they may\n",
      "36\n",
      "TABLE VI\n",
      "VARIOUS LESSONS LEARNED AND FUTURE RES\n",
      ", 2023.\n",
      "[19] ”GPT-1, GPT-2 and GPT-3 models explai\n",
      "37\n",
      "[34] J. R. Stevens, R. Venkatesan, S. Dai, B. K\n",
      "Hadjielias, M. Christoﬁ, and D. Vrontis, “A system\n",
      "and J. Liu, Deep Learning on Edge Computing\n",
      "Device\n",
      "A. Alam, “Possibilities and challenges of compound\n",
      "38\n",
      "[83] N. Pillai, A. Dasgupta, S. Sudaskorn, J. F\n",
      "O. H. Or ˘asan, and D.-A. Todea, “Therapeutic efﬁc\n",
      "Tsamados, M. Taddeo, and L. Floridi, “The\n",
      "ai gambi\n",
      "1943–1962.\n",
      "[125] N. Gillani, R. Eynon, C. Chiabaut\n",
      "39\n",
      "[130] X. Zhang, Y . Jiang, Y . Shang, Z. Cheng,\n",
      "S. Shahriar and K. Hayawi, “Let’s have a chat! a c\n",
      "to use chatgpt in your job search — indeed.com.” [\n",
      "ChatGPT”. [Accessed on 25.03.2023]. [Online]. Avai\n",
      "40\n",
      "[178] ”AI Dungeon: A text-based adventure-story\n",
      "Granmo, and M. Goodwin, “An inter-\n",
      "pretable word s\n",
      "McMahan, I. Mironov,\n",
      "K. Talwar, and L. Zhang, “Dee\n"
     ]
    }
   ],
   "source": [
    "# If you want to see the text content of each node\n",
    "for node in nodes:\n",
    "    print(node.text[:50])  #taking only 50 characters from each node's text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

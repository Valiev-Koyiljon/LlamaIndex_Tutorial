{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data (Ingestion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before your chosen LLM can act on your data, you first need to process the data and load it. This has parallels to data cleaning/feature engineering pipelines in the ML world, or ETL pipelines in the traditional data setting.\n",
    "\n",
    "This ingestion pipeline typically consists of three main stages:\n",
    "\n",
    "- Load the data\n",
    "- Transform the data\n",
    "- Index and store the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SimpleDirectoryReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "\n",
    "documents = SimpleDirectoryReader(\"../../data\").load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Readers from LlamaHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import download_loader\n",
    "from llama_index.readers.database import DatabaseReader\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "reader = DatabaseReader(\n",
    "    scheme = os.getenv(\"DB_SCHEME\"),\n",
    "    host=os.getenv(\"DB_HOST\"),\n",
    "    port=os.getenv(\"DB_PORT\"),\n",
    "    user=os.getenv(\"DB_USER\"),\n",
    "    password=os.getenv(\"DB_PASS\"),\n",
    "    dbname=os.getenv(\"DB_NAME\"),\n",
    "    \n",
    ")\n",
    "\n",
    "query = \"SELECT * FROM users\"\n",
    "documents = reader.load_data(query=query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating Documents directly\n",
    "Instead of using a loader, you can also use a Document directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Document\n",
    "\n",
    "doc = Document(text = \"This is the longer piece of text\", metadata = {\"source\":\"example.txt\", \"author\":\"Koyilbek\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(id_='b0d18c3e-dcfd-468b-966b-1f695c32d391', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Text', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformations\n",
    "After the data is loaded, you then need to process and transform your data before putting it into a storage system. These transformations include chunking, extracting metadata, and embedding each chunk. This is necessary to make sure that the data can be retrieved, and used optimally by the LLM.\n",
    "\n",
    "Transformation input/outputs are Node objects (a Document is a subclass of a Node). Transformations can also be stacked and reordered.\n",
    "\n",
    "We have both a high-level and lower-level API for transforming documents.\n",
    "\n",
    "### High-Level Transformation API\n",
    "Indexes have a .from_documents() method which accepts an array of Document objects and will correctly parse and chunk them up. However, sometimes you will want greater control over how your documents are split up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.24s/it]\n",
      "c:\\Users\\User\\anaconda3\\envs\\llm\\lib\\site-packages\\llama_index\\core\\indices\\base.py:110: DeprecationWarning: Call to deprecated method get_doc_id. ('get_doc_id' is deprecated, access the 'id_' property instead.) -- Deprecated since version 0.12.2.\n",
      "  docstore.set_document_hash(doc.get_doc_id(), doc.hash)\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, Settings\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.llms.huggingface import HuggingFaceLLM\n",
    "import warnings\n",
    "warnings.resetwarnings()\n",
    "\n",
    "\n",
    "# local embedding\n",
    "Settings.embed_model = HuggingFaceEmbedding(model_name = \"BAAI/bge-small-en-v1.5\")\n",
    "\n",
    "# local LLM\n",
    "Settings.llm = HuggingFaceLLM(\n",
    "    model_name=\"microsoft/phi-2\",  # This is a smaller model that works well for most tasks\n",
    "    tokenizer_name=\"microsoft/phi-2\",\n",
    "    context_window=2048,\n",
    "    max_new_tokens=256,\n",
    "    generate_kwargs={\"temperature\": 0.7, \"do_sample\": True},\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "# laod and index your document\n",
    "documents = SimpleDirectoryReader(\"../../data\").load_data()\n",
    "vector_index = VectorStoreIndex.from_documents(documents)\n",
    "query_engine =  vector_index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "This is a friendly reminder - the current text generation call will exceed the model's predefined maximum length (2048). Depending on the model, you may observe exceptions, performance degradation, or nothing at all.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Response(response=\"------------\\nGiven the new context, refine the original answer to better answer the query. If the context isn't useful, return the original answer.\\nQuery: What are the main topics discussed in these documents\\nAnswer: ------------\\nGiven the new context, refine the original answer to better answer the query. If the context isn't useful, return the original answer.\\nQuery: What are the main topics discussed in these documents\\nAnswer: ------------\\nGiven the new context, refine the original answer to better answer the query. If the context isn't useful, return the original answer.\\nQuery: What are the main topics discussed in these documents\\nAnswer: ------------\\nGiven the new context, refine the original answer to better answer the query. If the context isn't useful, return the original answer.\\nQuery: What are the main topics discussed in these documents\\nAnswer: ------------\\nGiven the new context, refine the original answer to better answer the query. If the context isn't useful, return the original answer.\\nQuery: What are the main topics discussed in these documents\\nAnswer: ------------\\nGiven the new context, refine the original answer to better answer the query. If the context isn't useful, return the original answer.\\nQuery\", source_nodes=[NodeWithScore(node=TextNode(id_='64a633f6-863c-4c91-9b24-93d4d9c57ad5', embedding=None, metadata={'page_label': '39', 'file_name': 'GPT-paper.pdf', 'file_path': 'c:\\\\Users\\\\User\\\\Desktop\\\\LlamaIndex\\\\tutorials\\\\loading_data\\\\..\\\\..\\\\data\\\\GPT-paper.pdf', 'file_type': 'application/pdf', 'file_size': 3250309, 'creation_date': '2025-02-12', 'last_modified_date': '2025-01-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='697160f8-3e96-4ece-a7e2-8b0db4d3a820', node_type='4', metadata={'page_label': '39', 'file_name': 'GPT-paper.pdf', 'file_path': 'c:\\\\Users\\\\User\\\\Desktop\\\\LlamaIndex\\\\tutorials\\\\loading_data\\\\..\\\\..\\\\data\\\\GPT-paper.pdf', 'file_type': 'application/pdf', 'file_size': 3250309, 'creation_date': '2025-02-12', 'last_modified_date': '2025-01-21'}, hash='d1f96bda86e399156678171dd4866c2964b8d49dd06356ef0907d15c2d96948b'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='8f93862b-d113-4fd5-8246-0d84d45e1deb', node_type='1', metadata={'page_label': '39', 'file_name': 'GPT-paper.pdf', 'file_path': 'c:\\\\Users\\\\User\\\\Desktop\\\\LlamaIndex\\\\tutorials\\\\loading_data\\\\..\\\\..\\\\data\\\\GPT-paper.pdf', 'file_type': 'application/pdf', 'file_size': 3250309, 'creation_date': '2025-02-12', 'last_modified_date': '2025-01-21'}, hash='26c5fbb99f6e8c841c515d1dd79cad009dd0e716d24c0cc6647e9126e76b0886'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='d8bb8081-21ab-4cda-b9bf-393197de1b57', node_type='1', metadata={}, hash='409308dc5b194c9566eb0096990c45e5c364c6114d357b554b5f52e352b04c6b')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='165, no. 8, pp. 854–857, 2005.\\n[156] Y . H. Yeo, J. S. Samaan, W. H. Ng, P.-S. Ting, H. Trivedi, A. Vipani,\\nW. Ayoub, J. D. Yang, O. Liran, B. Spiegel et al. , “Assessing the\\nperformance of chatgpt in answering questions regarding cirrhosis and\\nhepatocellular carcinoma,” medRxiv, pp. 2023–02, 2023.\\n[157] S. S. Biswas, “Role of chat gpt in public health,” Annals of Biomedical\\nEngineering, pp. 1–2, 2023.\\n[158] M. Patkar, “5 Free Travel Planning AI and ChatGPT Apps to Get an\\nInstant Itinerary — makeuseof.com,” https://www.makeuseof.com/free-\\ntravel-planning-ai-chatgpt-apps/, [Accessed 24-Apr-2023].\\n[159] “Your ai-powered personal chef.” [Online]. Available: https://www.\\nchefgpt.xyz/\\n[160] lechjaLearnCrafts, “Learn Crafts & Hobbies w/ GPT Chat —\\nlechja.com,” https://www.lechja.com/ai/learn-crafts-hobbies-w-gpt-\\nchat, 2023, [Accessed 24-Apr-2023].\\n[161] “How to use chatgpt in your job search — indeed.com.” [On-\\nline]. Available: https://www.indeed.com/career-advice/news/chatgpt-\\njob-search\\n[162] L. Floridi and M. Chiriatti, “Gpt-3: Its nature, scope, limits, and\\nconsequences,” Minds and Machines , vol. 30, pp. 681–694, 2020.\\n[163] S. Toshniwal, S. Wiseman, K. Livescu, and K. Gimpel, “Learning chess\\nblindfolded,” 2021.\\n[164] J. Freiknecht and W. Effelsberg, “Procedural generation of interactive\\nstories using language models,” in Proceedings of the 15th Interna-\\ntional Conference on the Foundations of Digital Games , 2020, pp.\\n1–8.\\n[165] S. V ¨artinen, P. H ¨am¨al¨ainen, and C. Guckelsberger, “Generating role-\\nplaying game quests with gpt language models,” IEEE Transactions on\\nGames, pp. 1–12, 2022.\\n[166] J. van Stegeren and J. Myundeﬁnedliwiec, “Fine-tuning gpt-2 on\\nannotated rpg quests for npc dialogue generation,” in Proceedings\\nof the 16th International Conference on the Foundations of Digital\\nGames, ser. FDG ’21. New York, NY , USA: Association for\\nComputing Machinery, 2021. [Online]. Available: https://doi.org/10.\\n1145/3472538.3472595\\n[167] P. Roetzer and M. Kaput, Marketing Artiﬁcial Intelligence: AI, Mar-\\nketing, and the Future of Business . BenBella Books, 2022.\\n[168] J. Thiergart, S. Huber, and T. ¨Ubellacker, “Understanding emails\\nand drafting responses–an approach using gpt-3,” arXiv preprint\\narXiv:2102.03062, 2021.\\n[169] X. Bai, L. Duan, R. Tang, G. Batra, and R. Agrawal, “Improving text-\\nbased similar product recommendation for dynamic product advertising\\nat yahoo,” in Proceedings of the 31st ACM International Conference on\\nInformation & Knowledge Management , ser. CIKM ’22. New York,\\nNY , USA: Association for Computing Machinery, 2022, p. 2883–2892.\\n[Online]. Available: https://doi.org/10.1145/3511808.3557129\\n[170] P. S. Neves, “Chat gpt ais “interview” 1, december 2022,” AIS-\\nArchitecture Image Studies, vol. 3, no. 2, pp. 58–67, 2022.\\n[171] X.-R. Gong, J.-X.', mimetype='text/plain', start_char_idx=5044, end_char_idx=7861, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.628496433308969), NodeWithScore(node=TextNode(id_='9fea320a-6114-4182-a629-3c6c113ab23d', embedding=None, metadata={'page_label': '38', 'file_name': 'GPT-paper.pdf', 'file_path': 'c:\\\\Users\\\\User\\\\Desktop\\\\LlamaIndex\\\\tutorials\\\\loading_data\\\\..\\\\..\\\\data\\\\GPT-paper.pdf', 'file_type': 'application/pdf', 'file_size': 3250309, 'creation_date': '2025-02-12', 'last_modified_date': '2025-01-21'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='5cfe4436-8ade-4f8c-acb7-3148f16764ee', node_type='4', metadata={'page_label': '38', 'file_name': 'GPT-paper.pdf', 'file_path': 'c:\\\\Users\\\\User\\\\Desktop\\\\LlamaIndex\\\\tutorials\\\\loading_data\\\\..\\\\..\\\\data\\\\GPT-paper.pdf', 'file_type': 'application/pdf', 'file_size': 3250309, 'creation_date': '2025-02-12', 'last_modified_date': '2025-01-21'}, hash='f4d4e57f7ae9eaa3babdfbb42d4f1146dd4dea7c9401314bfb00d5f44a903ff5'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='b6ee86e3-beea-47a1-8fb7-2b76693ed980', node_type='1', metadata={'page_label': '38', 'file_name': 'GPT-paper.pdf', 'file_path': 'c:\\\\Users\\\\User\\\\Desktop\\\\LlamaIndex\\\\tutorials\\\\loading_data\\\\..\\\\..\\\\data\\\\GPT-paper.pdf', 'file_type': 'application/pdf', 'file_size': 3250309, 'creation_date': '2025-02-12', 'last_modified_date': '2025-01-21'}, hash='12c2005cf0268f5c1b502191a091abe38fc6a662d6d1dd04ff0357113f2f5f85')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='Raghavan, M. Ahuja et al. ,\\n““so what if chatgpt wrote it?” multidisciplinary perspectives on op-\\nportunities, challenges and implications of generative conversational ai\\nfor research, practice and policy,” International Journal of Information\\nManagement, vol. 71, p. 102642, 2023.\\n[118] S. Biswas, “Prospective role of chat gpt in the military: According to\\nchatgpt,” Qeios, 2023.\\n[119] P. Helo and A. Shamsuzzoha, “Real-time supply chain—a blockchain\\narchitecture for project deliveries,” Robotics and Computer-Integrated\\nManufacturing, vol. 63, p. 101909, 2020.\\n[120] R. Kadel, H. Shrestha, A. Shrestha, P. Sharma, N. Shrestha, J. Bashyal,\\nand S. Shrestha, “Emergence of ai in cyber security,” International\\nResearch Journal of Modernization in Engineering Technology and\\nScience, 2022.\\n[121] H. Benbya, S. Pachidi, and S. Jarvenpaa, “Special issue editorial:\\nArtiﬁcial intelligence in organizations: Implications for information\\nsystems research,” Journal of the Association for Information Systems ,\\nvol. 22, no. 2, p. 10, 2021.\\n[122] T. Zheng, M. Ardolino, A. Bacchetti, and M. Perona, “The applications\\nof industry 4.0 technologies in manufacturing context: a systematic lit-\\nerature review,”International Journal of Production Research, vol. 59,\\nno. 6, pp. 1922–1954, 2021.\\n[123] B. Rathore, “Digital transformation 4.0: Integration of artiﬁcial in-\\ntelligence & metaverse in marketing,” Eduzone: International Peer\\nReviewed/Refereed Multidisciplinary Journal, vol. 12, no. 1, pp. 42–48,\\n2023.\\n[124] J. Bulchand-Gidumal, “Impact of artiﬁcial intelligence in travel,\\ntourism, and hospitality,” in Handbook of e-Tourism. Springer, 2022,\\npp. 1943–1962.\\n[125] N. Gillani, R. Eynon, C. Chiabaut, and K. Finkel, “Unpacking the\\n“black box” of ai in education,” Educational Technology & Society ,\\nvol. 26, no. 1, pp. 99–111, 2023.\\n[126] N. Mehrabi, F. Morstatter, N. Saxena, K. Lerman, and A. Galstyan,\\n“A survey on bias and fairness in machine learning,” ACM Computing\\nSurveys (CSUR), vol. 54, no. 6, pp. 1–35, 2021.\\n[127] F. T. Tschang and E. Almirall, “Artiﬁcial intelligence as augmenting\\nautomation: Implications for employment,” Academy of Management\\nPerspectives, vol. 35, no. 4, pp. 642–659, 2021.\\n[128] V . Jain, B. Malviya, and S. Arya, “An overview of electronic commerce\\n(e-commerce),” Journal of Contemporary Issues in Business and Gov-\\nernment— Vol , vol. 27, no. 3, p. 666, 2021.\\n[129] B. Feijoo and A. Garc ´ıa Gonz´alez, “Online shopping routines among\\nchilean children: level of expansion and main causes,” 2020.', mimetype='text/plain', start_char_idx=6713, end_char_idx=9243, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.6241788738592242)], metadata={'64a633f6-863c-4c91-9b24-93d4d9c57ad5': {'page_label': '39', 'file_name': 'GPT-paper.pdf', 'file_path': 'c:\\\\Users\\\\User\\\\Desktop\\\\LlamaIndex\\\\tutorials\\\\loading_data\\\\..\\\\..\\\\data\\\\GPT-paper.pdf', 'file_type': 'application/pdf', 'file_size': 3250309, 'creation_date': '2025-02-12', 'last_modified_date': '2025-01-21'}, '9fea320a-6114-4182-a629-3c6c113ab23d': {'page_label': '38', 'file_name': 'GPT-paper.pdf', 'file_path': 'c:\\\\Users\\\\User\\\\Desktop\\\\LlamaIndex\\\\tutorials\\\\loading_data\\\\..\\\\..\\\\data\\\\GPT-paper.pdf', 'file_type': 'application/pdf', 'file_size': 3250309, 'creation_date': '2025-02-12', 'last_modified_date': '2025-01-21'}})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response1 = query_engine.query(\"What are the main topics discussed in these documents\")\n",
    "response1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Under the hood, this splits your Document into Node objects, which are similar to Documents (they contain text and metadata) but have a relationship to their parent Document.\n",
    "\n",
    "If you want to customize core components, like the text splitter, through this abstraction you can pass in a custom transformations list or apply to the global Settings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\anaconda3\\envs\\llm\\lib\\site-packages\\llama_index\\core\\indices\\base.py:110: DeprecationWarning: Call to deprecated method get_doc_id. ('get_doc_id' is deprecated, access the 'id_' property instead.) -- Deprecated since version 0.12.2.\n",
      "  docstore.set_document_hash(doc.get_doc_id(), doc.hash)\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.core import Settings, VectorStoreIndex, SimpleDirectoryReader\n",
    "\n",
    "# Create the text splitter\n",
    "text_splitter = SentenceSplitter(chunk_size=512, chunk_overlap=10)\n",
    "\n",
    "# Set it globally\n",
    "Settings.text_splitter = text_splitter\n",
    "\n",
    "# Load documents\n",
    "documents = SimpleDirectoryReader(\"../../data\").load_data()\n",
    "\n",
    "# Create index - note the correct syntax here\n",
    "index = VectorStoreIndex.from_documents(\n",
    "    documents,  # Just pass documents directly\n",
    "    transformations=[text_splitter]\n",
    ")\n",
    "\n",
    "# Now you can create a query engine and use it\n",
    "query_engine = index.as_query_engine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
